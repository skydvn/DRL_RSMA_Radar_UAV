{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DRL-RSMA-Radar.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "mpllzjbjn6lb",
        "DNgW_zzrn_3y",
        "Xr5CEJAANWY6",
        "5xUhLjdsNRlC",
        "vMKb-zkdkz1F",
        "7p0roQPkH46C"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "mpllzjbjn6lb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/DuongLuongHoa-BKHN/DRL-RSMA-Radar\n",
        "!ls"
      ],
      "metadata": {
        "id": "j4wirn3GgNvw",
        "outputId": "57c7f409-a2cd-43d9-e9ab-7fb605720154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/Shareddrives/DuongLuongHoa-BKHN/DRL-RSMA-Radar\n",
            "'Copy of DRL-RSMA-Radar.ipynb'\t DRL-RSMA-Radar.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "IN_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    !apt install python-opengl\n",
        "    !apt install ffmpeg\n",
        "    !apt install xvfb\n",
        "    !pip install pyvirtualdisplay\n",
        "    from pyvirtualdisplay import Display\n",
        "    \n",
        "    # Start virtual display\n",
        "    dis = Display(visible=0, size=(600, 400))\n",
        "    dis.start()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH0dOjduMJZE",
        "outputId": "cfc7a0d0-a70f-47b0-a21b-c1a7a028036f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 42 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library definition"
      ],
      "metadata": {
        "id": "DNgW_zzrn_3y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fundamental\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "import copy\n",
        "import random\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import scipy\n",
        "from scipy import special\n",
        "from scipy.special import lambertw\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pytorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "dtype = np.float32\n",
        "\n",
        "\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "5Gf0XAdGoDms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU \n",
        "if torch.backends.cudnn.enabled:\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    print(\"GPU enabled\")\n",
        "\n",
        "seed = 777\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WizJlJScMDRK",
        "outputId": "5f3261ca-b99b-4d4b-db60-02014341bed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU enabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment "
      ],
      "metadata": {
        "id": "bRzGOQ-xn-pP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definition of Channel\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ek73oLa8bjjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BS - CU**\n",
        "* Channel: $h^C_q$, Noise: $n^C_q$ ~ $\\sigma^2_q$, Power: $p_o$ (broadcast power), $p_q$ (normal transmit power)\n",
        "\n",
        "**CU**\n",
        "* Common data rate: $a_{q,0}$\n",
        "\n",
        "**UAV**\n",
        "* Channel: $h^C_q$, Noise: $n^C_q$ ~ $\\sigma^2_q$\n",
        "\n",
        "**UAV**\n",
        "* Channel: $h^C_q$ \n",
        "<!-- *  Noise:   $n^C_q$ ~ $\\sigma^2_q$ -->\n",
        "\n",
        "**Radar**\n",
        "* Channel: $h^{CR}$, Noise: $n^R$ ~ $\\sigma^2$\n",
        "\n",
        "<!-- **Radar - UAV**\n",
        "* Channel: $h^R$, Noise: $n^R$ ~ $\\sigma^2$ -->\n"
      ],
      "metadata": {
        "id": "ABQldJO2er8c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "fGVutbBQesxr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNUR settings\n",
        "Here is a CNUR settings\n",
        "\n",
        "| Notations            | Value        ||| Notations            | Value        | \n",
        "|---                   |---           ||| ---                  | ---          | \n",
        "|Number of CU (Q)      | 10 - 20      ||| Antenna Gain T BS    |  17dBi~50    | \n",
        "|Wave length (lambda)  | 0.1m         ||| Antenna Gain R BS    |   0dBi~1     | \n",
        "|BS to CU              | 200-300m     ||| Antanna Gain Radar   |  30dBi~1000  | \n",
        "|Radar to CU           | 1000-2000m   ||| G'^R_t               | -27dBi~0.002 | \n",
        "|Radar to UAV          | 5000-10000m  ||| G'^R_r               | -27dBi~0.002 | \n",
        "|P_BS                  | 30 dBm / 1W  ||| sigma_RCS            | 1m^2         | \n",
        "|P_radar               | 1000W        ||| sigma^2_q, sigma^2   | -150dBm/Hz   | |B                     | 10^6         ||| C^TH                 | 10^5 - 4*10^5| "
      ],
      "metadata": {
        "id": "A1Hu2XGdiQF1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwXtcdjfejiX"
      },
      "outputs": [],
      "source": [
        "class Env_CNUR():\n",
        "    ### Initialization ###\n",
        "    def __init__(self, MAX_EP_STEPS, N_user_max,   \n",
        "                 BS_R_min, BS_R_max, radar_R,           # Radius of BS and Radar distance to BS\n",
        "                 h_max, h_min,                          # Height of the UAV\n",
        "                 uav_R_max, uav_R_min,                  # Radius of the UAV\n",
        "                #  Radar_R_max,                         # Radius of the Radar\n",
        "                 C_TH,                                  # Datarate threshold\n",
        "                 P_BS_max, P_radar_max,                 # Power\n",
        "                 Bandwidth, noise):                     # Data Rate, Bandwidth\n",
        "        # Visualization\n",
        "        self.visualization = \"2D\"          # 3D or else\n",
        "        # Data logging\n",
        "        self.verbose_distance = False\n",
        "        self.verbose_channelGain = False\n",
        "        self.verbose_SINR = False\n",
        "        self.verbose_DataRate = False\n",
        "\n",
        "        # Network settings\n",
        "        self.BS_R_max = BS_R_max           # Base Station maximum radius\n",
        "        self.BS_R_min = BS_R_min           # Base Station minimum radius\n",
        "        self.N_User = N_user_max           # Number of User / m\n",
        "        self.P_BS_max  = P_BS_max          # Base Station 's max power / m\n",
        "        self.noise  = noise                # Noise density: -174 dBm/Hz\n",
        "        self.B      = Bandwidth            # Bandwidth\n",
        "        self.C_TH   = C_TH                 # Lower threshold for data rate - CU\n",
        "\n",
        "        self.n_0 = noise**2 * self.B       # Noise power     \n",
        "        self.lambda_c = 0.1                #   \n",
        "        # Power setting\n",
        "        self.P_CU   = 1                    # 1W\n",
        "        self.P_R    = 1000                 # P_radar_max = 1000\n",
        "        self.P_BS_0 = np.random.uniform(self.P_BS_max/2, self.P_BS_max)\n",
        "        self.P_BS_U = (self.P_BS_max / self.N_User)* np.ones((self.N_User, 1))        \n",
        "\n",
        "        # Antenna Gain\n",
        "        self.G_R_t = 1000                               # Transmitting Radar Gain\n",
        "        self.G_R_r = 1000                               # Transmitting Radar Gain\n",
        "        self.G_R_t_s = 0.002\n",
        "        self.G_R_r_s = 0.002\n",
        "        self.G_C_t = 50                                 # Transmitting BS Gain\n",
        "        self.G_CU_list = np.ones((self.N_User,1))       # Receiving antenna gain of all CUs\n",
        "        self.sigma_RCS = 1                              # Radar coss section of target - Radar\n",
        "        self.sigma2 = -10**(-18)                        # W/Hz\n",
        "\n",
        "        # Base Station initialization\n",
        "        self.P_max = P_BS_max                 # Max power        \n",
        "        self.BS_x = 0                      # BS location initialization \n",
        "        self.BS_y = 0                      # BS location initialization \n",
        "        self.BS_location = np.expand_dims(self._location_BS_Generator(), axis=0)\n",
        "        self.Common_User_Allocation = np.random.rand(self.N_User,1)\n",
        "\n",
        "        # Radar initialization\n",
        "        self.Radar_R = radar_R             # Radius\n",
        "        self.Gamma_R = 10                  # dB ??? \n",
        "        self.Radar_location = np.expand_dims(self._location_Radar_Generator(), axis=0)\n",
        "\n",
        "        # UAV initialization\n",
        "        self.uav_h_max = h_max             # Height max\n",
        "        self.uav_h_min = h_min             # Height min\n",
        "        self.uav_R_max = uav_R_max         # R UAV max \n",
        "        self.uav_R_min = uav_R_min         # R UAV min \n",
        "        self.UAV_location   = np.expand_dims(self._location_UAV_Generator()  , axis=0)\n",
        "        self.UAV_trajectory = np.expand_dims(self._trajectory_UAV_Generator(), axis=0)\n",
        "\n",
        "        # User location initialization\n",
        "        self.CU_location = self._location_CU_Generator()\n",
        "        \n",
        "        # Distance calculation\n",
        "\n",
        "        self.distance_Radar_UAV    = self._calculateDistance(self.UAV_location, self.Radar_location)\n",
        "        self.distance_BS_Radar     = self._calculateDistance(self.UAV_location, self.BS_location)\n",
        "        self.distanceList_BS_CU    = self._calculateDistance(self.BS_location , self.CU_location)\n",
        "        self.distanceList_Radar_CU = self._calculateDistance(self.CU_location , self.Radar_location)\n",
        "        if self.verbose_distance == True:\n",
        "            print(\"Distance\")\n",
        "            print(f\"radar-uav: {self.distance_Radar_UAV}\")\n",
        "            print(f\"radar-bs: {self.distance_BS_Radar}\")\n",
        "            print(f\"bs-cu: {self.distanceList_BS_CU}\")\n",
        "            print(f\"radar-cu: {self.distanceList_Radar_CU}\")\n",
        "         \n",
        "        # Channel Gain\n",
        "        self.H_R  = self._channelGain_Radar_UAV()        # Channel round-trip between Radar and UAV\n",
        "        self.H_CR = self._channelGain_BS_Radar()         # Channel from BS to Radar\n",
        "        self.H_C  = self._channelGain_BS_CU()            # Channel from BS to CU    (Interference)\n",
        "        self.H_RC = self._channelGain_Radar_CU()         # Channel from Radar to CU (Interference)\n",
        "        if self.verbose_channelGain == True:\n",
        "            print(\"Channel Gain\")\n",
        "            print(f\"radar-uav: {self.H_R}\")\n",
        "            print(f\"radar-bs: {self.H_CR}\")\n",
        "            print(f\"bs-cu: {self.H_C}\")\n",
        "            print(f\"radar-cu: {self.H_RC}\")            \n",
        "\n",
        "        # SINR calculation\n",
        "        self.SINR_Radar = self._SINR_Radar(power_radar = self.P_R, \n",
        "                                           power_bs_comm = self.P_BS_0, power_bs_priv = self.P_BS_U,\n",
        "                                           H_radar_uav = self.H_R, H_BS_radar = self.H_CR)\n",
        "        if self.verbose_SINR == True:\n",
        "            print(f\"SINR: {self.SINR_Radar}\")\n",
        "        self.commonDataRate, self.privateDataRate = self._calculateDataRate(self.H_C, self.H_RC)\n",
        "        if 0 == 1:\n",
        "            print(f\"common: {self.commonDataRate}\")\n",
        "            print(f\"private: {self.privateDataRate}\")\n",
        "\n",
        "        # Environment settings\n",
        "        \"state_size can be represented by number of user initialized each episode\"\n",
        "        self.rewardMatrix = np.array([])\n",
        "\n",
        "        self.observation_space = self._wrapState().squeeze()\n",
        "        self.action_space      = self._wrapAction().squeeze()\n",
        "        self.reward_space      = np.array(())\n",
        "\n",
        "    ### Functions ###\n",
        "    # Channel gain generation\n",
        "    def _channelGain_BS_CU(self):\n",
        "        numerator   = self.G_C_t * self.G_CU_list * (self.lambda_c**2)\n",
        "        denominator = ((4*np.pi)**3) * (self.distanceList_BS_CU**4)\n",
        "        channelGain = numerator/denominator \n",
        "        return channelGain\n",
        "\n",
        "    def _channelGain_Radar_CU(self):\n",
        "        numerator   = self.G_R_t * self.G_CU_list * (self.lambda_c**2)\n",
        "        denominator = ((4*np.pi)**3) * (self.distanceList_Radar_CU**4)\n",
        "        channelGain = numerator/denominator \n",
        "        return channelGain\n",
        "\n",
        "    def _channelGain_BS_Radar(self):\n",
        "        numerator   = self.G_C_t * self.G_R_r * (self.lambda_c**2)\n",
        "        denominator = ((4*np.pi)**3) * (self.distance_BS_Radar**4)\n",
        "        channelGain = numerator/denominator \n",
        "        return channelGain\n",
        "\n",
        "    def _channelGain_Radar_UAV(self):            # h^R\n",
        "        numerator   = self.G_R_t * self.G_R_r * self.sigma_RCS * (self.lambda_c**2)\n",
        "        denominator = ((4*np.pi)**3) * (self.distance_Radar_UAV**4)\n",
        "        channelGain = numerator/denominator \n",
        "        return channelGain\n",
        "\n",
        "    # Radar initialization\n",
        "    def _location_BS_Generator(self):\n",
        "        # r = self.BS_R_max * np.sqrt(np.random.rand())\n",
        "        # theta = np.random.uniform(-np.pi, np.pi)\n",
        "        # Radar_x = self.BS_x + r*np.cos(theta)\n",
        "        # Radar_y = self.BS_y + r*np.sin(theta)\n",
        "        BS_location = [self.BS_x, self.BS_y, 0]\n",
        "        return np.array(BS_location)\n",
        "\n",
        "    # Radar initialization\n",
        "    def _location_Radar_Generator(self):\n",
        "        r = self.Radar_R * np.sqrt(np.random.rand())\n",
        "        theta = np.random.uniform(-np.pi, np.pi)\n",
        "        Radar_x = self.BS_x + r*np.cos(theta)\n",
        "        Radar_y = self.BS_y + r*np.sin(theta)\n",
        "        Radar_location = [Radar_x, Radar_y, 0]\n",
        "        return np.array(Radar_location)\n",
        "\n",
        "    # UAV initialization\n",
        "    def _location_UAV_Generator(self):\n",
        "        # h_min < h < h_max\n",
        "        # -180 < theta < 180 (Oxy hyper-space)\n",
        "        # 0 < R < R_Max\n",
        "        r = self.uav_R_max * np.sqrt(np.random.rand())\n",
        "        theta = np.random.uniform(-np.pi, np.pi)\n",
        "        UAV_x = self.BS_x + r*np.cos(theta)\n",
        "        UAV_y = self.BS_y + r*np.sin(theta)\n",
        "        UAV_h = np.random.uniform(self.uav_h_min, self.uav_h_max)\n",
        "        UAV_location = [UAV_x, UAV_y, UAV_h]\n",
        "        return np.array(UAV_location)\n",
        "\n",
        "    def _trajectory_UAV_Generator(self):\n",
        "        theta  = 0\n",
        "        theta  = theta + np.pi/360\n",
        "        r      = np.sin(theta)\n",
        "        UAV_vx = r*np.cos(2*theta)\n",
        "        UAV_vy = r*np.sin(2*theta)\n",
        "        UAV_vh = 0\n",
        "        UAV_trajectory = [UAV_vx, UAV_vy, UAV_vh]\n",
        "        return np.array(UAV_trajectory)\n",
        "\n",
        "    # User distance initialization\n",
        "    def _location_CU_Generator(self):\n",
        "        # Generate random CU locations\n",
        "        # N_User: number of users\n",
        "        # BS_R_min, BS_R_max: circle radius\n",
        "        # [BS_x, BS_y]: center of the circle\n",
        "        userList = []\n",
        "        for i in range(self.N_User):\n",
        "            r = self.BS_R_max * np.sqrt(np.random.rand())\n",
        "            # theta =  i/self.N_User*2*np.pi + np.random.uniform(-np.pi/10, np.pi/10)\n",
        "            theta = np.random.uniform(-np.pi, np.pi)\n",
        "            xUser_temp = self.BS_x + r*np.cos(theta)\n",
        "            yUser_temp = self.BS_y + r*np.sin(theta)\n",
        "            userList.append([xUser_temp, yUser_temp, 0])\n",
        "            \n",
        "        comm_user = np.array(userList)\n",
        "        if self.visualization == \"2D\":\n",
        "            #Plot scatter figure\n",
        "            fig, ax = plt.subplots()\n",
        "            circle1 = plt.Circle((self.BS_x, self.BS_y), 1, color='r', fill=True)\n",
        "            circle2 = plt.Circle((self.BS_x, self.BS_y), self.BS_R_min, color='g', fill=False)\n",
        "            circle3 = plt.Circle((self.BS_x, self.BS_y), self.BS_R_max, color='b', fill=False)\n",
        "            ax.add_patch(circle1)\n",
        "            ax.add_patch(circle2)\n",
        "            ax.add_patch(circle3)\n",
        "            # print(comm_user.transpose()[0:2].transpose())\n",
        "            gu = comm_user.transpose()[0:2].transpose()\n",
        "            plt.scatter(gu[:,0], gu[:,1])\n",
        "            plt.show()\n",
        "        # elif self.visualization == \"3D\":\n",
        "        #     fig = plt.figure()\n",
        "        #     ax = fig.add_subplot(projection='3d')\n",
        "        #     circle1 = plt.Circle((self.BS_x, self.BS_y, 0), 1, color='r', fill=True)\n",
        "        #     circle2 = plt.Circle((self.BS_x, self.BS_y, 0), self.BS_R_min, color='g', fill=False)\n",
        "        #     circle3 = plt.Circle((self.BS_x, self.BS_y, 0), self.BS_R_max, color='b', fill=False)\n",
        "        #     n = 100\n",
        "\n",
        "        #     # For each set of style and range settings, plot n random points in the box\n",
        "        #     # defined by x in [23, 32], y in [0, 100], z in [zlow, zhigh].\n",
        "        #     for m, zlow, zhigh in [('o', -50, -25), ('^', -30, -5)]:\n",
        "        #         xs = randrange(n, 23, 32)\n",
        "        #         ys = randrange(n, 0, 100)\n",
        "        #         zs = randrange(n, zlow, zhigh)\n",
        "        #         ax.scatter(xs, ys, zs, marker=m)\n",
        "\n",
        "        #     ax.set_xlabel('X')\n",
        "        #     ax.set_ylabel('Y')\n",
        "        #     ax.set_zlabel('Height')\n",
        "\n",
        "        #     plt.show()            \n",
        "        return comm_user\n",
        "\n",
        "    # SINR Calculator\n",
        "    ### power_bs_comm = 1 value\n",
        "    ### power_bs_priv = N_User value\n",
        "    ### power_radar   = 1 value\n",
        "    ### H_radar_uav   = 1\n",
        "    ### H_userradar   = N_User value\n",
        "    def _SINR_Radar(self, power_radar, power_bs_comm, power_bs_priv,\n",
        "                    H_radar_uav, H_BS_radar):\n",
        "        numerator = (H_radar_uav**2)*power_radar\n",
        "        denominator = (H_BS_radar**2) * (power_bs_comm + np.sum(power_bs_priv)) + (self.B*(self.sigma2))\n",
        "        SINR = numerator/denominator\n",
        "        return SINR\n",
        "\n",
        "    def _calculateDistance(self, A, B):\n",
        "        return np.array([np.sqrt(np.sum((A - B)**2,axis=1))]).transpose()\n",
        "    \n",
        "    def _selfExcluded_MatrixSum(self, V):\n",
        "        # Private user exclude sum of user at this point\n",
        "        # Clone P_BS_U vector into P_BS_U matrix \n",
        "        clonedM = np.ones((len(V),1))*V\n",
        "        # Remove diagonal\n",
        "        diagonalExcludedM = clonedM -np.diag(np.diag(clonedM))\n",
        "        # Sum over self-excluded matrix\n",
        "        rowWise_SumM = np.matrix(diagonalExcludedM).sum(axis=1)\n",
        "        return rowWise_SumM\n",
        "\n",
        "    def _calculateDataRate(self, channelGain_BS_CU, channelGain_Radar_CU):\n",
        "        # Generate partial components\n",
        "        interferenceRadarUser   = ((channelGain_Radar_CU)**2)*self.P_R\n",
        "\n",
        "        sumCommonUserPower      = np.sum(self.P_BS_U)\n",
        "        sumPrivateUserPower     = self._selfExcluded_MatrixSum(self.P_BS_U)\n",
        "\n",
        "        interferenceCommonUser  = ((channelGain_BS_CU)**2)*sumCommonUserPower  \n",
        "\n",
        "        interferencePrivateUser = np.multiply(((channelGain_BS_CU)**2),np.array([sumPrivateUserPower]).transpose())\n",
        "        interferenceBandwidth   = self.B*self.sigma2\n",
        "        \n",
        "        commonNumerator       = ((channelGain_BS_CU)**2)*self.P_BS_0\n",
        "        commonDenominator     = interferenceCommonUser + interferenceCommonUser + interferenceBandwidth\n",
        "        \n",
        "        privateNumerator      = ((channelGain_BS_CU)**2)*self.P_BS_U\n",
        "        privateDenominator    = interferencePrivateUser + interferenceCommonUser + interferenceBandwidth\n",
        "        \n",
        "        commonDataRate  = self.B * np.log2(1+(commonNumerator/commonDenominator))\n",
        "        privateDataRate = self.B * np.log2(1+(privateNumerator/privateDenominator))\n",
        "        if self.verbose_DataRate == True:\n",
        "            print(f\"sumPrivateUserPower: {sumPrivateUserPower}\")\n",
        "            print(f\"interferenceCommonUser: {interferenceCommonUser}\")\n",
        "            print(f\"interferencePrivateUser: {interferencePrivateUser}\")\n",
        "            print(f\"interferenceBandwidth: {interferenceBandwidth}\")\n",
        "            print(f\"commonNumerator: {commonNumerator}\")\n",
        "            print(f\"commonDenominator: {commonDenominator}\")\n",
        "            print(f\"privateNumerator: {privateNumerator}\")\n",
        "            print(f\"privateDenominator: {privateDenominator}\")\n",
        "        return commonDataRate, privateDataRate\n",
        "\n",
        "    def _wrapState(self):\n",
        "        # Channel Gain\n",
        "        self.H_R  = self._channelGain_Radar_UAV()        # Channel round-trip between Radar and UAV\n",
        "        self.H_CR = self._channelGain_BS_Radar()         # Channel from BS to Radar\n",
        "        self.H_C  = self._channelGain_BS_CU()            # Channel from BS to CU    (Interference)  \n",
        "        self.H_RC = self._channelGain_Radar_CU()         # Channel from Radar to CU (Interference)  \n",
        "        if self.verbose_channelGain == True:\n",
        "            print(\"Channel Gain\")\n",
        "            print(f\"radar-uav: {self.H_R}\")\n",
        "            print(f\"radar-bs: {self.H_CR}\")\n",
        "            print(f\"bs-cu: {self.H_C}\")    \n",
        "            print(f\"radar-cu: {self.H_RC}\")\n",
        "\n",
        "        # SINR calculation\n",
        "        self.SINR_Radar = self._SINR_Radar(power_radar = self.P_R,                                  \n",
        "                                           power_bs_comm = self.P_BS_0, power_bs_priv = self.P_BS_U,\n",
        "                                           H_radar_uav = self.H_R, H_BS_radar = self.H_CR)          \n",
        "        if self.verbose_SINR == True:\n",
        "            print(f\"SINR: {self.SINR_Radar}\")\n",
        "        self.commonDataRate, self.privateDataRate = self._calculateDataRate(self.H_C, self.H_RC)\n",
        "\n",
        "        # print(np.shape(self.H_RC))\n",
        "        # print(np.shape(self.H_C))\n",
        "        # print(np.shape(self.H_CR))\n",
        "        # print(np.shape(self.H_R))\n",
        "        # print(np.shape(self.UAV_location))\n",
        "        # print(np.shape(self.UAV_trajectory))\n",
        "\n",
        "        state = np.concatenate((np.array(self.H_RC).reshape(1,self.N_User), np.array(self.H_C).reshape(1,self.N_User),                    \n",
        "                                np.array(self.H_CR), np.array(self.H_R),                    \n",
        "                                np.array(self.UAV_location), np.array(self.UAV_trajectory)\n",
        "                               ), axis = 1)\n",
        "\n",
        "        return state\n",
        "\n",
        "    def _wrapAction(self):\n",
        "        action = np.concatenate((np.array([[self.P_BS_0]]), np.array(self.P_BS_U).reshape(1,self.N_User),                    \n",
        "                                np.array([[self.P_R]]), np.array(self.Common_User_Allocation).reshape(1,self.N_User)                    \n",
        "                               ), axis = 1)\n",
        "        return action\n",
        "\n",
        "    def _decomposeState(self, state):\n",
        "        H_RC = state[0 : self.N_user]\n",
        "        H_C  = state[self.N_User     : 2*self.N_User]\n",
        "        H_CR = state[2*self.N_User   : 2*self.N_User+1]\n",
        "        H_R  = state[2*self.N_User+1 : 2*self.N_User+2]\n",
        "        UAV_location   = state[self.N_User+2 : 2*self.N_User+5]\n",
        "        UAV_trajectory = state[self.N_User+5 : 2*self.N_User+8]\n",
        "        return  [\n",
        "                 np.array(H_RC).reshape(self.N_User,1), np.array(H_C).reshape(self.N_User,1),                    \n",
        "                 np.array(H_CR), np.array(H_R),                    \n",
        "                 np.array(UAV_location), np.array(UAV_trajectory)\n",
        "                ]\n",
        "\n",
        "    def _decomposeAction(self, action):\n",
        "        P_BS_0 = action[0:1]\n",
        "        P_BS_U = action[1:1+self.N_User]\n",
        "        P_R    = action[1+self.N_User: 2+self.N_User]\n",
        "        Common_User_Allocation = action[2+self.N_User:2+2*self.N_User]\n",
        "        return [\n",
        "                np.array(P_BS_0), np.array(P_BS_U), \n",
        "                np.array(P_R), np.array(Common_User_Allocation)\n",
        "               ]\n",
        "\n",
        "    ###########################\n",
        "    # DRL Environment process #\n",
        "    def step(self, action):\n",
        "        # Current state decomposition\n",
        "        # State: [H_RC, H_C, H_CR, H_R, UAV_location, UAV_trajectory]\n",
        "        # self.H_RC, self.H_C, self.H_CR, self.H_R, self.UAV_location, self.UAV_trajectory = self._decomposeState()\n",
        "        # Current action decomposition\n",
        "        # Action: [P_BS_0, P_BS_U, P_R, Common_User_Allocation]\n",
        "        self.P_BS_0, self.P_BS_U, self.P_R, self.Common_User_Allocation = self._decomposeAction(action)\n",
        "\n",
        "        # Environment changed\n",
        "            # UAV moves\n",
        "        self.UAV_trajectory = np.expand_dims(self._trajectory_UAV_Generator(), axis=0)\n",
        "        self.UAV_location = self.UAV_location + self.UAV_trajectory\n",
        "            # Users move\n",
        "      \n",
        "        # state wrap [Radar-UAV, BS-Radar, BS-CU, Radar-CU]\n",
        "        state_next = self._wrapState()\n",
        "        # Re-calculate dataRate\n",
        "        self.commonDataRate, self.privateDataRate = self._calculateDataRate(self.H_C, self.H_RC)  \n",
        "        # Re-generate current Radar-SINR\n",
        "        self.SINR_Radar = self._SINR_Radar(power_radar = self.P_R,                                  \n",
        "                                           power_bs_comm = self.P_BS_0, power_bs_priv = self.P_BS_U,\n",
        "                                           H_radar_uav = self.H_R, H_BS_radar = self.H_CR)          \n",
        "        # Total dataRate\n",
        "        cRate = np.sum(self.privateDataRate) + np.min(self.commonDataRate)\n",
        "        # self.rewardMatrix = np.concatenate((self.rewardMatrix, cRate), axis = 0)\n",
        "\n",
        "        # Calculate reward (Sum-Rate)\n",
        "        reward = cRate \n",
        "\n",
        "        # If reach number of rounds / achieve the desirable reward -> done\n",
        "        done = False # not implement yet\n",
        "\n",
        "        return state_next, reward, done, {}\n",
        "\n",
        "    def reset(self):\n",
        "        # Base Station initialization\n",
        "        self.BS_location = np.expand_dims(self._location_BS_Generator(), axis=0)\n",
        "\n",
        "        # Radar initialization\n",
        "        self.Radar_location = np.expand_dims(self._location_Radar_Generator(), axis=0)\n",
        "\n",
        "        # UAV initialization\n",
        "        self.UAV_location   = np.expand_dims(self._location_UAV_Generator()  , axis=0)\n",
        "        self.UAV_trajectory = np.expand_dims(self._trajectory_UAV_Generator(), axis=0)\n",
        "\n",
        "        # User location initialization\n",
        "        self.CU_location = self._location_CU_Generator()\n",
        "        \n",
        "        # Distance calculation\n",
        "        self.distance_Radar_UAV    = self._calculateDistance(self.UAV_location, self.Radar_location)\n",
        "        self.distance_BS_Radar     = self._calculateDistance(self.UAV_location, self.BS_location)\n",
        "        self.distanceList_BS_CU    = self._calculateDistance(self.BS_location , self.CU_location)\n",
        "        self.distanceList_Radar_CU = self._calculateDistance(self.CU_location , self.Radar_location) \n",
        "        \n",
        "        # Generate next state\n",
        "        state_next = self._wrapState()\n",
        "\n",
        "        return state_next\n",
        "\n",
        "    def close(self):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = Env_CNUR(MAX_EP_STEPS = 10000, N_user_max = 5,   \n",
        "               BS_R_min = 10, BS_R_max = 150, radar_R = 1000,     # Radius of BS and Radar distance to BS\n",
        "               h_max = 500, h_min = 10,                           # Height of the UAV\n",
        "               uav_R_max = 1000, uav_R_min = 200,                 # Radius of the UAV\n",
        "               C_TH = 50,                                         # Datarate threshold\n",
        "               P_BS_max = 100, P_radar_max = 1000, \n",
        "               Bandwidth = 100, noise = -174)                     # Power, Data Rate, Bandwidth"
      ],
      "metadata": {
        "id": "KNWzAnU1CWZp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1eed20f0-ca0e-4e1e-9d98-aeac62e723f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DDPG Agent"
      ],
      "metadata": {
        "id": "6rYoxokfLYEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Replay buffer\n",
        "Typically, people implement replay buffers with one of the following three data structures:\n",
        "\n",
        "- collections.deque\n",
        "- list\n",
        "- numpy.ndarray\n",
        "\n",
        "**deque** is very easy to handle once you initialize its maximum length (e.g. deque(maxlen=buffer_size)). However, the indexing operation of deque gets terribly slow as it grows up because it is [internally doubly linked list](https://wiki.python.org/moin/TimeComplexity#collections.deque). On the other hands, **list** is an array, so it is relatively faster than deque when you sample batches at every step. Its amortized cost of Get item is [O(1)](https://wiki.python.org/moin/TimeComplexity#list).\n",
        "\n",
        "Last but not least, let's see **numpy.ndarray**. numpy.ndarray is even faster than list due to the fact that it is [a homogeneous array of fixed-size items](https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray), so you can get the benefits of [locality of reference](https://en.wikipedia.org/wiki/Locality_of_reference), . Whereas list is an array of pointers to objects, even when all of them are of the same type.\n",
        "\n",
        "Here, we are going to implement a replay buffer using numpy.ndarray.\n",
        "\n",
        "Reference: \n",
        "- [OpenAI spinning-up](https://github.com/openai/spinningup/blob/master/spinup/algos/sac/sac.py#L10)\n",
        "- [rainbow-is-all-you-need](https://render.githubusercontent.com/view/ipynb?commit=032d11277cf2436853478a69ca5a4aba03202598&enc_url=68747470733a2f2f7261772e67697468756275736572636f6e74656e742e636f6d2f437572742d5061726b2f7261696e626f772d69732d616c6c2d796f752d6e6565642f303332643131323737636632343336383533343738613639636135613461626130333230323539382f30312e64716e2e6970796e62&nwo=Curt-Park%2Frainbow-is-all-you-need&path=01.dqn.ipynb&repository_id=191133946&repository_type=Repository#Replay-buffer)"
      ],
      "metadata": {
        "id": "Xr5CEJAANWY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "    \"\"\"A simple numpy replay buffer.\"\"\"\n",
        "\n",
        "    def __init__(self, obs_dim: int, action_dim: int, size: int, batch_size: int = 32):\n",
        "        \"\"\"Initializate.\"\"\"\n",
        "        self.obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.next_obs_buf = np.zeros([size, obs_dim], dtype=np.float32)\n",
        "        self.acts_buf = np.zeros([size, action_dim], dtype=np.float32)\n",
        "        self.rews_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.done_buf = np.zeros([size], dtype=np.float32)\n",
        "        self.max_size, self.batch_size = size, batch_size\n",
        "        self.ptr, self.size, = 0, 0\n",
        "\n",
        "    def store(\n",
        "        self,\n",
        "        obs: np.ndarray,\n",
        "        act: np.ndarray, \n",
        "        rew: float, \n",
        "        next_obs: np.ndarray, \n",
        "        done: bool,\n",
        "    ):\n",
        "        \"\"\"Store the transition in buffer.\"\"\"\n",
        "        self.obs_buf[self.ptr] = obs\n",
        "        self.next_obs_buf[self.ptr] = next_obs\n",
        "        self.acts_buf[self.ptr] = act\n",
        "        self.rews_buf[self.ptr] = rew\n",
        "        self.done_buf[self.ptr] = done\n",
        "        self.ptr = (self.ptr + 1) % self.max_size\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "\n",
        "    def sample_batch(self) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
        "        idxs = np.random.choice(self.size, size=self.batch_size, replace=False)\n",
        "        return dict(obs=self.obs_buf[idxs],\n",
        "                    next_obs=self.next_obs_buf[idxs],\n",
        "                    acts=self.acts_buf[idxs],\n",
        "                    rews=self.rews_buf[idxs],\n",
        "                    done=self.done_buf[idxs])\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.size"
      ],
      "metadata": {
        "id": "r2U6kzQgLa4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## OU Noise\n",
        "**Ornstein-Uhlenbeck** process generates temporally correlated exploration, and it effectively copes with physical control problems of inertia.\n",
        "\n",
        "$$\n",
        "dx_t = \\theta(\\mu - x_t) dt + \\sigma dW_t\n",
        "$$"
      ],
      "metadata": {
        "id": "5xUhLjdsNRlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OUNoise:\n",
        "    \"\"\"Ornstein-Uhlenbeck process.\n",
        "    Taken from Udacity deep-reinforcement-learning github repository:\n",
        "    https://github.com/udacity/deep-reinforcement-learning/blob/master/\n",
        "    ddpg-pendulum/ddpg_agent.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        size: int, \n",
        "        mu: float = 0.0, \n",
        "        theta: float = 0.15, \n",
        "        sigma: float = 0.2,\n",
        "    ):\n",
        "        \"\"\"Initialize parameters and noise process.\"\"\"\n",
        "        self.state = np.float64(0.0)\n",
        "        self.mu = mu * np.ones(size)\n",
        "        self.theta = theta\n",
        "        self.sigma = sigma\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the internal state (= noise) to mean (mu).\"\"\"\n",
        "        self.state = copy.copy(self.mu)\n",
        "\n",
        "    def sample(self) -> np.ndarray:\n",
        "        \"\"\"Update internal state and return it as a noise sample.\"\"\"\n",
        "        x = self.state\n",
        "        dx = self.theta * (self.mu - x) + self.sigma * np.array(\n",
        "            [random.random() for _ in range(len(x))]\n",
        "        )\n",
        "        self.state = x + dx\n",
        "        return self.state"
      ],
      "metadata": {
        "id": "jVpi-esHMevz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Network"
      ],
      "metadata": {
        "id": "TsvTlYXDNfJK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Old network"
      ],
      "metadata": {
        "id": "4tUssQyJkx2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Actor(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_dim: int, \n",
        "        out_dim: int,\n",
        "        init_w: float = 3e-3,\n",
        "    ):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super(Actor, self).__init__()\n",
        "        self.hidden1 = nn.Linear(in_dim, 128)\n",
        "        self.hidden2 = nn.Linear(128, 128)\n",
        "        self.out = nn.Linear(128, out_dim)\n",
        "        \n",
        "        self.out.weight.data.uniform_(-init_w, init_w)\n",
        "        self.out.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(self, state: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = F.relu(self.hidden1(state))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        action = self.out(x).tanh()\n",
        "        \n",
        "        return action\n",
        "    \n",
        "    \n",
        "class Critic(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        in_dim: int, \n",
        "        init_w: float = 3e-3,\n",
        "    ):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        super(Critic, self).__init__()\n",
        "        \n",
        "        self.hidden1 = nn.Linear(in_dim, 128)\n",
        "        self.hidden2 = nn.Linear(128, 128)\n",
        "        self.out = nn.Linear(128, 1)\n",
        "        \n",
        "        self.out.weight.data.uniform_(-init_w, init_w)\n",
        "        self.out.bias.data.uniform_(-init_w, init_w)\n",
        "\n",
        "    def forward(\n",
        "        self, state: torch.Tensor, action: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Forward method implementation.\"\"\"\n",
        "        x = torch.cat((state, action), dim=-1)\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        value = self.out(x)\n",
        "        \n",
        "        return value"
      ],
      "metadata": {
        "id": "hkQ83MuwMiIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### New network"
      ],
      "metadata": {
        "id": "vMKb-zkdkz1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WEIGHTS_FINAL_INIT = 3e-3\n",
        "# BIAS_FINAL_INIT = 3e-4\n",
        "\n",
        "\n",
        "# def fan_in_uniform_init(tensor, fan_in=None):\n",
        "#     \"\"\"Utility function for initializing actor and critic\"\"\"\n",
        "#     if fan_in is None:\n",
        "#         fan_in = tensor.size(-1)\n",
        "\n",
        "#     w = 1. / np.sqrt(fan_in)\n",
        "#     nn.init.uniform_(tensor, -w, w)\n",
        "\n",
        "\n",
        "# class Actor(nn.Module):\n",
        "#     def __init__(self, hidden_size, \n",
        "#                  num_inputs, action_space):\n",
        "#         super(Actor, self).__init__()\n",
        "#         self.action_space = action_space\n",
        "#         num_outputs = action_space.shape[0]\n",
        "\n",
        "#         # Layer 1\n",
        "#         self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
        "#         self.ln1 = nn.LayerNorm(hidden_size[0])\n",
        "\n",
        "#         # Layer 2\n",
        "#         self.linear2 = nn.Linear(hidden_size[0], hidden_size[1])\n",
        "#         self.ln2 = nn.LayerNorm(hidden_size[1])\n",
        "\n",
        "#         # Output Layer\n",
        "#         self.mu = nn.Linear(hidden_size[1], num_outputs)\n",
        "\n",
        "#         # Weight Init\n",
        "#         fan_in_uniform_init(self.linear1.weight)\n",
        "#         fan_in_uniform_init(self.linear1.bias)\n",
        "\n",
        "#         fan_in_uniform_init(self.linear2.weight)\n",
        "#         fan_in_uniform_init(self.linear2.bias)\n",
        "\n",
        "#         nn.init.uniform_(self.mu.weight, -WEIGHTS_FINAL_INIT, WEIGHTS_FINAL_INIT)\n",
        "#         nn.init.uniform_(self.mu.bias, -BIAS_FINAL_INIT, BIAS_FINAL_INIT)\n",
        "\n",
        "#     def forward(self, inputs):\n",
        "#         x = inputs\n",
        "\n",
        "#         # Layer 1\n",
        "#         x = self.linear1(x)\n",
        "#         x = self.ln1(x)\n",
        "#         x = F.relu(x)\n",
        "\n",
        "#         # Layer 2\n",
        "#         x = self.linear2(x)\n",
        "#         x = self.ln2(x)\n",
        "#         x = F.relu(x)\n",
        "\n",
        "#         # Output\n",
        "#         mu = torch.tanh(self.mu(x))\n",
        "#         return mu\n",
        "\n",
        "# class Critic(nn.Module):\n",
        "#     def __init__(self, hidden_size, \n",
        "#                  num_inputs, action_space):\n",
        "#         super(Critic, self).__init__()\n",
        "#         self.action_space = action_space\n",
        "#         num_outputs = action_space.shape[0]\n",
        "\n",
        "#         # Layer 1\n",
        "#         self.linear1 = nn.Linear(num_inputs, hidden_size[0])\n",
        "#         self.ln1 = nn.LayerNorm(hidden_size[0])\n",
        "\n",
        "#         # Layer 2\n",
        "#         # In the second layer the actions will be inserted also \n",
        "#         self.linear2 = nn.Linear(hidden_size[0] + num_outputs, hidden_size[1])\n",
        "#         self.ln2 = nn.LayerNorm(hidden_size[1])\n",
        "\n",
        "#         # Output layer (single value)\n",
        "#         self.V = nn.Linear(hidden_size[1], 1)\n",
        "\n",
        "#         # Weight Init\n",
        "#         fan_in_uniform_init(self.linear1.weight)\n",
        "#         fan_in_uniform_init(self.linear1.bias)\n",
        "\n",
        "#         fan_in_uniform_init(self.linear2.weight)\n",
        "#         fan_in_uniform_init(self.linear2.bias)\n",
        "\n",
        "#         nn.init.uniform_(self.V.weight, -WEIGHTS_FINAL_INIT, WEIGHTS_FINAL_INIT)\n",
        "#         nn.init.uniform_(self.V.bias, -BIAS_FINAL_INIT, BIAS_FINAL_INIT)\n",
        "\n",
        "#     def forward(self, inputs, actions):\n",
        "#         x = inputs\n",
        "\n",
        "#         # Layer 1\n",
        "#         x = self.linear1(x)\n",
        "#         x = self.ln1(x)\n",
        "#         x = F.relu(x)\n",
        "\n",
        "#         # Layer 2\n",
        "#         x = torch.cat((x, actions), 1)  # Insert the actions\n",
        "#         x = self.linear2(x)\n",
        "#         x = self.ln2(x)\n",
        "#         x = F.relu(x)\n",
        "\n",
        "#         # Output\n",
        "#         V = self.V(x)\n",
        "#         return V"
      ],
      "metadata": {
        "id": "xRUeMz45k1i3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DDPG Agent\n",
        "Here is a summary of DDPGAgent class.\n",
        "\n",
        "| Method           | Note                                                 |\n",
        "|---               |---                                                  |\n",
        "|select_action     | select an action from the input state.               |\n",
        "|step              | take an action and return the response of the env.   |\n",
        "|update_model      | update the model by gradient descent.                |\n",
        "|train             | train the agent during num_frames.                   |\n",
        "|test              | test the agent (1 episode).                          |\n",
        "|\\_target_soft_update| soft update from the local model to the target model.|\n",
        "|\\_plot              | plot the training progresses.     "
      ],
      "metadata": {
        "id": "7aAkNYiZNLjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDPGAgent:\n",
        "    \"\"\"DDPGAgent interacting with environment.\n",
        "    \n",
        "    Attribute:\n",
        "        env (gym.Env): openAI Gym environment\n",
        "        actor (nn.Module): target actor model to select actions\n",
        "        actor_target (nn.Module): actor model to predict next actions\n",
        "        actor_optimizer (Optimizer): optimizer for training actor\n",
        "        critic (nn.Module): critic model to predict state values\n",
        "        critic_target (nn.Module): target critic model to predict state values\n",
        "        critic_optimizer (Optimizer): optimizer for training critic\n",
        "        memory (ReplayBuffer): replay memory to store transitions\n",
        "        batch_size (int): batch size for sampling\n",
        "        gamma (float): discount factor\n",
        "        tau (float): parameter for soft target update\n",
        "        initial_random_steps (int): initial random action steps\n",
        "        noise (OUNoise): noise generator for exploration\n",
        "        device (torch.device): cpu / gpu\n",
        "        transition (list): temporory storage for the recent transition\n",
        "        total_step (int): total step numbers\n",
        "        is_test (bool): flag to show the current mode (train / test)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        env,\n",
        "        memory_size: int,\n",
        "        batch_size: int,\n",
        "        ou_noise_theta: float,\n",
        "        ou_noise_sigma: float,\n",
        "        gamma: float = 0.99,\n",
        "        tau: float = 5e-3,\n",
        "        initial_random_steps: int = 1e4,\n",
        "    ):\n",
        "        \"\"\"Initialize.\"\"\"\n",
        "        obs_dim = env.observation_space.shape[0]\n",
        "        print(env.observation_space.shape)\n",
        "        action_dim = env.action_space.shape[0]\n",
        "        print(env.action_space.shape)\n",
        "\n",
        "        self.discount = 1\n",
        "        self.env = env\n",
        "        self.memory = ReplayBuffer(obs_dim, action_dim, memory_size, batch_size)\n",
        "        self.batch_size = batch_size\n",
        "        self.gamma = gamma\n",
        "        self.tau = tau\n",
        "        self.initial_random_steps = initial_random_steps\n",
        "                \n",
        "        # noise\n",
        "        self.noise = OUNoise(\n",
        "            action_dim,\n",
        "            theta=ou_noise_theta,\n",
        "            sigma=ou_noise_sigma,\n",
        "        )\n",
        "\n",
        "        # device: cpu / gpu\n",
        "        self.device = torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        )\n",
        "        print(self.device)\n",
        "\n",
        "        # networks\n",
        "        self.actor = Actor(obs_dim, action_dim).to(self.device)\n",
        "        self.actor_target = Actor(obs_dim, action_dim).to(self.device)\n",
        "        self.actor_target.load_state_dict(self.actor.state_dict())\n",
        "        \n",
        "        self.critic = Critic(obs_dim + action_dim).to(self.device)\n",
        "        self.critic_target = Critic(obs_dim + action_dim).to(self.device)\n",
        "        self.critic_target.load_state_dict(self.critic.state_dict())\n",
        "\n",
        "        # optimizer\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=3e-4)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=1e-3)\n",
        "        \n",
        "        # transition to store in memory\n",
        "        self.transition = list()\n",
        "        \n",
        "        # total steps count\n",
        "        self.total_step = 0\n",
        "\n",
        "        # mode: train / test\n",
        "        self.is_test = False\n",
        "    \n",
        "    def select_action(self, state: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Select an action from the input state.\"\"\"\n",
        "        # if initial random action should be conducted\n",
        "        if self.total_step < self.initial_random_steps and not self.is_test:\n",
        "            selected_action = self.actor(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).detach().cpu().numpy()\n",
        "        else:\n",
        "            selected_action = self.actor(\n",
        "                torch.FloatTensor(state).to(self.device)\n",
        "            ).detach().cpu().numpy()\n",
        "        \n",
        "        # add noise for exploration during training\n",
        "        if not self.is_test:\n",
        "            noise = self.noise.sample()\n",
        "            selected_action = np.clip(selected_action + noise, -1.0, 1.0)\n",
        "        \n",
        "        self.transition = [state, selected_action]\n",
        "        \n",
        "        return selected_action\n",
        "    \n",
        "    def step(self, action: np.ndarray) -> Tuple[np.ndarray, np.float64, bool]:\n",
        "        \"\"\"Take an action and return the response of the env.\"\"\"\n",
        "        next_state, reward, done, _ = self.env.step(action)\n",
        "        \n",
        "        if not self.is_test:\n",
        "            self.transition += [reward, next_state, done]\n",
        "            # print(self.transition)\n",
        "            self.memory.store(*self.transition)\n",
        "    \n",
        "        return next_state, reward, done\n",
        "    \n",
        "    def update_model(self) -> torch.Tensor:\n",
        "        \"\"\"Update the model by gradient descent.\"\"\"\n",
        "        device = self.device  # for shortening the following lines\n",
        "        \n",
        "        samples = self.memory.sample_batch()\n",
        "        state = torch.FloatTensor(samples[\"obs\"]).to(device)\n",
        "        next_state = torch.FloatTensor(samples[\"next_obs\"]).to(device)\n",
        "        action = torch.FloatTensor(samples[\"acts\"]).to(device)     \n",
        "        reward = torch.FloatTensor(samples[\"rews\"].reshape(-1, 1)).to(device)\n",
        "        done = torch.FloatTensor(samples[\"done\"].reshape(-1, 1)).to(device)\n",
        "        if 0 == True: \n",
        "            print(f\"state size: {np.shape(state)}\")\n",
        "\n",
        "        masks = 1 - done\n",
        "        next_action = self.actor_target(next_state)\n",
        "        # print(f\"next action: {np.shape(next_action)}\")\n",
        "        next_value = self.critic_target(next_state, next_action)\n",
        "        curr_return = reward + self.gamma * next_value * masks\n",
        "        \n",
        "        # train critic\n",
        "        values = self.critic(state, action)\n",
        "        critic_loss = F.mse_loss(values, curr_return)\n",
        "        \n",
        "        self.critic_optimizer.zero_grad()\n",
        "        critic_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "                \n",
        "        # train actor\n",
        "        actor_loss = -self.critic(state, self.actor(state)).mean()\n",
        "        \n",
        "        self.actor_optimizer.zero_grad()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "        \n",
        "        # target update\n",
        "        self._target_soft_update()\n",
        "        \n",
        "        return actor_loss.data, critic_loss.data\n",
        "    \n",
        "    def train(self, num_frames: int, plotting_interval: int = 20000):\n",
        "        \"\"\"Train the agent.\"\"\"\n",
        "        self.is_test = False\n",
        "        \n",
        "        state = self.env.reset().squeeze()\n",
        "        \n",
        "        actor_losses = []\n",
        "        critic_losses = []\n",
        "        scores = []\n",
        "        score = 0\n",
        "        \n",
        "        for self.total_step in range(1, num_frames + 1):\n",
        "            action = self.select_action(state)\n",
        "            next_state, reward, done = self.step(action)\n",
        "            next_state = next_state.squeeze()\n",
        "            print(f\"reward of step {self.total_step} is: {reward}\")\n",
        "            state = next_state\n",
        "\n",
        "            score = self.discount*score + reward\n",
        "            # if episode ends\n",
        "            if done:         \n",
        "                state = env.reset().squeeze()\n",
        "                scores.append(score)\n",
        "                # print(f\"scores: {scores}\")\n",
        "                score = 0\n",
        "\n",
        "            # if training is ready\n",
        "            if (\n",
        "                len(self.memory) >= self.batch_size \n",
        "                and self.total_step > self.initial_random_steps\n",
        "            ):\n",
        "                actor_loss, critic_loss = self.update_model()\n",
        "                actor_losses.append(actor_loss)\n",
        "                critic_losses.append(critic_loss)\n",
        "                # print(f\"actor loss: {actor_losses}\")\n",
        "                # print(f\"critic loss: {critic_losses}\")\n",
        "            \n",
        "            # plotting\n",
        "            if self.total_step % plotting_interval == 0:\n",
        "                self._plot(\n",
        "                    self.total_step, \n",
        "                    scores, \n",
        "                    actor_losses, \n",
        "                    critic_losses,\n",
        "                )\n",
        "                pass\n",
        "        self.env.close()\n",
        "        \n",
        "    def test(self):\n",
        "        # \"\"\"Test the agent.\"\"\"\n",
        "        # self.is_test = True\n",
        "        \n",
        "        # state = self.env.reset()\n",
        "        # done = False\n",
        "        # score = 0\n",
        "        \n",
        "        # frames = []\n",
        "        # while not done:\n",
        "        #     frames.append(self.env.render(mode=\"rgb_array\"))\n",
        "        #     action = self.select_action(state)\n",
        "        #     next_state, reward, done = self.step(action)\n",
        "\n",
        "        #     state = next_state\n",
        "        #     score = self.discount*score + reward\n",
        "        \n",
        "        # print(\"score: \", score)\n",
        "        # self.env.close()\n",
        "        \n",
        "        # return frames\n",
        "        pass\n",
        "    \n",
        "    def _target_soft_update(self):\n",
        "        \"\"\"Soft-update: target = tau*local + (1-tau)*target.\"\"\"\n",
        "        tau = self.tau\n",
        "        \n",
        "        for t_param, l_param in zip(\n",
        "            self.actor_target.parameters(), self.actor.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "            \n",
        "        for t_param, l_param in zip(\n",
        "            self.critic_target.parameters(), self.critic.parameters()\n",
        "        ):\n",
        "            t_param.data.copy_(tau * l_param.data + (1.0 - tau) * t_param.data)\n",
        "    \n",
        "    def _plot(\n",
        "        self, \n",
        "        frame_idx: int, \n",
        "        scores: List[float], \n",
        "        actor_losses: List[float], \n",
        "        critic_losses: List[float], \n",
        "    ):\n",
        "        \"\"\"Plot the training progresses.\"\"\"\n",
        "        def subplot(loc: int, title: str, values: List[float]):\n",
        "            plt.subplot(loc)\n",
        "            plt.title(title)\n",
        "            plt.plot(values)\n",
        "\n",
        "        subplot_params = [\n",
        "            (131, f\"frame {frame_idx}. score: {np.mean(scores[-10:])}\", scores),\n",
        "            (132, \"actor_loss\", actor_losses),\n",
        "            (133, \"critic_loss\", critic_losses),\n",
        "        ]\n",
        "        \n",
        "        clear_output(True)\n",
        "        plt.figure(figsize=(30, 5))\n",
        "        for loc, title, values in subplot_params:\n",
        "            subplot(loc, title, values)\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "GW1sIaf9Mkv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Algorithm Execution"
      ],
      "metadata": {
        "id": "mWavl7GIMqH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_frames = 50000\n",
        "memory_size = 100000\n",
        "batch_size = 128\n",
        "ou_noise_theta = 1.0\n",
        "ou_noise_sigma = 0.1\n",
        "initial_random_steps = 10000\n",
        "\n",
        "agent = DDPGAgent(\n",
        "    env, \n",
        "    memory_size, \n",
        "    batch_size,\n",
        "    ou_noise_theta,\n",
        "    ou_noise_sigma,\n",
        "    initial_random_steps=initial_random_steps\n",
        ")"
      ],
      "metadata": {
        "id": "3dXH12mlMt0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6033e784-75cc-403f-9384-9ead35df1639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18,)\n",
            "(12,)\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.train(num_frames)"
      ],
      "metadata": {
        "id": "Ya3or16UM0SS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9530de23-5c46-45b2-ca7d-7291913fdef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2160x360 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "reward of step 20001 is: -0.00016821467065074235\n",
            "reward of step 20002 is: -0.00016469774287212617\n",
            "reward of step 20003 is: -0.00016284674808368546\n",
            "reward of step 20004 is: -0.00017438866362485902\n",
            "reward of step 20005 is: -0.00016411264873782437\n",
            "reward of step 20006 is: -0.00016048075954862835\n",
            "reward of step 20007 is: -0.00015922928309248534\n",
            "reward of step 20008 is: -0.0001682811556237358\n",
            "reward of step 20009 is: -0.00015760475737418641\n",
            "reward of step 20010 is: -0.00016443617008861017\n",
            "reward of step 20011 is: -0.00016817960187956056\n",
            "reward of step 20012 is: -0.00016806636475750572\n",
            "reward of step 20013 is: -0.0001597867848312851\n",
            "reward of step 20014 is: -0.0001723464785796617\n",
            "reward of step 20015 is: -0.00016189310643727298\n",
            "reward of step 20016 is: -0.0001764097346697644\n",
            "reward of step 20017 is: -0.00016997040847322516\n",
            "reward of step 20018 is: -0.00016322912051366562\n",
            "reward of step 20019 is: -0.00015765887428068062\n",
            "reward of step 20020 is: -0.00016523297291049668\n",
            "reward of step 20021 is: -0.00017769729474320642\n",
            "reward of step 20022 is: -0.00016199335668819437\n",
            "reward of step 20023 is: -0.00015695329064386692\n",
            "reward of step 20024 is: -0.00015827929915255193\n",
            "reward of step 20025 is: -0.00017492121804780998\n",
            "reward of step 20026 is: -0.00016762342750687847\n",
            "reward of step 20027 is: -0.00015456000167843076\n",
            "reward of step 20028 is: -0.0001658500592373428\n",
            "reward of step 20029 is: -0.0001721705607168767\n",
            "reward of step 20030 is: -0.0001566529459161165\n",
            "reward of step 20031 is: -0.0001782209146911951\n",
            "reward of step 20032 is: -0.00017292236259295365\n",
            "reward of step 20033 is: -0.00017306800263910033\n",
            "reward of step 20034 is: -0.00016949481237794417\n",
            "reward of step 20035 is: -0.000167042466474578\n",
            "reward of step 20036 is: -0.0001707186103397257\n",
            "reward of step 20037 is: -0.00016716559028932641\n",
            "reward of step 20038 is: -0.00015826175498107872\n",
            "reward of step 20039 is: -0.00016531370706290694\n",
            "reward of step 20040 is: -0.00017474464532980113\n",
            "reward of step 20041 is: -0.0001734494584944122\n",
            "reward of step 20042 is: -0.00016869041247410642\n",
            "reward of step 20043 is: -0.00017051580944270683\n",
            "reward of step 20044 is: -0.00016853737033381357\n",
            "reward of step 20045 is: -0.00016077358017546484\n",
            "reward of step 20046 is: -0.0001713959658116982\n",
            "reward of step 20047 is: -0.00017529928409351834\n",
            "reward of step 20048 is: -0.0001587593138951696\n",
            "reward of step 20049 is: -0.00015376627822792088\n",
            "reward of step 20050 is: -0.0001725000467172786\n",
            "reward of step 20051 is: -0.00017280517548303283\n",
            "reward of step 20052 is: -0.00016151621718312901\n",
            "reward of step 20053 is: -0.00016725634254930073\n",
            "reward of step 20054 is: -0.00015146791886222214\n",
            "reward of step 20055 is: -0.00016435110383195714\n",
            "reward of step 20056 is: -0.00015971033110518808\n",
            "reward of step 20057 is: -0.00017352988083432116\n",
            "reward of step 20058 is: -0.00016009790638227224\n",
            "reward of step 20059 is: -0.00017006830778550417\n",
            "reward of step 20060 is: -0.0001760148286995929\n",
            "reward of step 20061 is: -0.00016621154446811863\n",
            "reward of step 20062 is: -0.00015316177683554733\n",
            "reward of step 20063 is: -0.0001669970734152611\n",
            "reward of step 20064 is: -0.00017681300590422012\n",
            "reward of step 20065 is: -0.0001694280489491594\n",
            "reward of step 20066 is: -0.0001753998408138427\n",
            "reward of step 20067 is: -0.00016154273183666726\n",
            "reward of step 20068 is: -0.000173741181985014\n",
            "reward of step 20069 is: -0.00016709113168331412\n",
            "reward of step 20070 is: -0.00015551579083021013\n",
            "reward of step 20071 is: -0.0001603807942098266\n",
            "reward of step 20072 is: -0.00016259561703920345\n",
            "reward of step 20073 is: -0.0001648690818429103\n",
            "reward of step 20074 is: -0.00016178024875191302\n",
            "reward of step 20075 is: -0.00017247303037282147\n",
            "reward of step 20076 is: -0.00017020042028916514\n",
            "reward of step 20077 is: -0.00016811869721908697\n",
            "reward of step 20078 is: -0.0001643702499563683\n",
            "reward of step 20079 is: -0.00016877198548493233\n",
            "reward of step 20080 is: -0.0001791189587339007\n",
            "reward of step 20081 is: -0.00017127262940229605\n",
            "reward of step 20082 is: -0.0001728533564427905\n",
            "reward of step 20083 is: -0.00016807364029025972\n",
            "reward of step 20084 is: -0.0001669618459904779\n",
            "reward of step 20085 is: -0.00016945532000238922\n",
            "reward of step 20086 is: -0.00016835426139873415\n",
            "reward of step 20087 is: -0.00016386342826196068\n",
            "reward of step 20088 is: -0.00016819427217379168\n",
            "reward of step 20089 is: -0.00016413594766726127\n",
            "reward of step 20090 is: -0.0001752125839223446\n",
            "reward of step 20091 is: -0.0001699398875623381\n",
            "reward of step 20092 is: -0.0001710585323172207\n",
            "reward of step 20093 is: -0.00016542093529631059\n",
            "reward of step 20094 is: -0.00017714274943281342\n",
            "reward of step 20095 is: -0.0001728284386314646\n",
            "reward of step 20096 is: -0.00015961493496737767\n",
            "reward of step 20097 is: -0.00016499771220698683\n",
            "reward of step 20098 is: -0.00017181541259841243\n",
            "reward of step 20099 is: -0.00017354328347425548\n",
            "reward of step 20100 is: -0.00015984336576907874\n",
            "reward of step 20101 is: -0.00016851857544363755\n",
            "reward of step 20102 is: -0.00017014033969250868\n",
            "reward of step 20103 is: -0.00017388590569833543\n",
            "reward of step 20104 is: -0.0001780706343312241\n",
            "reward of step 20105 is: -0.00016518451699997966\n",
            "reward of step 20106 is: -0.00017652818154814646\n",
            "reward of step 20107 is: -0.0001690386904696531\n",
            "reward of step 20108 is: -0.0001657680924627095\n",
            "reward of step 20109 is: -0.0001724649969230379\n",
            "reward of step 20110 is: -0.00016096248586911825\n",
            "reward of step 20111 is: -0.00016615126774596192\n",
            "reward of step 20112 is: -0.00016890794349992892\n",
            "reward of step 20113 is: -0.00016809697162464612\n",
            "reward of step 20114 is: -0.00015715687763265078\n",
            "reward of step 20115 is: -0.00016694202201610265\n",
            "reward of step 20116 is: -0.00015938236281823014\n",
            "reward of step 20117 is: -0.0001765162121132833\n",
            "reward of step 20118 is: -0.00015761878149047446\n",
            "reward of step 20119 is: -0.00016953504336819243\n",
            "reward of step 20120 is: -0.00016856638948290926\n",
            "reward of step 20121 is: -0.0001765198528475142\n",
            "reward of step 20122 is: -0.00017726360953153843\n",
            "reward of step 20123 is: -0.00016769753091941384\n",
            "reward of step 20124 is: -0.00016601963331113685\n",
            "reward of step 20125 is: -0.0001672014418923493\n",
            "reward of step 20126 is: -0.00016606767800248398\n",
            "reward of step 20127 is: -0.00016065546963362038\n",
            "reward of step 20128 is: -0.0001544787311460539\n",
            "reward of step 20129 is: -0.00015697557313749323\n",
            "reward of step 20130 is: -0.00016950623558994343\n",
            "reward of step 20131 is: -0.00016873711502863074\n",
            "reward of step 20132 is: -0.00017366787290730873\n",
            "reward of step 20133 is: -0.0001594562487428902\n",
            "reward of step 20134 is: -0.00016359114685268972\n",
            "reward of step 20135 is: -0.00015733608636071434\n",
            "reward of step 20136 is: -0.00015368517343356325\n",
            "reward of step 20137 is: -0.00016400718204875943\n",
            "reward of step 20138 is: -0.00016596949721829724\n",
            "reward of step 20139 is: -0.00017049949504946543\n",
            "reward of step 20140 is: -0.00016603656227023823\n",
            "reward of step 20141 is: -0.00016931098865324636\n",
            "reward of step 20142 is: -0.00016293655715367327\n",
            "reward of step 20143 is: -0.0001743125336965639\n",
            "reward of step 20144 is: -0.00016141853399606265\n",
            "reward of step 20145 is: -0.00017831930634691485\n",
            "reward of step 20146 is: -0.000175690199064288\n",
            "reward of step 20147 is: -0.00016726142303309405\n",
            "reward of step 20148 is: -0.00015951579091459122\n",
            "reward of step 20149 is: -0.00017088133154457454\n",
            "reward of step 20150 is: -0.0001749364794484953\n",
            "reward of step 20151 is: -0.0001716650247837527\n",
            "reward of step 20152 is: -0.00016054663313354176\n",
            "reward of step 20153 is: -0.00016208268749923142\n",
            "reward of step 20154 is: -0.0001701053975500579\n",
            "reward of step 20155 is: -0.00015877947140167448\n",
            "reward of step 20156 is: -0.00015859825487536653\n",
            "reward of step 20157 is: -0.00016211129214493026\n",
            "reward of step 20158 is: -0.00016623059247892688\n",
            "reward of step 20159 is: -0.00017810695404356806\n",
            "reward of step 20160 is: -0.00016339617887652831\n",
            "reward of step 20161 is: -0.00016778436711131753\n",
            "reward of step 20162 is: -0.00016938098431018634\n",
            "reward of step 20163 is: -0.00017146653602083942\n",
            "reward of step 20164 is: -0.0001541011765206086\n",
            "reward of step 20165 is: -0.0001704556611290216\n",
            "reward of step 20166 is: -0.00016769499264895657\n",
            "reward of step 20167 is: -0.00016444825057369695\n",
            "reward of step 20168 is: -0.00016087914972130526\n",
            "reward of step 20169 is: -0.00015580750698660742\n",
            "reward of step 20170 is: -0.00015838936838636548\n",
            "reward of step 20171 is: -0.00016781390274689249\n",
            "reward of step 20172 is: -0.00015411505578397393\n",
            "reward of step 20173 is: -0.00017917907050090255\n",
            "reward of step 20174 is: -0.0001760008344177046\n",
            "reward of step 20175 is: -0.0001727996240371148\n",
            "reward of step 20176 is: -0.00017743204362155235\n",
            "reward of step 20177 is: -0.00017285098901070046\n",
            "reward of step 20178 is: -0.0001557220021078063\n",
            "reward of step 20179 is: -0.00016351954179035947\n",
            "reward of step 20180 is: -0.00016262314220351877\n",
            "reward of step 20181 is: -0.0001678626349504745\n",
            "reward of step 20182 is: -0.00017140722349558043\n",
            "reward of step 20183 is: -0.00017267846244675326\n",
            "reward of step 20184 is: -0.00015411380539357574\n",
            "reward of step 20185 is: -0.00016040937368570093\n",
            "reward of step 20186 is: -0.0001648302650049195\n",
            "reward of step 20187 is: -0.0001715691018448557\n",
            "reward of step 20188 is: -0.00016535994299141216\n",
            "reward of step 20189 is: -0.00016819473310141313\n",
            "reward of step 20190 is: -0.00017841243196525694\n",
            "reward of step 20191 is: -0.00016427821928071204\n",
            "reward of step 20192 is: -0.00016788736554454423\n",
            "reward of step 20193 is: -0.0001633942547771592\n",
            "reward of step 20194 is: -0.00015871231585429813\n",
            "reward of step 20195 is: -0.00016247741992314303\n",
            "reward of step 20196 is: -0.00016828263168101786\n",
            "reward of step 20197 is: -0.000158780765243527\n",
            "reward of step 20198 is: -0.00016995392184969592\n",
            "reward of step 20199 is: -0.0001665772908786156\n",
            "reward of step 20200 is: -0.00016746952135688058\n",
            "reward of step 20201 is: -0.0001690478413163245\n",
            "reward of step 20202 is: -0.00016646368087136994\n",
            "reward of step 20203 is: -0.00017889099807838176\n",
            "reward of step 20204 is: -0.00017180155200212602\n",
            "reward of step 20205 is: -0.0001638507009947343\n",
            "reward of step 20206 is: -0.00016912654967111607\n",
            "reward of step 20207 is: -0.00016827508402760276\n",
            "reward of step 20208 is: -0.000177301132347562\n",
            "reward of step 20209 is: -0.0001544660232187168\n",
            "reward of step 20210 is: -0.0001723654950690538\n",
            "reward of step 20211 is: -0.00016687432584641229\n",
            "reward of step 20212 is: -0.0001565770110197809\n",
            "reward of step 20213 is: -0.00016546130079350533\n",
            "reward of step 20214 is: -0.0001640370509140576\n",
            "reward of step 20215 is: -0.00016198310395144154\n",
            "reward of step 20216 is: -0.00017314253000267314\n",
            "reward of step 20217 is: -0.0001686860464608693\n",
            "reward of step 20218 is: -0.00016699192858782885\n",
            "reward of step 20219 is: -0.00016819428678434146\n",
            "reward of step 20220 is: -0.00015675777593855634\n",
            "reward of step 20221 is: -0.00016090725680251392\n",
            "reward of step 20222 is: -0.0001529511343741442\n",
            "reward of step 20223 is: -0.0001645667094243048\n",
            "reward of step 20224 is: -0.000172845108231928\n",
            "reward of step 20225 is: -0.00016268527829045698\n",
            "reward of step 20226 is: -0.00016272295989596414\n",
            "reward of step 20227 is: -0.00016434125025367732\n",
            "reward of step 20228 is: -0.00016644256741906095\n",
            "reward of step 20229 is: -0.00016160214524863072\n",
            "reward of step 20230 is: -0.00017327948713480014\n",
            "reward of step 20231 is: -0.00016984974936802764\n",
            "reward of step 20232 is: -0.00015672688977159163\n",
            "reward of step 20233 is: -0.00017472310461942163\n",
            "reward of step 20234 is: -0.00016151267643046077\n",
            "reward of step 20235 is: -0.00016538519718589222\n",
            "reward of step 20236 is: -0.00016958494090683267\n",
            "reward of step 20237 is: -0.00017479026545112218\n",
            "reward of step 20238 is: -0.00016907621733552096\n",
            "reward of step 20239 is: -0.0001735523865183369\n",
            "reward of step 20240 is: -0.00016906141619274425\n",
            "reward of step 20241 is: -0.00015957694374395102\n",
            "reward of step 20242 is: -0.00016929577846987482\n",
            "reward of step 20243 is: -0.00016510504911591058\n",
            "reward of step 20244 is: -0.00017348848248407048\n",
            "reward of step 20245 is: -0.00017668816052325779\n",
            "reward of step 20246 is: -0.0001647435016461099\n",
            "reward of step 20247 is: -0.00015897438928887852\n",
            "reward of step 20248 is: -0.0001741422467667742\n",
            "reward of step 20249 is: -0.00017332266895509456\n",
            "reward of step 20250 is: -0.00016816270227310343\n",
            "reward of step 20251 is: -0.00017915484036750258\n",
            "reward of step 20252 is: -0.0001656083325989868\n",
            "reward of step 20253 is: -0.0001576497035295315\n",
            "reward of step 20254 is: -0.00015577360357954979\n",
            "reward of step 20255 is: -0.00016085639298153937\n",
            "reward of step 20256 is: -0.0001656576827207194\n",
            "reward of step 20257 is: -0.00015184052801140574\n",
            "reward of step 20258 is: -0.00017275564294514214\n",
            "reward of step 20259 is: -0.00017374778321158034\n",
            "reward of step 20260 is: -0.0001591948805237745\n",
            "reward of step 20261 is: -0.00016490689754607903\n",
            "reward of step 20262 is: -0.00016872182846897735\n",
            "reward of step 20263 is: -0.0001565646361573803\n",
            "reward of step 20264 is: -0.00016212155364354877\n",
            "reward of step 20265 is: -0.00016367882642991878\n",
            "reward of step 20266 is: -0.00017025101639533212\n",
            "reward of step 20267 is: -0.00017556000690301674\n",
            "reward of step 20268 is: -0.0001634440398285023\n",
            "reward of step 20269 is: -0.00017004168514608305\n",
            "reward of step 20270 is: -0.00017442222652001602\n",
            "reward of step 20271 is: -0.00016694285724665398\n",
            "reward of step 20272 is: -0.00016445473685417446\n",
            "reward of step 20273 is: -0.00016768674273072285\n",
            "reward of step 20274 is: -0.00016584878548043172\n",
            "reward of step 20275 is: -0.00017525274378777842\n",
            "reward of step 20276 is: -0.0001701038242558503\n",
            "reward of step 20277 is: -0.00016945043235321443\n",
            "reward of step 20278 is: -0.0001796104784565218\n",
            "reward of step 20279 is: -0.0001714381443854658\n",
            "reward of step 20280 is: -0.0001703212242998209\n",
            "reward of step 20281 is: -0.00015475177369511504\n",
            "reward of step 20282 is: -0.00015750464915594394\n",
            "reward of step 20283 is: -0.00017461326695267465\n",
            "reward of step 20284 is: -0.00015677871628535822\n",
            "reward of step 20285 is: -0.0001761363735122269\n",
            "reward of step 20286 is: -0.0001623947264916959\n",
            "reward of step 20287 is: -0.0001633745332526915\n",
            "reward of step 20288 is: -0.00015658188691034411\n",
            "reward of step 20289 is: -0.00016936304110173216\n",
            "reward of step 20290 is: -0.000172262043337858\n",
            "reward of step 20291 is: -0.0001712512293917869\n",
            "reward of step 20292 is: -0.0001643463546261198\n",
            "reward of step 20293 is: -0.00016177555172033342\n",
            "reward of step 20294 is: -0.00016430775458556508\n",
            "reward of step 20295 is: -0.00016314399549367226\n",
            "reward of step 20296 is: -0.00017193569655251783\n",
            "reward of step 20297 is: -0.00016782952220206724\n",
            "reward of step 20298 is: -0.000173261231257176\n",
            "reward of step 20299 is: -0.0001644486215099531\n",
            "reward of step 20300 is: -0.00016264708252712357\n",
            "reward of step 20301 is: -0.00016060356383616417\n",
            "reward of step 20302 is: -0.00016690881971923624\n",
            "reward of step 20303 is: -0.0001634952810297005\n",
            "reward of step 20304 is: -0.0001721441095359627\n",
            "reward of step 20305 is: -0.00017497060713309506\n",
            "reward of step 20306 is: -0.0001669840092404673\n",
            "reward of step 20307 is: -0.00017827269187946243\n",
            "reward of step 20308 is: -0.00015702632630982394\n",
            "reward of step 20309 is: -0.0001671789373301268\n",
            "reward of step 20310 is: -0.0001596266187223325\n",
            "reward of step 20311 is: -0.00016168600458692494\n",
            "reward of step 20312 is: -0.00016485943364941258\n",
            "reward of step 20313 is: -0.0001566755381868316\n",
            "reward of step 20314 is: -0.0001702653596642585\n",
            "reward of step 20315 is: -0.00016283131164173168\n",
            "reward of step 20316 is: -0.00017453638405150385\n",
            "reward of step 20317 is: -0.00016493623199733844\n",
            "reward of step 20318 is: -0.00016493695546441678\n",
            "reward of step 20319 is: -0.0001656670708140554\n",
            "reward of step 20320 is: -0.00016947115736833614\n",
            "reward of step 20321 is: -0.00016410061378031165\n",
            "reward of step 20322 is: -0.00016022448660744365\n",
            "reward of step 20323 is: -0.00016028035928741845\n",
            "reward of step 20324 is: -0.0001655144652864086\n",
            "reward of step 20325 is: -0.00016606580364253193\n",
            "reward of step 20326 is: -0.0001592490768883797\n",
            "reward of step 20327 is: -0.0001746774018971186\n",
            "reward of step 20328 is: -0.00016486487450962506\n",
            "reward of step 20329 is: -0.00016322040224970563\n",
            "reward of step 20330 is: -0.00016535192121890972\n",
            "reward of step 20331 is: -0.0001698015840692109\n",
            "reward of step 20332 is: -0.00016598034179546057\n",
            "reward of step 20333 is: -0.00017206035264901232\n",
            "reward of step 20334 is: -0.00016484937121883706\n",
            "reward of step 20335 is: -0.00016339903073474266\n",
            "reward of step 20336 is: -0.0001629867504403356\n",
            "reward of step 20337 is: -0.00016818506787562816\n",
            "reward of step 20338 is: -0.0001624616601767019\n",
            "reward of step 20339 is: -0.00016565472465728196\n",
            "reward of step 20340 is: -0.00017239589321285995\n",
            "reward of step 20341 is: -0.00016071418857363458\n",
            "reward of step 20342 is: -0.00016566222349125788\n",
            "reward of step 20343 is: -0.00017148575688503027\n",
            "reward of step 20344 is: -0.00016320866135838762\n",
            "reward of step 20345 is: -0.00016443939718437624\n",
            "reward of step 20346 is: -0.00016154041072851194\n",
            "reward of step 20347 is: -0.00017286744270361796\n",
            "reward of step 20348 is: -0.00016513149871743335\n",
            "reward of step 20349 is: -0.00016544394508406784\n",
            "reward of step 20350 is: -0.0001686674182101742\n",
            "reward of step 20351 is: -0.00016148464557950662\n",
            "reward of step 20352 is: -0.00016918217846731342\n",
            "reward of step 20353 is: -0.00016347779148023452\n",
            "reward of step 20354 is: -0.00016274583828846344\n",
            "reward of step 20355 is: -0.00016687872029728067\n",
            "reward of step 20356 is: -0.00016215633417013018\n",
            "reward of step 20357 is: -0.0001626235704640058\n",
            "reward of step 20358 is: -0.00016919909114358395\n",
            "reward of step 20359 is: -0.00015595160534243532\n",
            "reward of step 20360 is: -0.0001654399239544895\n",
            "reward of step 20361 is: -0.00016083492137084024\n",
            "reward of step 20362 is: -0.00016406903854540732\n",
            "reward of step 20363 is: -0.0001616202296633052\n",
            "reward of step 20364 is: -0.00017537726872513036\n",
            "reward of step 20365 is: -0.00016549570450737563\n",
            "reward of step 20366 is: -0.00016856060715285775\n",
            "reward of step 20367 is: -0.00016072974613581258\n",
            "reward of step 20368 is: -0.00016836458210374805\n",
            "reward of step 20369 is: -0.00016682840317812798\n",
            "reward of step 20370 is: -0.0001726614365892759\n",
            "reward of step 20371 is: -0.00016741336693864369\n",
            "reward of step 20372 is: -0.00016354318039020686\n",
            "reward of step 20373 is: -0.00015881682982184198\n",
            "reward of step 20374 is: -0.00018005510007389956\n",
            "reward of step 20375 is: -0.00016518349729802075\n",
            "reward of step 20376 is: -0.00017496097690420412\n",
            "reward of step 20377 is: -0.00015844200219238024\n",
            "reward of step 20378 is: -0.00017054854272514666\n",
            "reward of step 20379 is: -0.000156159966153696\n",
            "reward of step 20380 is: -0.00015769019271300066\n",
            "reward of step 20381 is: -0.0001739318031117894\n",
            "reward of step 20382 is: -0.00016784767680500084\n",
            "reward of step 20383 is: -0.0001610455595914084\n",
            "reward of step 20384 is: -0.00017196635309789675\n",
            "reward of step 20385 is: -0.0001578474466641414\n",
            "reward of step 20386 is: -0.0001611997426549739\n",
            "reward of step 20387 is: -0.00017163887943774176\n",
            "reward of step 20388 is: -0.00016596313695418604\n",
            "reward of step 20389 is: -0.0001691352954531159\n",
            "reward of step 20390 is: -0.00016690099640860582\n",
            "reward of step 20391 is: -0.00017798078600908922\n",
            "reward of step 20392 is: -0.00016171655209041162\n",
            "reward of step 20393 is: -0.00016350875491949755\n",
            "reward of step 20394 is: -0.00016229703345096806\n",
            "reward of step 20395 is: -0.00015796628724892975\n",
            "reward of step 20396 is: -0.00016124868661131063\n",
            "reward of step 20397 is: -0.00016565272031083842\n",
            "reward of step 20398 is: -0.00015291687695702386\n",
            "reward of step 20399 is: -0.00017734608679993846\n",
            "reward of step 20400 is: -0.00015300759587614086\n",
            "reward of step 20401 is: -0.00017499115876921194\n",
            "reward of step 20402 is: -0.00016858287824437183\n",
            "reward of step 20403 is: -0.0001678081787857327\n",
            "reward of step 20404 is: -0.0001537115539574978\n",
            "reward of step 20405 is: -0.00016927399212623553\n",
            "reward of step 20406 is: -0.000164801465763779\n",
            "reward of step 20407 is: -0.00016465748081189523\n",
            "reward of step 20408 is: -0.00016369230794621855\n",
            "reward of step 20409 is: -0.0001651317823568249\n",
            "reward of step 20410 is: -0.00016218542699911702\n",
            "reward of step 20411 is: -0.0001649509098107467\n",
            "reward of step 20412 is: -0.0001564027125438329\n",
            "reward of step 20413 is: -0.00017468107777462316\n",
            "reward of step 20414 is: -0.0001691846639959562\n",
            "reward of step 20415 is: -0.00016123291867517955\n",
            "reward of step 20416 is: -0.00017026310319561826\n",
            "reward of step 20417 is: -0.00016244370388775848\n",
            "reward of step 20418 is: -0.00016566847720945349\n",
            "reward of step 20419 is: -0.00017151706625215008\n",
            "reward of step 20420 is: -0.000169352159198229\n",
            "reward of step 20421 is: -0.00016710629725339508\n",
            "reward of step 20422 is: -0.00016099046244557363\n",
            "reward of step 20423 is: -0.0001671972459007431\n",
            "reward of step 20424 is: -0.00016820986065353903\n",
            "reward of step 20425 is: -0.00016458600532333776\n",
            "reward of step 20426 is: -0.00017366384806491783\n",
            "reward of step 20427 is: -0.00017043268413694573\n",
            "reward of step 20428 is: -0.00016942208322500563\n",
            "reward of step 20429 is: -0.0001804573449419832\n",
            "reward of step 20430 is: -0.00016650144210003214\n",
            "reward of step 20431 is: -0.0001554622215149347\n",
            "reward of step 20432 is: -0.00017326462883155162\n",
            "reward of step 20433 is: -0.00015973105920947422\n",
            "reward of step 20434 is: -0.00016681367019732895\n",
            "reward of step 20435 is: -0.00016750122126213033\n",
            "reward of step 20436 is: -0.0001709541384148433\n",
            "reward of step 20437 is: -0.00016566970651141362\n",
            "reward of step 20438 is: -0.00015365959259967238\n",
            "reward of step 20439 is: -0.00016115198654738228\n",
            "reward of step 20440 is: -0.00016718679699001312\n",
            "reward of step 20441 is: -0.00015345321391856443\n",
            "reward of step 20442 is: -0.00017233902897518234\n",
            "reward of step 20443 is: -0.00015983887020946962\n",
            "reward of step 20444 is: -0.00017068974699669653\n",
            "reward of step 20445 is: -0.00017008776149940824\n",
            "reward of step 20446 is: -0.0001759224204396309\n",
            "reward of step 20447 is: -0.00015607324846534322\n",
            "reward of step 20448 is: -0.00016440875720224218\n",
            "reward of step 20449 is: -0.00015463851303658063\n",
            "reward of step 20450 is: -0.00017149047178918189\n",
            "reward of step 20451 is: -0.00017806673009800828\n",
            "reward of step 20452 is: -0.0001721175298184393\n",
            "reward of step 20453 is: -0.00016622044366377406\n",
            "reward of step 20454 is: -0.00016828003883333963\n",
            "reward of step 20455 is: -0.00016451746456000847\n",
            "reward of step 20456 is: -0.00016020610605569692\n",
            "reward of step 20457 is: -0.00016545389953076298\n",
            "reward of step 20458 is: -0.00015998976150857747\n",
            "reward of step 20459 is: -0.00016575614505156042\n",
            "reward of step 20460 is: -0.00016990842502395993\n",
            "reward of step 20461 is: -0.00016437570116307795\n",
            "reward of step 20462 is: -0.0001700043963749483\n",
            "reward of step 20463 is: -0.0001634598579691959\n",
            "reward of step 20464 is: -0.0001765435568436168\n",
            "reward of step 20465 is: -0.00017037530786089802\n",
            "reward of step 20466 is: -0.00015940252337006994\n",
            "reward of step 20467 is: -0.00015876401579908002\n",
            "reward of step 20468 is: -0.00016215269528628004\n",
            "reward of step 20469 is: -0.00017321966865664214\n",
            "reward of step 20470 is: -0.0001680127011673174\n",
            "reward of step 20471 is: -0.0001695294293881384\n",
            "reward of step 20472 is: -0.000167306468359484\n",
            "reward of step 20473 is: -0.00016675210196410387\n",
            "reward of step 20474 is: -0.00016511558751545964\n",
            "reward of step 20475 is: -0.00017059581201034208\n",
            "reward of step 20476 is: -0.0001722863681281928\n",
            "reward of step 20477 is: -0.0001688758090867699\n",
            "reward of step 20478 is: -0.0001661663707967264\n",
            "reward of step 20479 is: -0.0001663304360070365\n",
            "reward of step 20480 is: -0.0001602653242050166\n",
            "reward of step 20481 is: -0.00016859256798276319\n",
            "reward of step 20482 is: -0.0001549027199095357\n",
            "reward of step 20483 is: -0.0001610233325974317\n",
            "reward of step 20484 is: -0.00017399279022023534\n",
            "reward of step 20485 is: -0.00015987762680902106\n",
            "reward of step 20486 is: -0.00016230628758382134\n",
            "reward of step 20487 is: -0.00017238975768289327\n",
            "reward of step 20488 is: -0.00017015817758547845\n",
            "reward of step 20489 is: -0.00016803260069674935\n",
            "reward of step 20490 is: -0.00017950064314629357\n",
            "reward of step 20491 is: -0.0001704594286530848\n",
            "reward of step 20492 is: -0.00016407873262782907\n",
            "reward of step 20493 is: -0.00016575641423784496\n",
            "reward of step 20494 is: -0.00016102384124245327\n",
            "reward of step 20495 is: -0.0001740738471181551\n",
            "reward of step 20496 is: -0.00016782416085342057\n",
            "reward of step 20497 is: -0.0001674419643708165\n",
            "reward of step 20498 is: -0.000165107068289102\n",
            "reward of step 20499 is: -0.00017132107704864678\n",
            "reward of step 20500 is: -0.0001599266302983576\n",
            "reward of step 20501 is: -0.0001550285711352775\n",
            "reward of step 20502 is: -0.0001597740992349486\n",
            "reward of step 20503 is: -0.00015487260152563984\n",
            "reward of step 20504 is: -0.00016773443589954422\n",
            "reward of step 20505 is: -0.0001583802161098178\n",
            "reward of step 20506 is: -0.00016903541983553802\n",
            "reward of step 20507 is: -0.00017793388132432522\n",
            "reward of step 20508 is: -0.00017983606216457888\n",
            "reward of step 20509 is: -0.0001721287501894004\n",
            "reward of step 20510 is: -0.0001648293491862229\n",
            "reward of step 20511 is: -0.00016149237691467734\n",
            "reward of step 20512 is: -0.0001779845507948997\n",
            "reward of step 20513 is: -0.00016064081108520777\n",
            "reward of step 20514 is: -0.00016801096109713144\n",
            "reward of step 20515 is: -0.00016125373100851323\n",
            "reward of step 20516 is: -0.00016158697578258786\n",
            "reward of step 20517 is: -0.0001631943914356422\n",
            "reward of step 20518 is: -0.00016769916813882252\n",
            "reward of step 20519 is: -0.00015737798119654588\n",
            "reward of step 20520 is: -0.0001660017729355535\n",
            "reward of step 20521 is: -0.00016833302895487558\n",
            "reward of step 20522 is: -0.0001745201418580747\n",
            "reward of step 20523 is: -0.00017195283414323065\n",
            "reward of step 20524 is: -0.0001740065880196218\n",
            "reward of step 20525 is: -0.00015937488885811745\n",
            "reward of step 20526 is: -0.0001782610661393612\n",
            "reward of step 20527 is: -0.00017457843602847135\n",
            "reward of step 20528 is: -0.00016849376293037185\n",
            "reward of step 20529 is: -0.00017170172068683537\n",
            "reward of step 20530 is: -0.00015938030383313612\n",
            "reward of step 20531 is: -0.00017775544230671928\n",
            "reward of step 20532 is: -0.0001712878012749654\n",
            "reward of step 20533 is: -0.00016620431694600146\n",
            "reward of step 20534 is: -0.00016298409442039728\n",
            "reward of step 20535 is: -0.0001637817705149709\n",
            "reward of step 20536 is: -0.0001694536086983307\n",
            "reward of step 20537 is: -0.00017401747341339014\n",
            "reward of step 20538 is: -0.00016463224917689866\n",
            "reward of step 20539 is: -0.00015549961450926606\n",
            "reward of step 20540 is: -0.0001604180278473393\n",
            "reward of step 20541 is: -0.00015577084628876024\n",
            "reward of step 20542 is: -0.00016797010315920387\n",
            "reward of step 20543 is: -0.00017200431450583448\n",
            "reward of step 20544 is: -0.00016341047256331022\n",
            "reward of step 20545 is: -0.0001662966262884077\n",
            "reward of step 20546 is: -0.0001678443615014426\n",
            "reward of step 20547 is: -0.00017777477313954924\n",
            "reward of step 20548 is: -0.00016839404523499404\n",
            "reward of step 20549 is: -0.00016256862222137559\n",
            "reward of step 20550 is: -0.00016439141749977182\n",
            "reward of step 20551 is: -0.0001653398629764611\n",
            "reward of step 20552 is: -0.00016055480662569244\n",
            "reward of step 20553 is: -0.0001643508533984887\n",
            "reward of step 20554 is: -0.00015821258397136903\n",
            "reward of step 20555 is: -0.00016328621286816082\n",
            "reward of step 20556 is: -0.0001699497404385971\n",
            "reward of step 20557 is: -0.00015444635787977476\n",
            "reward of step 20558 is: -0.00016023850491610312\n",
            "reward of step 20559 is: -0.00016576731362474216\n",
            "reward of step 20560 is: -0.00017771853658532966\n",
            "reward of step 20561 is: -0.00017530434308253687\n",
            "reward of step 20562 is: -0.0001738240714312497\n",
            "reward of step 20563 is: -0.00017274460492129327\n",
            "reward of step 20564 is: -0.00016099847392336326\n",
            "reward of step 20565 is: -0.00016795751075564247\n",
            "reward of step 20566 is: -0.0001629710637909395\n",
            "reward of step 20567 is: -0.00017147365912234953\n",
            "reward of step 20568 is: -0.00015828043472754903\n",
            "reward of step 20569 is: -0.00016118691053755528\n",
            "reward of step 20570 is: -0.00016242419240131687\n",
            "reward of step 20571 is: -0.0001665420071018019\n",
            "reward of step 20572 is: -0.00016040393811114263\n",
            "reward of step 20573 is: -0.00015598214476047933\n",
            "reward of step 20574 is: -0.00016909080910547063\n",
            "reward of step 20575 is: -0.00016975047853294852\n",
            "reward of step 20576 is: -0.00016838879196035602\n",
            "reward of step 20577 is: -0.00016755237647069502\n",
            "reward of step 20578 is: -0.00017530159572482108\n",
            "reward of step 20579 is: -0.0001725732232086517\n",
            "reward of step 20580 is: -0.00016031111251209646\n",
            "reward of step 20581 is: -0.00017136687579753155\n",
            "reward of step 20582 is: -0.00016457656970517127\n",
            "reward of step 20583 is: -0.0001750912005112958\n",
            "reward of step 20584 is: -0.00016510864498841139\n",
            "reward of step 20585 is: -0.00016257551431886601\n",
            "reward of step 20586 is: -0.0001735810738907853\n",
            "reward of step 20587 is: -0.0001595828168537924\n",
            "reward of step 20588 is: -0.0001641810653800712\n",
            "reward of step 20589 is: -0.00016593490397780826\n",
            "reward of step 20590 is: -0.0001581552182796816\n",
            "reward of step 20591 is: -0.00016816024470179666\n",
            "reward of step 20592 is: -0.00016826271140350755\n",
            "reward of step 20593 is: -0.0001738396903894155\n",
            "reward of step 20594 is: -0.00016660186359262745\n",
            "reward of step 20595 is: -0.00016535196649399012\n",
            "reward of step 20596 is: -0.00016687685980434496\n",
            "reward of step 20597 is: -0.0001652007215414257\n",
            "reward of step 20598 is: -0.00017198363552051624\n",
            "reward of step 20599 is: -0.00016125590909909766\n",
            "reward of step 20600 is: -0.00017023686720123372\n",
            "reward of step 20601 is: -0.00016446095318452454\n",
            "reward of step 20602 is: -0.0001766910145856532\n",
            "reward of step 20603 is: -0.0001606302015836585\n",
            "reward of step 20604 is: -0.0001570131476827658\n",
            "reward of step 20605 is: -0.000170032235916323\n",
            "reward of step 20606 is: -0.00016833341611962425\n",
            "reward of step 20607 is: -0.00017406335604260554\n",
            "reward of step 20608 is: -0.0001667300987324734\n",
            "reward of step 20609 is: -0.00016735519007769463\n",
            "reward of step 20610 is: -0.00015951701117195222\n",
            "reward of step 20611 is: -0.00017678728552642217\n",
            "reward of step 20612 is: -0.00015954550115352152\n",
            "reward of step 20613 is: -0.000172885932692481\n",
            "reward of step 20614 is: -0.00016526747879421936\n",
            "reward of step 20615 is: -0.0001556615480043311\n",
            "reward of step 20616 is: -0.00016777205476066584\n",
            "reward of step 20617 is: -0.00016600198210953835\n",
            "reward of step 20618 is: -0.0001725735434303533\n",
            "reward of step 20619 is: -0.00016458775914910938\n",
            "reward of step 20620 is: -0.00016915464818389518\n",
            "reward of step 20621 is: -0.00015733897748146687\n",
            "reward of step 20622 is: -0.0001707703633118941\n",
            "reward of step 20623 is: -0.000157378995323131\n",
            "reward of step 20624 is: -0.00015952593920507972\n",
            "reward of step 20625 is: -0.0001684201157791421\n",
            "reward of step 20626 is: -0.00017344054875743106\n",
            "reward of step 20627 is: -0.00016519168956081394\n",
            "reward of step 20628 is: -0.0001653899446592401\n",
            "reward of step 20629 is: -0.0001531183767060181\n",
            "reward of step 20630 is: -0.00016304020853546256\n",
            "reward of step 20631 is: -0.0001691001768576392\n",
            "reward of step 20632 is: -0.00017654648320104352\n",
            "reward of step 20633 is: -0.00016585368538582547\n",
            "reward of step 20634 is: -0.0001693742962941233\n",
            "reward of step 20635 is: -0.00016492475429120526\n",
            "reward of step 20636 is: -0.00016306505428948645\n",
            "reward of step 20637 is: -0.00017150798657495638\n",
            "reward of step 20638 is: -0.00017316537984091407\n",
            "reward of step 20639 is: -0.00016685488259666844\n",
            "reward of step 20640 is: -0.00016888838256469445\n",
            "reward of step 20641 is: -0.00016494968078327845\n",
            "reward of step 20642 is: -0.00016372407679364902\n",
            "reward of step 20643 is: -0.00017049657428865484\n",
            "reward of step 20644 is: -0.00016797005869903747\n",
            "reward of step 20645 is: -0.00015531318719990482\n",
            "reward of step 20646 is: -0.0001576796188753879\n",
            "reward of step 20647 is: -0.00015892921813149505\n",
            "reward of step 20648 is: -0.00015544676638019442\n",
            "reward of step 20649 is: -0.00017385512805462476\n",
            "reward of step 20650 is: -0.00016655561027136456\n",
            "reward of step 20651 is: -0.0001646137898119587\n",
            "reward of step 20652 is: -0.00017322741691030576\n",
            "reward of step 20653 is: -0.00016116173871909978\n",
            "reward of step 20654 is: -0.00016230432268467273\n",
            "reward of step 20655 is: -0.00016456091494331627\n",
            "reward of step 20656 is: -0.00015770609714016996\n",
            "reward of step 20657 is: -0.0001766670747953417\n",
            "reward of step 20658 is: -0.000164170701358229\n",
            "reward of step 20659 is: -0.00017669267479323447\n",
            "reward of step 20660 is: -0.0001528331905207081\n",
            "reward of step 20661 is: -0.00016925304716942132\n",
            "reward of step 20662 is: -0.00015592682955315514\n",
            "reward of step 20663 is: -0.00016316791793944888\n",
            "reward of step 20664 is: -0.0001670969248576082\n",
            "reward of step 20665 is: -0.0001732846695457815\n",
            "reward of step 20666 is: -0.00016716081960163465\n",
            "reward of step 20667 is: -0.0001703405791941337\n",
            "reward of step 20668 is: -0.00016406401568968564\n",
            "reward of step 20669 is: -0.0001690329204010533\n",
            "reward of step 20670 is: -0.00017506669612977273\n",
            "reward of step 20671 is: -0.00016871789343886153\n",
            "reward of step 20672 is: -0.00017967547707901777\n",
            "reward of step 20673 is: -0.00016859164164014575\n",
            "reward of step 20674 is: -0.00016608906175614535\n",
            "reward of step 20675 is: -0.00017620395015733516\n",
            "reward of step 20676 is: -0.0001612990541427321\n",
            "reward of step 20677 is: -0.00017001280427151962\n",
            "reward of step 20678 is: -0.00017642819125054924\n",
            "reward of step 20679 is: -0.00015965960434872242\n",
            "reward of step 20680 is: -0.00016544577522086153\n",
            "reward of step 20681 is: -0.00017138109628814585\n",
            "reward of step 20682 is: -0.00016603158536497573\n",
            "reward of step 20683 is: -0.00017099758566977084\n",
            "reward of step 20684 is: -0.00017188194147460653\n",
            "reward of step 20685 is: -0.00016639106050578905\n",
            "reward of step 20686 is: -0.00015790506777588252\n",
            "reward of step 20687 is: -0.00017313318574191605\n",
            "reward of step 20688 is: -0.00016847391816146253\n",
            "reward of step 20689 is: -0.0001600890275265963\n",
            "reward of step 20690 is: -0.00016161499080874747\n",
            "reward of step 20691 is: -0.00017193954630460067\n",
            "reward of step 20692 is: -0.0001746721290094629\n",
            "reward of step 20693 is: -0.00016602112875595482\n",
            "reward of step 20694 is: -0.00016621893412527652\n",
            "reward of step 20695 is: -0.00016005185480921357\n",
            "reward of step 20696 is: -0.00016880424917555426\n",
            "reward of step 20697 is: -0.00016635753019659367\n",
            "reward of step 20698 is: -0.00015680519886022607\n",
            "reward of step 20699 is: -0.00016066816539699763\n",
            "reward of step 20700 is: -0.00016118755669188955\n",
            "reward of step 20701 is: -0.00017070060384936358\n",
            "reward of step 20702 is: -0.00016794439699158536\n",
            "reward of step 20703 is: -0.00016236968487051532\n",
            "reward of step 20704 is: -0.00017291461078108544\n",
            "reward of step 20705 is: -0.00016773402695963334\n",
            "reward of step 20706 is: -0.0001726061045629537\n",
            "reward of step 20707 is: -0.0001654333788940055\n",
            "reward of step 20708 is: -0.0001667059044437256\n",
            "reward of step 20709 is: -0.00016691109673750836\n",
            "reward of step 20710 is: -0.00016266052028168963\n",
            "reward of step 20711 is: -0.00016350400228377072\n",
            "reward of step 20712 is: -0.00016759648201958657\n",
            "reward of step 20713 is: -0.00016754271135274596\n",
            "reward of step 20714 is: -0.00015690827062778885\n",
            "reward of step 20715 is: -0.00016790638775453164\n",
            "reward of step 20716 is: -0.00015548186494389384\n",
            "reward of step 20717 is: -0.00016612558805269276\n",
            "reward of step 20718 is: -0.00016961162383363805\n",
            "reward of step 20719 is: -0.00017490125087174963\n",
            "reward of step 20720 is: -0.00016311739832585595\n",
            "reward of step 20721 is: -0.00016137231322760565\n",
            "reward of step 20722 is: -0.0001519373219807038\n",
            "reward of step 20723 is: -0.00017343542065249094\n",
            "reward of step 20724 is: -0.00016806980196247453\n",
            "reward of step 20725 is: -0.0001642093476657084\n",
            "reward of step 20726 is: -0.00016734739406044756\n",
            "reward of step 20727 is: -0.00016461599160079454\n",
            "reward of step 20728 is: -0.00016906708828249857\n",
            "reward of step 20729 is: -0.00015649528372303051\n",
            "reward of step 20730 is: -0.00017495261365048652\n",
            "reward of step 20731 is: -0.0001644409648791512\n",
            "reward of step 20732 is: -0.0001605598456173782\n",
            "reward of step 20733 is: -0.0001711273866045881\n",
            "reward of step 20734 is: -0.0001629770130806937\n",
            "reward of step 20735 is: -0.0001702124126831584\n",
            "reward of step 20736 is: -0.00016752376360875196\n",
            "reward of step 20737 is: -0.0001546665165131687\n",
            "reward of step 20738 is: -0.00016860211082244173\n",
            "reward of step 20739 is: -0.00017126763134868932\n",
            "reward of step 20740 is: -0.00017047353072985493\n",
            "reward of step 20741 is: -0.00017087101601943153\n",
            "reward of step 20742 is: -0.0001651543869130163\n",
            "reward of step 20743 is: -0.0001604082022089995\n",
            "reward of step 20744 is: -0.00016080917233705314\n",
            "reward of step 20745 is: -0.00015958254109589104\n",
            "reward of step 20746 is: -0.00017681077745950615\n",
            "reward of step 20747 is: -0.0001723652458379399\n",
            "reward of step 20748 is: -0.00017365981020633624\n",
            "reward of step 20749 is: -0.00017312061833450444\n",
            "reward of step 20750 is: -0.00017503305535164309\n",
            "reward of step 20751 is: -0.00016691689442825772\n",
            "reward of step 20752 is: -0.00015721425540831668\n",
            "reward of step 20753 is: -0.00016190373366149765\n",
            "reward of step 20754 is: -0.00016525541629517618\n",
            "reward of step 20755 is: -0.00016886597761865484\n",
            "reward of step 20756 is: -0.00016168800700850912\n",
            "reward of step 20757 is: -0.0001742344095174308\n",
            "reward of step 20758 is: -0.00016803668584362233\n",
            "reward of step 20759 is: -0.00016180622295285094\n",
            "reward of step 20760 is: -0.00016919772853455487\n",
            "reward of step 20761 is: -0.00017339074340375424\n",
            "reward of step 20762 is: -0.00017937138683522713\n",
            "reward of step 20763 is: -0.0001552495491407481\n",
            "reward of step 20764 is: -0.00016538760841874986\n",
            "reward of step 20765 is: -0.0001601509979044729\n",
            "reward of step 20766 is: -0.00016640591185223107\n",
            "reward of step 20767 is: -0.00016681509413943307\n",
            "reward of step 20768 is: -0.00016475300317107675\n",
            "reward of step 20769 is: -0.00015939430019134857\n",
            "reward of step 20770 is: -0.00015259643408443584\n",
            "reward of step 20771 is: -0.00016072228703425823\n",
            "reward of step 20772 is: -0.0001564319464916351\n",
            "reward of step 20773 is: -0.00017105549061299964\n",
            "reward of step 20774 is: -0.0001710468503790776\n",
            "reward of step 20775 is: -0.00016211213468892048\n",
            "reward of step 20776 is: -0.0001685205382697955\n",
            "reward of step 20777 is: -0.00017225808485246924\n",
            "reward of step 20778 is: -0.00016628295351817457\n",
            "reward of step 20779 is: -0.00015697669352511087\n",
            "reward of step 20780 is: -0.00015612473692906294\n",
            "reward of step 20781 is: -0.00016089656161962204\n",
            "reward of step 20782 is: -0.00016226109755552282\n",
            "reward of step 20783 is: -0.00015984412527568958\n",
            "reward of step 20784 is: -0.0001748288034936504\n",
            "reward of step 20785 is: -0.00016532614483447418\n",
            "reward of step 20786 is: -0.0001707791728905178\n",
            "reward of step 20787 is: -0.0001607303517859279\n",
            "reward of step 20788 is: -0.00016048244356500256\n",
            "reward of step 20789 is: -0.00016681909613378294\n",
            "reward of step 20790 is: -0.00017046883855600166\n",
            "reward of step 20791 is: -0.00016330407539283208\n",
            "reward of step 20792 is: -0.00017608223918115832\n",
            "reward of step 20793 is: -0.0001643059257839695\n",
            "reward of step 20794 is: -0.00017674271036998256\n",
            "reward of step 20795 is: -0.00016222342456769577\n",
            "reward of step 20796 is: -0.00018031647769220537\n",
            "reward of step 20797 is: -0.0001707472918018441\n",
            "reward of step 20798 is: -0.00016162432945097564\n",
            "reward of step 20799 is: -0.00016584115981137576\n",
            "reward of step 20800 is: -0.00016630380310697548\n",
            "reward of step 20801 is: -0.00016400767548759265\n",
            "reward of step 20802 is: -0.00016606864574138867\n",
            "reward of step 20803 is: -0.0001720874762649119\n",
            "reward of step 20804 is: -0.00016547821402427304\n",
            "reward of step 20805 is: -0.00016837688052855724\n",
            "reward of step 20806 is: -0.00017697024539327353\n",
            "reward of step 20807 is: -0.00015914376190631185\n",
            "reward of step 20808 is: -0.00017321785777443132\n",
            "reward of step 20809 is: -0.00017149602054587244\n",
            "reward of step 20810 is: -0.0001645613493732963\n",
            "reward of step 20811 is: -0.0001527506394085078\n",
            "reward of step 20812 is: -0.00016294807363740295\n",
            "reward of step 20813 is: -0.0001632717548198195\n",
            "reward of step 20814 is: -0.00017602536008366746\n",
            "reward of step 20815 is: -0.0001646014998935001\n",
            "reward of step 20816 is: -0.00015813755385611926\n",
            "reward of step 20817 is: -0.0001736635911407745\n",
            "reward of step 20818 is: -0.00017468292747403467\n",
            "reward of step 20819 is: -0.0001711895653496753\n",
            "reward of step 20820 is: -0.00016094891978535005\n",
            "reward of step 20821 is: -0.00015797776049841778\n",
            "reward of step 20822 is: -0.00016952799934075147\n",
            "reward of step 20823 is: -0.00016496750903602692\n",
            "reward of step 20824 is: -0.0001693621264783101\n",
            "reward of step 20825 is: -0.00016871384550301257\n",
            "reward of step 20826 is: -0.00015414916381037305\n",
            "reward of step 20827 is: -0.0001651765315749538\n",
            "reward of step 20828 is: -0.00016993323193758978\n",
            "reward of step 20829 is: -0.00015799329980289902\n",
            "reward of step 20830 is: -0.00017258225621183954\n",
            "reward of step 20831 is: -0.0001598032620144092\n",
            "reward of step 20832 is: -0.00017276690993840433\n",
            "reward of step 20833 is: -0.00017453422067639047\n",
            "reward of step 20834 is: -0.00017784313558706137\n",
            "reward of step 20835 is: -0.0001629999147906965\n",
            "reward of step 20836 is: -0.00016407102139620274\n",
            "reward of step 20837 is: -0.00017279546431337212\n",
            "reward of step 20838 is: -0.00016660435697909339\n",
            "reward of step 20839 is: -0.00017627337485755213\n",
            "reward of step 20840 is: -0.00017316825525907944\n",
            "reward of step 20841 is: -0.00016095073881073577\n",
            "reward of step 20842 is: -0.00017656302832147673\n",
            "reward of step 20843 is: -0.00016627930464009825\n",
            "reward of step 20844 is: -0.00017597117469753237\n",
            "reward of step 20845 is: -0.00017422537680567425\n",
            "reward of step 20846 is: -0.00016661780541339142\n",
            "reward of step 20847 is: -0.00016086962330213788\n",
            "reward of step 20848 is: -0.0001561722507966477\n",
            "reward of step 20849 is: -0.00016016312956158003\n",
            "reward of step 20850 is: -0.00016520288520594198\n",
            "reward of step 20851 is: -0.00016440966810946987\n",
            "reward of step 20852 is: -0.00017309070231845536\n",
            "reward of step 20853 is: -0.00017770552890666912\n",
            "reward of step 20854 is: -0.00017212832254811782\n",
            "reward of step 20855 is: -0.00016135174204684601\n",
            "reward of step 20856 is: -0.00016418588361376168\n",
            "reward of step 20857 is: -0.00015969180950072554\n",
            "reward of step 20858 is: -0.0001590528525812957\n",
            "reward of step 20859 is: -0.0001650492589818885\n",
            "reward of step 20860 is: -0.00016074590596333685\n",
            "reward of step 20861 is: -0.0001723535666282458\n",
            "reward of step 20862 is: -0.00016682874167603322\n",
            "reward of step 20863 is: -0.00016203171181979585\n",
            "reward of step 20864 is: -0.0001600304546095879\n",
            "reward of step 20865 is: -0.00016895451711947625\n",
            "reward of step 20866 is: -0.0001644315822369407\n",
            "reward of step 20867 is: -0.00016487414292148128\n",
            "reward of step 20868 is: -0.00016760651101766386\n",
            "reward of step 20869 is: -0.0001605625239418762\n",
            "reward of step 20870 is: -0.0001651890820934353\n",
            "reward of step 20871 is: -0.00016482387660729302\n",
            "reward of step 20872 is: -0.0001638931084649776\n",
            "reward of step 20873 is: -0.00016824072752251036\n",
            "reward of step 20874 is: -0.00016978600406219186\n",
            "reward of step 20875 is: -0.00016095164368467988\n",
            "reward of step 20876 is: -0.00016710206214457586\n",
            "reward of step 20877 is: -0.00016697460074093762\n",
            "reward of step 20878 is: -0.0001645566068771565\n",
            "reward of step 20879 is: -0.00015617735056364598\n",
            "reward of step 20880 is: -0.00017141576325067852\n",
            "reward of step 20881 is: -0.0001599648984067879\n",
            "reward of step 20882 is: -0.00016144871230418419\n",
            "reward of step 20883 is: -0.00016799813162641657\n",
            "reward of step 20884 is: -0.00016925434275593413\n",
            "reward of step 20885 is: -0.00016471190974515307\n",
            "reward of step 20886 is: -0.00016725034692474937\n",
            "reward of step 20887 is: -0.0001717652023172718\n",
            "reward of step 20888 is: -0.00017659185937518967\n",
            "reward of step 20889 is: -0.0001648376677924998\n",
            "reward of step 20890 is: -0.00015784438304262927\n",
            "reward of step 20891 is: -0.0001620576458996319\n",
            "reward of step 20892 is: -0.0001572641571374375\n",
            "reward of step 20893 is: -0.00017660301849568199\n",
            "reward of step 20894 is: -0.00017661767151857472\n",
            "reward of step 20895 is: -0.00017904511940031233\n",
            "reward of step 20896 is: -0.00017282424248404936\n",
            "reward of step 20897 is: -0.00015359995849403762\n",
            "reward of step 20898 is: -0.00017331117417060236\n",
            "reward of step 20899 is: -0.0001658883731765084\n",
            "reward of step 20900 is: -0.00016788859871093116\n",
            "reward of step 20901 is: -0.00016971085832304656\n",
            "reward of step 20902 is: -0.00016409598115838594\n",
            "reward of step 20903 is: -0.000175171743571546\n",
            "reward of step 20904 is: -0.0001660481582230908\n",
            "reward of step 20905 is: -0.00016436919775745062\n",
            "reward of step 20906 is: -0.0001644566347601066\n",
            "reward of step 20907 is: -0.00016773262707374655\n",
            "reward of step 20908 is: -0.0001648927337762012\n",
            "reward of step 20909 is: -0.0001696787325488734\n",
            "reward of step 20910 is: -0.0001714667392971192\n",
            "reward of step 20911 is: -0.00016625685629426937\n",
            "reward of step 20912 is: -0.00017967844890220806\n",
            "reward of step 20913 is: -0.0001643517079440625\n",
            "reward of step 20914 is: -0.00015874548347985192\n",
            "reward of step 20915 is: -0.00017537554389278153\n",
            "reward of step 20916 is: -0.00015469946848239316\n",
            "reward of step 20917 is: -0.00016692728421628363\n",
            "reward of step 20918 is: -0.0001766834023731965\n",
            "reward of step 20919 is: -0.0001605282648577387\n",
            "reward of step 20920 is: -0.00016312230483401862\n",
            "reward of step 20921 is: -0.0001741706821164503\n",
            "reward of step 20922 is: -0.00015734322296519077\n",
            "reward of step 20923 is: -0.0001560392886923887\n",
            "reward of step 20924 is: -0.0001787739046692373\n",
            "reward of step 20925 is: -0.0001598713251222936\n",
            "reward of step 20926 is: -0.00015617831186469342\n",
            "reward of step 20927 is: -0.00016685458723359676\n",
            "reward of step 20928 is: -0.00016507583632659504\n",
            "reward of step 20929 is: -0.00016112521432962872\n",
            "reward of step 20930 is: -0.0001628352967170933\n",
            "reward of step 20931 is: -0.00016628576000950635\n",
            "reward of step 20932 is: -0.00016636894740467293\n",
            "reward of step 20933 is: -0.0001635275393826767\n",
            "reward of step 20934 is: -0.00016184187484977744\n",
            "reward of step 20935 is: -0.00016591553826247538\n",
            "reward of step 20936 is: -0.00017671662671290073\n",
            "reward of step 20937 is: -0.0001633273857816385\n",
            "reward of step 20938 is: -0.00015774166953779243\n",
            "reward of step 20939 is: -0.00016157986253006158\n",
            "reward of step 20940 is: -0.0001671500181163163\n",
            "reward of step 20941 is: -0.00016773529730729696\n",
            "reward of step 20942 is: -0.0001598614178951161\n",
            "reward of step 20943 is: -0.00017725030507448157\n",
            "reward of step 20944 is: -0.00017476337288053624\n",
            "reward of step 20945 is: -0.0001574067911194006\n",
            "reward of step 20946 is: -0.00017734753228675922\n",
            "reward of step 20947 is: -0.00015988538368214166\n",
            "reward of step 20948 is: -0.00016973614097036069\n",
            "reward of step 20949 is: -0.00018002646039197925\n",
            "reward of step 20950 is: -0.00016468210920663785\n",
            "reward of step 20951 is: -0.0001561955620515555\n",
            "reward of step 20952 is: -0.00016525926297392195\n",
            "reward of step 20953 is: -0.0001771652793052916\n",
            "reward of step 20954 is: -0.00015443634875285817\n",
            "reward of step 20955 is: -0.00016659785863714968\n",
            "reward of step 20956 is: -0.00016432246093659272\n",
            "reward of step 20957 is: -0.00017156054666188258\n",
            "reward of step 20958 is: -0.00016312411888379054\n",
            "reward of step 20959 is: -0.0001662089215629637\n",
            "reward of step 20960 is: -0.0001692614332003561\n",
            "reward of step 20961 is: -0.00016201303648639585\n",
            "reward of step 20962 is: -0.00017208404139767392\n",
            "reward of step 20963 is: -0.00016750569053558754\n",
            "reward of step 20964 is: -0.0001664081365273565\n",
            "reward of step 20965 is: -0.0001543792740170338\n",
            "reward of step 20966 is: -0.00015681778676629248\n",
            "reward of step 20967 is: -0.00015152790597003704\n",
            "reward of step 20968 is: -0.00016635199390184754\n",
            "reward of step 20969 is: -0.00016556320913859235\n",
            "reward of step 20970 is: -0.0001648991379152248\n",
            "reward of step 20971 is: -0.0001772180203334067\n",
            "reward of step 20972 is: -0.00016524487306007093\n",
            "reward of step 20973 is: -0.00017452137452770918\n",
            "reward of step 20974 is: -0.00015894679137774324\n",
            "reward of step 20975 is: -0.0001704330657132614\n",
            "reward of step 20976 is: -0.00015808398866075837\n",
            "reward of step 20977 is: -0.0001627673363904373\n",
            "reward of step 20978 is: -0.0001666832908240052\n",
            "reward of step 20979 is: -0.0001609237067938722\n",
            "reward of step 20980 is: -0.00017334065662755017\n",
            "reward of step 20981 is: -0.0001520738121349761\n",
            "reward of step 20982 is: -0.00016911788551577265\n",
            "reward of step 20983 is: -0.0001646109243598327\n",
            "reward of step 20984 is: -0.0001623608957033563\n",
            "reward of step 20985 is: -0.00017932209971663823\n",
            "reward of step 20986 is: -0.00015790196223857946\n",
            "reward of step 20987 is: -0.0001699977086452937\n",
            "reward of step 20988 is: -0.00016692571745733994\n",
            "reward of step 20989 is: -0.0001781989496424521\n",
            "reward of step 20990 is: -0.00015685267604507303\n",
            "reward of step 20991 is: -0.0001574595749795269\n",
            "reward of step 20992 is: -0.00016447362637724065\n",
            "reward of step 20993 is: -0.00017315617221983417\n",
            "reward of step 20994 is: -0.0001658667482681696\n",
            "reward of step 20995 is: -0.00016319945002830924\n",
            "reward of step 20996 is: -0.00017187772719767195\n",
            "reward of step 20997 is: -0.0001724246628485408\n",
            "reward of step 20998 is: -0.00015668321704908808\n",
            "reward of step 20999 is: -0.0001645061201532212\n",
            "reward of step 21000 is: -0.0001571802577321493\n",
            "reward of step 21001 is: -0.00016818546643091882\n",
            "reward of step 21002 is: -0.00016519172183801148\n",
            "reward of step 21003 is: -0.000175855662400719\n",
            "reward of step 21004 is: -0.00016125643770743467\n",
            "reward of step 21005 is: -0.00016251067077973044\n",
            "reward of step 21006 is: -0.00016244080012181296\n",
            "reward of step 21007 is: -0.00016648193475162152\n",
            "reward of step 21008 is: -0.00017281592642562498\n",
            "reward of step 21009 is: -0.0001662118925895482\n",
            "reward of step 21010 is: -0.00015597749799916425\n",
            "reward of step 21011 is: -0.0001720772764416203\n",
            "reward of step 21012 is: -0.00016772418277775513\n",
            "reward of step 21013 is: -0.0001687764550737716\n",
            "reward of step 21014 is: -0.0001625420049014399\n",
            "reward of step 21015 is: -0.0001686866002901888\n",
            "reward of step 21016 is: -0.0001594749523256807\n",
            "reward of step 21017 is: -0.00016645251335384528\n",
            "reward of step 21018 is: -0.0001657389414236239\n",
            "reward of step 21019 is: -0.00017169726830165602\n",
            "reward of step 21020 is: -0.00016325130734679897\n",
            "reward of step 21021 is: -0.00017120976689992444\n",
            "reward of step 21022 is: -0.00016156181230088336\n",
            "reward of step 21023 is: -0.0001654568687696151\n",
            "reward of step 21024 is: -0.0001682284279872458\n",
            "reward of step 21025 is: -0.00017213639466686145\n",
            "reward of step 21026 is: -0.00016269541643132432\n",
            "reward of step 21027 is: -0.0001571566230163662\n",
            "reward of step 21028 is: -0.0001712730158042985\n",
            "reward of step 21029 is: -0.0001677401130192693\n",
            "reward of step 21030 is: -0.00016013731436524074\n",
            "reward of step 21031 is: -0.0001718226712454069\n",
            "reward of step 21032 is: -0.00016445066510675045\n",
            "reward of step 21033 is: -0.0001715298810289483\n",
            "reward of step 21034 is: -0.00015648304811137706\n",
            "reward of step 21035 is: -0.00017120931460605488\n",
            "reward of step 21036 is: -0.00015575623523774793\n",
            "reward of step 21037 is: -0.00016872481583191085\n",
            "reward of step 21038 is: -0.00017129104418674452\n",
            "reward of step 21039 is: -0.00017635592830299562\n",
            "reward of step 21040 is: -0.00017281664097326284\n",
            "reward of step 21041 is: -0.00016666282964888292\n",
            "reward of step 21042 is: -0.00017124308735132248\n",
            "reward of step 21043 is: -0.0001709035166058988\n",
            "reward of step 21044 is: -0.0001683015555780584\n",
            "reward of step 21045 is: -0.00016649510214527058\n",
            "reward of step 21046 is: -0.00016314101382180278\n",
            "reward of step 21047 is: -0.00016481055084898447\n",
            "reward of step 21048 is: -0.00016886785247682533\n",
            "reward of step 21049 is: -0.00016548198430799179\n",
            "reward of step 21050 is: -0.00016458602821604494\n",
            "reward of step 21051 is: -0.0001672820668550085\n",
            "reward of step 21052 is: -0.00016608857520248097\n",
            "reward of step 21053 is: -0.00017273092341501688\n",
            "reward of step 21054 is: -0.00016100001278147207\n",
            "reward of step 21055 is: -0.00015902980773334138\n",
            "reward of step 21056 is: -0.00016855654443892267\n",
            "reward of step 21057 is: -0.00015826326113495273\n",
            "reward of step 21058 is: -0.0001691476957487713\n",
            "reward of step 21059 is: -0.0001635890932523812\n",
            "reward of step 21060 is: -0.00016609864430820392\n",
            "reward of step 21061 is: -0.00016050436868950734\n",
            "reward of step 21062 is: -0.0001658716898419506\n",
            "reward of step 21063 is: -0.00016399820329261606\n",
            "reward of step 21064 is: -0.0001688945162591591\n",
            "reward of step 21065 is: -0.00016310369946222463\n",
            "reward of step 21066 is: -0.00016521991732555897\n",
            "reward of step 21067 is: -0.00016709407999685496\n",
            "reward of step 21068 is: -0.00016300610162252828\n",
            "reward of step 21069 is: -0.00017411565489603483\n",
            "reward of step 21070 is: -0.00016340336860469135\n",
            "reward of step 21071 is: -0.00016675732492875053\n",
            "reward of step 21072 is: -0.00016466276855297565\n",
            "reward of step 21073 is: -0.00017573070375570608\n",
            "reward of step 21074 is: -0.00016538531902974776\n",
            "reward of step 21075 is: -0.00016331741025254543\n",
            "reward of step 21076 is: -0.00016249315623967679\n",
            "reward of step 21077 is: -0.00017129760124131988\n",
            "reward of step 21078 is: -0.0001643338149551907\n",
            "reward of step 21079 is: -0.00016973811731521\n",
            "reward of step 21080 is: -0.0001687068217816347\n",
            "reward of step 21081 is: -0.00016579137751772285\n",
            "reward of step 21082 is: -0.0001744803239203183\n",
            "reward of step 21083 is: -0.0001660202735057929\n",
            "reward of step 21084 is: -0.00016826830268697882\n",
            "reward of step 21085 is: -0.00016577941203701143\n",
            "reward of step 21086 is: -0.00015653200708183422\n",
            "reward of step 21087 is: -0.00017227221513036996\n",
            "reward of step 21088 is: -0.0001654821520596188\n",
            "reward of step 21089 is: -0.0001569615871203501\n",
            "reward of step 21090 is: -0.0001533252330119715\n",
            "reward of step 21091 is: -0.00016879832003329224\n",
            "reward of step 21092 is: -0.00015971833463146118\n",
            "reward of step 21093 is: -0.00016846036133122682\n",
            "reward of step 21094 is: -0.00016130859638166853\n",
            "reward of step 21095 is: -0.000164531461306317\n",
            "reward of step 21096 is: -0.00016376498294777333\n",
            "reward of step 21097 is: -0.0001595068108804118\n",
            "reward of step 21098 is: -0.00016496661738933435\n",
            "reward of step 21099 is: -0.00015987160548214133\n",
            "reward of step 21100 is: -0.00016898623361186963\n",
            "reward of step 21101 is: -0.0001689190670322252\n",
            "reward of step 21102 is: -0.00016763527602439037\n",
            "reward of step 21103 is: -0.00016703424172214638\n",
            "reward of step 21104 is: -0.0001715470789764093\n",
            "reward of step 21105 is: -0.0001649626028150657\n",
            "reward of step 21106 is: -0.00016592473416689153\n",
            "reward of step 21107 is: -0.00017320214987271752\n",
            "reward of step 21108 is: -0.0001684568193721273\n",
            "reward of step 21109 is: -0.0001716639931660017\n",
            "reward of step 21110 is: -0.00016756441923544813\n",
            "reward of step 21111 is: -0.00016398835256803423\n",
            "reward of step 21112 is: -0.00016400697949150374\n",
            "reward of step 21113 is: -0.00016256476296032523\n",
            "reward of step 21114 is: -0.0001659827815106551\n",
            "reward of step 21115 is: -0.00017948779019422116\n",
            "reward of step 21116 is: -0.000172088072529031\n",
            "reward of step 21117 is: -0.00015605004195232424\n",
            "reward of step 21118 is: -0.00017430877120297613\n",
            "reward of step 21119 is: -0.00016857597563689166\n",
            "reward of step 21120 is: -0.00016378365609573322\n",
            "reward of step 21121 is: -0.00015465753421950652\n",
            "reward of step 21122 is: -0.0001772659532632214\n",
            "reward of step 21123 is: -0.00017191534614809125\n",
            "reward of step 21124 is: -0.0001668486823684708\n",
            "reward of step 21125 is: -0.00016118015641524542\n",
            "reward of step 21126 is: -0.00015937281035502317\n",
            "reward of step 21127 is: -0.00016783715994497352\n",
            "reward of step 21128 is: -0.00017150073904484447\n",
            "reward of step 21129 is: -0.0001688379909122787\n",
            "reward of step 21130 is: -0.00016273411578372095\n",
            "reward of step 21131 is: -0.00016681510084472822\n",
            "reward of step 21132 is: -0.00016311878945164397\n",
            "reward of step 21133 is: -0.00016862150121012257\n",
            "reward of step 21134 is: -0.00017175106847487807\n",
            "reward of step 21135 is: -0.0001631315518505706\n",
            "reward of step 21136 is: -0.00016095148482839634\n",
            "reward of step 21137 is: -0.00016301385682062088\n",
            "reward of step 21138 is: -0.00017095010255427186\n",
            "reward of step 21139 is: -0.00017058951810654008\n",
            "reward of step 21140 is: -0.00018033895737245743\n",
            "reward of step 21141 is: -0.00016389559659327435\n",
            "reward of step 21142 is: -0.00017350602847329637\n",
            "reward of step 21143 is: -0.00016679530581472109\n",
            "reward of step 21144 is: -0.00016312456801073313\n",
            "reward of step 21145 is: -0.00016719777673710566\n",
            "reward of step 21146 is: -0.00016657611815732964\n",
            "reward of step 21147 is: -0.00017278444831724958\n",
            "reward of step 21148 is: -0.00016534507594965228\n",
            "reward of step 21149 is: -0.00016349212603613872\n",
            "reward of step 21150 is: -0.00016580845650280787\n",
            "reward of step 21151 is: -0.00016284204122797862\n",
            "reward of step 21152 is: -0.00016854577856378552\n",
            "reward of step 21153 is: -0.00016047337038459006\n",
            "reward of step 21154 is: -0.00016693931122654894\n",
            "reward of step 21155 is: -0.00016087055129001299\n",
            "reward of step 21156 is: -0.00016932208922614353\n",
            "reward of step 21157 is: -0.0001573291528883145\n",
            "reward of step 21158 is: -0.0001608074554882455\n",
            "reward of step 21159 is: -0.00016330583297526378\n",
            "reward of step 21160 is: -0.00016872693460085147\n",
            "reward of step 21161 is: -0.00016798834939589288\n",
            "reward of step 21162 is: -0.00016629711851503653\n",
            "reward of step 21163 is: -0.00016392703654854267\n",
            "reward of step 21164 is: -0.0001612361323722778\n",
            "reward of step 21165 is: -0.00016423771810563387\n",
            "reward of step 21166 is: -0.00017134115903872228\n",
            "reward of step 21167 is: -0.00016666081861688403\n",
            "reward of step 21168 is: -0.00016501723344116358\n",
            "reward of step 21169 is: -0.00017176074631574482\n",
            "reward of step 21170 is: -0.00016718476283382328\n",
            "reward of step 21171 is: -0.00016264834561096028\n",
            "reward of step 21172 is: -0.00017570397987717211\n",
            "reward of step 21173 is: -0.00016376410259842403\n",
            "reward of step 21174 is: -0.00016273330054075632\n",
            "reward of step 21175 is: -0.00015739769043270988\n",
            "reward of step 21176 is: -0.00016335644480122878\n",
            "reward of step 21177 is: -0.00017160371921914202\n",
            "reward of step 21178 is: -0.00015861886940365645\n",
            "reward of step 21179 is: -0.00016697614679748798\n",
            "reward of step 21180 is: -0.00016966132083545566\n",
            "reward of step 21181 is: -0.0001705660103828093\n",
            "reward of step 21182 is: -0.00016336722466978477\n",
            "reward of step 21183 is: -0.0001624962113997654\n",
            "reward of step 21184 is: -0.00017363641408809656\n",
            "reward of step 21185 is: -0.00015860320983321924\n",
            "reward of step 21186 is: -0.00016740649694792025\n",
            "reward of step 21187 is: -0.00015784854381839332\n",
            "reward of step 21188 is: -0.00017614093558210395\n",
            "reward of step 21189 is: -0.00016600490928270973\n",
            "reward of step 21190 is: -0.00017001394225986592\n",
            "reward of step 21191 is: -0.0001604092358701385\n",
            "reward of step 21192 is: -0.00015752350519911747\n",
            "reward of step 21193 is: -0.00017555069594516783\n",
            "reward of step 21194 is: -0.00015303609411451637\n",
            "reward of step 21195 is: -0.00015434176620476403\n",
            "reward of step 21196 is: -0.00015718809092486142\n",
            "reward of step 21197 is: -0.00016375868476238467\n",
            "reward of step 21198 is: -0.00017270178414115987\n",
            "reward of step 21199 is: -0.00016372991173488447\n",
            "reward of step 21200 is: -0.00016857910968751816\n",
            "reward of step 21201 is: -0.00016874205623878055\n",
            "reward of step 21202 is: -0.00015595558445989822\n",
            "reward of step 21203 is: -0.00017427256420559064\n",
            "reward of step 21204 is: -0.0001734265491558071\n",
            "reward of step 21205 is: -0.00016863327023556256\n",
            "reward of step 21206 is: -0.00016617105554697919\n",
            "reward of step 21207 is: -0.00016743478257715891\n",
            "reward of step 21208 is: -0.00016400576848286675\n",
            "reward of step 21209 is: -0.0001604985869384412\n",
            "reward of step 21210 is: -0.00015555959789813095\n",
            "reward of step 21211 is: -0.00016402107309762136\n",
            "reward of step 21212 is: -0.0001668116998962716\n",
            "reward of step 21213 is: -0.0001609553795128951\n",
            "reward of step 21214 is: -0.00016433252477560668\n",
            "reward of step 21215 is: -0.00016336782858051384\n",
            "reward of step 21216 is: -0.00015969568449344533\n",
            "reward of step 21217 is: -0.00017121968803514108\n",
            "reward of step 21218 is: -0.0001760243633346867\n",
            "reward of step 21219 is: -0.00016388649776833585\n",
            "reward of step 21220 is: -0.00016455230209801844\n",
            "reward of step 21221 is: -0.00015903894094106727\n",
            "reward of step 21222 is: -0.00016814543894759265\n",
            "reward of step 21223 is: -0.0001607233980129613\n",
            "reward of step 21224 is: -0.00016407520623207083\n",
            "reward of step 21225 is: -0.00016553826749480665\n",
            "reward of step 21226 is: -0.00016787256329159095\n",
            "reward of step 21227 is: -0.00016819683663017151\n",
            "reward of step 21228 is: -0.00017065114994994232\n",
            "reward of step 21229 is: -0.00015352114491540552\n",
            "reward of step 21230 is: -0.0001614760415241635\n",
            "reward of step 21231 is: -0.00015696888062898654\n",
            "reward of step 21232 is: -0.00016870267680070718\n",
            "reward of step 21233 is: -0.0001690405887048698\n",
            "reward of step 21234 is: -0.00016814914518522488\n",
            "reward of step 21235 is: -0.00016372156653765728\n",
            "reward of step 21236 is: -0.00016961163075614633\n",
            "reward of step 21237 is: -0.0001685817918993528\n",
            "reward of step 21238 is: -0.00016680968546105643\n",
            "reward of step 21239 is: -0.00017859610651131233\n",
            "reward of step 21240 is: -0.00017460351104272656\n",
            "reward of step 21241 is: -0.0001641716434762245\n",
            "reward of step 21242 is: -0.00015882359520926845\n",
            "reward of step 21243 is: -0.00017836209685682158\n",
            "reward of step 21244 is: -0.00015920804175311172\n",
            "reward of step 21245 is: -0.00016228216308500977\n",
            "reward of step 21246 is: -0.00017893957702083473\n",
            "reward of step 21247 is: -0.00016250606389409678\n",
            "reward of step 21248 is: -0.00015835724201718104\n",
            "reward of step 21249 is: -0.00016893592543352654\n",
            "reward of step 21250 is: -0.0001693766927719722\n",
            "reward of step 21251 is: -0.00017036621955004882\n",
            "reward of step 21252 is: -0.00015796220699272118\n",
            "reward of step 21253 is: -0.00016383155251645433\n",
            "reward of step 21254 is: -0.00015932932021529177\n",
            "reward of step 21255 is: -0.0001710227711120023\n",
            "reward of step 21256 is: -0.0001712431840637392\n",
            "reward of step 21257 is: -0.00015689962736918856\n",
            "reward of step 21258 is: -0.00016738366007090332\n",
            "reward of step 21259 is: -0.00016019573363675892\n",
            "reward of step 21260 is: -0.00017509339349532663\n",
            "reward of step 21261 is: -0.00015550951326507586\n",
            "reward of step 21262 is: -0.00016311993047353785\n",
            "reward of step 21263 is: -0.00015891979202656273\n",
            "reward of step 21264 is: -0.00016172557669088985\n",
            "reward of step 21265 is: -0.0001631049021246398\n",
            "reward of step 21266 is: -0.00016834518046905385\n",
            "reward of step 21267 is: -0.00016065090643444581\n",
            "reward of step 21268 is: -0.00016889776822746533\n",
            "reward of step 21269 is: -0.00015506008456212455\n",
            "reward of step 21270 is: -0.00016393681202168616\n",
            "reward of step 21271 is: -0.0001707224595849387\n",
            "reward of step 21272 is: -0.00015894212307131036\n",
            "reward of step 21273 is: -0.00017001540676828323\n",
            "reward of step 21274 is: -0.00016601569978983482\n",
            "reward of step 21275 is: -0.0001603206749887055\n",
            "reward of step 21276 is: -0.00016167031508185727\n",
            "reward of step 21277 is: -0.00015696759413203146\n",
            "reward of step 21278 is: -0.0001707323859377486\n",
            "reward of step 21279 is: -0.00015537719948061413\n",
            "reward of step 21280 is: -0.00016207879835229482\n",
            "reward of step 21281 is: -0.00016300324760442782\n",
            "reward of step 21282 is: -0.00016261357215518018\n",
            "reward of step 21283 is: -0.0001769611982540648\n",
            "reward of step 21284 is: -0.00016580871763766027\n",
            "reward of step 21285 is: -0.00015324162945161104\n",
            "reward of step 21286 is: -0.00016203566817296438\n",
            "reward of step 21287 is: -0.00016919782107169628\n",
            "reward of step 21288 is: -0.00017131423542846025\n",
            "reward of step 21289 is: -0.00016578198534563017\n",
            "reward of step 21290 is: -0.00016037888469544134\n",
            "reward of step 21291 is: -0.00016955149319179563\n",
            "reward of step 21292 is: -0.00017254502184756723\n",
            "reward of step 21293 is: -0.0001644230511571672\n",
            "reward of step 21294 is: -0.0001671150037268896\n",
            "reward of step 21295 is: -0.0001660186285042575\n",
            "reward of step 21296 is: -0.00017463176889374537\n",
            "reward of step 21297 is: -0.00016981250206914533\n",
            "reward of step 21298 is: -0.00017147400985426605\n",
            "reward of step 21299 is: -0.00016443392674192454\n",
            "reward of step 21300 is: -0.00016589569405949976\n",
            "reward of step 21301 is: -0.00016350808928517095\n",
            "reward of step 21302 is: -0.00015887036798258353\n",
            "reward of step 21303 is: -0.00016774216680219217\n",
            "reward of step 21304 is: -0.00015697836487954444\n",
            "reward of step 21305 is: -0.0001744644838375562\n",
            "reward of step 21306 is: -0.0001643033764349245\n",
            "reward of step 21307 is: -0.0001600805743120414\n",
            "reward of step 21308 is: -0.0001639056953471566\n",
            "reward of step 21309 is: -0.0001775949750303133\n",
            "reward of step 21310 is: -0.00017503761537553887\n",
            "reward of step 21311 is: -0.00015295503644134864\n",
            "reward of step 21312 is: -0.0001587393739872053\n",
            "reward of step 21313 is: -0.0001669609359555574\n",
            "reward of step 21314 is: -0.00017496844893256163\n",
            "reward of step 21315 is: -0.0001646167073635952\n",
            "reward of step 21316 is: -0.00016648660955403342\n",
            "reward of step 21317 is: -0.00016789960292971803\n",
            "reward of step 21318 is: -0.00016687462647726017\n",
            "reward of step 21319 is: -0.00016754533549023407\n",
            "reward of step 21320 is: -0.00017494023129197575\n",
            "reward of step 21321 is: -0.00016396464925860237\n",
            "reward of step 21322 is: -0.0001542165666053317\n",
            "reward of step 21323 is: -0.00016272034848970483\n",
            "reward of step 21324 is: -0.00016795554504535397\n",
            "reward of step 21325 is: -0.0001577668236387407\n",
            "reward of step 21326 is: -0.00016971393985338375\n",
            "reward of step 21327 is: -0.00016925401402981225\n",
            "reward of step 21328 is: -0.00016643785132220153\n",
            "reward of step 21329 is: -0.00016717566743634863\n",
            "reward of step 21330 is: -0.00016634168091388905\n",
            "reward of step 21331 is: -0.00016078743490741771\n",
            "reward of step 21332 is: -0.00017336805880577307\n",
            "reward of step 21333 is: -0.00016433624604531038\n",
            "reward of step 21334 is: -0.00017541331142114706\n",
            "reward of step 21335 is: -0.0001711617637196799\n",
            "reward of step 21336 is: -0.00016784821130173147\n",
            "reward of step 21337 is: -0.00016769954141357258\n",
            "reward of step 21338 is: -0.0001716692761574494\n",
            "reward of step 21339 is: -0.00017235721625151527\n",
            "reward of step 21340 is: -0.00016831129088875618\n",
            "reward of step 21341 is: -0.000168410774438218\n",
            "reward of step 21342 is: -0.00017029499118728398\n",
            "reward of step 21343 is: -0.00017394316539414594\n",
            "reward of step 21344 is: -0.000162647562370781\n",
            "reward of step 21345 is: -0.0001740213322563631\n",
            "reward of step 21346 is: -0.00016245135153100307\n",
            "reward of step 21347 is: -0.00017639688137054563\n",
            "reward of step 21348 is: -0.0001617678308084851\n",
            "reward of step 21349 is: -0.00017419965857809092\n",
            "reward of step 21350 is: -0.00015780155342249598\n",
            "reward of step 21351 is: -0.00017067603281015393\n",
            "reward of step 21352 is: -0.00015684582913525497\n",
            "reward of step 21353 is: -0.00015865879118425616\n",
            "reward of step 21354 is: -0.00017939163569877676\n",
            "reward of step 21355 is: -0.0001745531995710759\n",
            "reward of step 21356 is: -0.00016029272486100906\n",
            "reward of step 21357 is: -0.00016290221382732754\n",
            "reward of step 21358 is: -0.00017190463399754534\n",
            "reward of step 21359 is: -0.00017911510709823806\n",
            "reward of step 21360 is: -0.00016714927283568816\n",
            "reward of step 21361 is: -0.000161927580336563\n",
            "reward of step 21362 is: -0.00016556372743654224\n",
            "reward of step 21363 is: -0.00017367698538030033\n",
            "reward of step 21364 is: -0.0001553545066033437\n",
            "reward of step 21365 is: -0.0001698310426350784\n",
            "reward of step 21366 is: -0.00018039175458944365\n",
            "reward of step 21367 is: -0.00017044731097950146\n",
            "reward of step 21368 is: -0.0001793297319487112\n",
            "reward of step 21369 is: -0.00016269255775576256\n",
            "reward of step 21370 is: -0.00015535576027941693\n",
            "reward of step 21371 is: -0.00016005813396637096\n",
            "reward of step 21372 is: -0.00017423259292019365\n",
            "reward of step 21373 is: -0.00016911079714992575\n",
            "reward of step 21374 is: -0.0001640183208843427\n",
            "reward of step 21375 is: -0.00017947290348847923\n",
            "reward of step 21376 is: -0.00018048533119475072\n",
            "reward of step 21377 is: -0.0001639894954453057\n",
            "reward of step 21378 is: -0.0001598275182194875\n",
            "reward of step 21379 is: -0.00016503034579278642\n",
            "reward of step 21380 is: -0.00017664631080561622\n",
            "reward of step 21381 is: -0.00017063468263094544\n",
            "reward of step 21382 is: -0.00016805598179123703\n",
            "reward of step 21383 is: -0.0001743209995707943\n",
            "reward of step 21384 is: -0.0001679019101020576\n",
            "reward of step 21385 is: -0.00016533976546694764\n",
            "reward of step 21386 is: -0.00016573501159265484\n",
            "reward of step 21387 is: -0.0001660091065164577\n",
            "reward of step 21388 is: -0.00016788658032269838\n",
            "reward of step 21389 is: -0.00017492828150061836\n",
            "reward of step 21390 is: -0.0001747354759479874\n",
            "reward of step 21391 is: -0.00017230622016599245\n",
            "reward of step 21392 is: -0.00017379446652524797\n",
            "reward of step 21393 is: -0.00017395328321875427\n",
            "reward of step 21394 is: -0.00016818110144195528\n",
            "reward of step 21395 is: -0.0001682557002148097\n",
            "reward of step 21396 is: -0.00015907104214722773\n",
            "reward of step 21397 is: -0.00016215376996909757\n",
            "reward of step 21398 is: -0.00016731986833459049\n",
            "reward of step 21399 is: -0.00018032012571604907\n",
            "reward of step 21400 is: -0.0001682555838156772\n",
            "reward of step 21401 is: -0.00017655669896783966\n",
            "reward of step 21402 is: -0.0001712866267164137\n",
            "reward of step 21403 is: -0.00016251597754425728\n",
            "reward of step 21404 is: -0.00016821169837566357\n",
            "reward of step 21405 is: -0.0001765964735761637\n",
            "reward of step 21406 is: -0.00017254429020453692\n",
            "reward of step 21407 is: -0.00016695840235143414\n",
            "reward of step 21408 is: -0.00016479764651569775\n",
            "reward of step 21409 is: -0.00016453181997414993\n",
            "reward of step 21410 is: -0.0001769261874125632\n",
            "reward of step 21411 is: -0.00017268654832532963\n",
            "reward of step 21412 is: -0.0001580686241207053\n",
            "reward of step 21413 is: -0.0001677019323188909\n",
            "reward of step 21414 is: -0.00016258017076870563\n",
            "reward of step 21415 is: -0.00017755091386756979\n",
            "reward of step 21416 is: -0.00016995400770872785\n",
            "reward of step 21417 is: -0.00015547509216014936\n",
            "reward of step 21418 is: -0.0001639380347059133\n",
            "reward of step 21419 is: -0.00016678658795744682\n",
            "reward of step 21420 is: -0.00015798410349155572\n",
            "reward of step 21421 is: -0.00017025277362052874\n",
            "reward of step 21422 is: -0.00016026945398377778\n",
            "reward of step 21423 is: -0.00016455809031657717\n",
            "reward of step 21424 is: -0.0001666277082685004\n",
            "reward of step 21425 is: -0.00017432495172042505\n",
            "reward of step 21426 is: -0.0001758758349816361\n",
            "reward of step 21427 is: -0.00015654376136260624\n",
            "reward of step 21428 is: -0.0001570036706324262\n",
            "reward of step 21429 is: -0.00015622615170011127\n",
            "reward of step 21430 is: -0.00015934398088973838\n",
            "reward of step 21431 is: -0.00016148613602692843\n",
            "reward of step 21432 is: -0.00015927003458673139\n",
            "reward of step 21433 is: -0.00016763299267471345\n",
            "reward of step 21434 is: -0.00018055611802902092\n",
            "reward of step 21435 is: -0.00016927504290753704\n",
            "reward of step 21436 is: -0.00016642029603320034\n",
            "reward of step 21437 is: -0.00015996248317998947\n",
            "reward of step 21438 is: -0.0001742187199427218\n",
            "reward of step 21439 is: -0.00016491186005158028\n",
            "reward of step 21440 is: -0.0001635122939419191\n",
            "reward of step 21441 is: -0.0001551591353863351\n",
            "reward of step 21442 is: -0.0001551824519014451\n",
            "reward of step 21443 is: -0.00017260699867286628\n",
            "reward of step 21444 is: -0.00015887791556741851\n",
            "reward of step 21445 is: -0.00015789829743872985\n",
            "reward of step 21446 is: -0.00016875566970274276\n",
            "reward of step 21447 is: -0.0001593464713761076\n",
            "reward of step 21448 is: -0.00017143662718854176\n",
            "reward of step 21449 is: -0.00016600306591294965\n",
            "reward of step 21450 is: -0.00017156250876243569\n",
            "reward of step 21451 is: -0.00015738878241920002\n",
            "reward of step 21452 is: -0.00017477719311813524\n",
            "reward of step 21453 is: -0.00015614309343001283\n",
            "reward of step 21454 is: -0.0001599312740156494\n",
            "reward of step 21455 is: -0.00015606619390287\n",
            "reward of step 21456 is: -0.00017345069660003892\n",
            "reward of step 21457 is: -0.00015813922280739253\n",
            "reward of step 21458 is: -0.00017532359585830702\n",
            "reward of step 21459 is: -0.00017167026206468705\n",
            "reward of step 21460 is: -0.0001729491748465701\n",
            "reward of step 21461 is: -0.00016125785780331773\n",
            "reward of step 21462 is: -0.00017603530360773761\n",
            "reward of step 21463 is: -0.00015913531090390017\n",
            "reward of step 21464 is: -0.00016882008706564755\n",
            "reward of step 21465 is: -0.0001706630828606685\n",
            "reward of step 21466 is: -0.00017017146573348855\n",
            "reward of step 21467 is: -0.00017064984024021935\n",
            "reward of step 21468 is: -0.00016870365299306137\n",
            "reward of step 21469 is: -0.0001625835615434887\n",
            "reward of step 21470 is: -0.00017384015731580543\n",
            "reward of step 21471 is: -0.00016658436658597924\n",
            "reward of step 21472 is: -0.00016971324384187225\n",
            "reward of step 21473 is: -0.00016219333680770739\n",
            "reward of step 21474 is: -0.00015797636019069841\n",
            "reward of step 21475 is: -0.00016726226934128875\n",
            "reward of step 21476 is: -0.000162211217362844\n",
            "reward of step 21477 is: -0.00016727034876814524\n",
            "reward of step 21478 is: -0.0001533783494283998\n",
            "reward of step 21479 is: -0.000167075895215722\n",
            "reward of step 21480 is: -0.00017056758879672537\n",
            "reward of step 21481 is: -0.00017606417361854904\n",
            "reward of step 21482 is: -0.00016955673991621384\n",
            "reward of step 21483 is: -0.00015796736991229707\n",
            "reward of step 21484 is: -0.00016975725422355468\n",
            "reward of step 21485 is: -0.00016986276989365096\n",
            "reward of step 21486 is: -0.00016025849457998302\n",
            "reward of step 21487 is: -0.000161500878520849\n",
            "reward of step 21488 is: -0.00016867971454886114\n",
            "reward of step 21489 is: -0.00016990681783859876\n",
            "reward of step 21490 is: -0.00016944673066278396\n",
            "reward of step 21491 is: -0.0001527166710634498\n",
            "reward of step 21492 is: -0.00015975468721235778\n",
            "reward of step 21493 is: -0.00017411410121670825\n",
            "reward of step 21494 is: -0.00016338519964008172\n",
            "reward of step 21495 is: -0.0001615902282237112\n",
            "reward of step 21496 is: -0.00017183402260040603\n",
            "reward of step 21497 is: -0.00016629109477483904\n",
            "reward of step 21498 is: -0.00016678728349508155\n",
            "reward of step 21499 is: -0.00017029002834643137\n",
            "reward of step 21500 is: -0.00016785937151711405\n",
            "reward of step 21501 is: -0.0001779708695708573\n",
            "reward of step 21502 is: -0.00017562119280544684\n",
            "reward of step 21503 is: -0.0001717372168568216\n",
            "reward of step 21504 is: -0.000155995700314548\n",
            "reward of step 21505 is: -0.00016322062310192617\n",
            "reward of step 21506 is: -0.00016252948535320821\n",
            "reward of step 21507 is: -0.00015674001385581907\n",
            "reward of step 21508 is: -0.00016409378747673663\n",
            "reward of step 21509 is: -0.00015936174100426414\n",
            "reward of step 21510 is: -0.00016521319734166828\n",
            "reward of step 21511 is: -0.00016076024344053157\n",
            "reward of step 21512 is: -0.0001676919101936922\n",
            "reward of step 21513 is: -0.0001771413404766046\n",
            "reward of step 21514 is: -0.00015847189996467123\n",
            "reward of step 21515 is: -0.00016013195564239648\n",
            "reward of step 21516 is: -0.0001762872383925606\n",
            "reward of step 21517 is: -0.0001610934660575737\n",
            "reward of step 21518 is: -0.000160053831999785\n",
            "reward of step 21519 is: -0.0001563144159597945\n",
            "reward of step 21520 is: -0.00016469165532009096\n",
            "reward of step 21521 is: -0.00017094848916296348\n",
            "reward of step 21522 is: -0.00018090673306157408\n",
            "reward of step 21523 is: -0.00015981521942895211\n",
            "reward of step 21524 is: -0.00016342547952451396\n",
            "reward of step 21525 is: -0.00016574378754517593\n",
            "reward of step 21526 is: -0.000154474777523425\n",
            "reward of step 21527 is: -0.00015550070923639153\n",
            "reward of step 21528 is: -0.00017082872501810877\n",
            "reward of step 21529 is: -0.00015932829377626826\n",
            "reward of step 21530 is: -0.00016998976387167883\n",
            "reward of step 21531 is: -0.0001679611840821205\n",
            "reward of step 21532 is: -0.00017467177271585893\n",
            "reward of step 21533 is: -0.0001660791459703852\n",
            "reward of step 21534 is: -0.00017145788439070362\n",
            "reward of step 21535 is: -0.0001734224926097772\n",
            "reward of step 21536 is: -0.00015833251836585161\n",
            "reward of step 21537 is: -0.000162204189632846\n",
            "reward of step 21538 is: -0.0001738135611459011\n",
            "reward of step 21539 is: -0.0001763295256294865\n",
            "reward of step 21540 is: -0.00017924808212288926\n",
            "reward of step 21541 is: -0.00016052475160193466\n",
            "reward of step 21542 is: -0.00016658570271625416\n",
            "reward of step 21543 is: -0.0001745931755327542\n",
            "reward of step 21544 is: -0.00015467509555382408\n",
            "reward of step 21545 is: -0.00016840454616368812\n",
            "reward of step 21546 is: -0.00016473860007242948\n",
            "reward of step 21547 is: -0.0001593974642190515\n",
            "reward of step 21548 is: -0.00017310314994671742\n",
            "reward of step 21549 is: -0.00016294193590646376\n",
            "reward of step 21550 is: -0.00015851867493689724\n",
            "reward of step 21551 is: -0.000175444727378712\n",
            "reward of step 21552 is: -0.00016675085013373903\n",
            "reward of step 21553 is: -0.00017731226069500145\n",
            "reward of step 21554 is: -0.00015302420782786918\n",
            "reward of step 21555 is: -0.00017694551906548498\n",
            "reward of step 21556 is: -0.0001727072859267644\n",
            "reward of step 21557 is: -0.00016997509657747488\n",
            "reward of step 21558 is: -0.00016593987804556164\n",
            "reward of step 21559 is: -0.00016892697900791718\n",
            "reward of step 21560 is: -0.00016731658383656927\n",
            "reward of step 21561 is: -0.00016188279748590687\n",
            "reward of step 21562 is: -0.00017128517258697948\n",
            "reward of step 21563 is: -0.00015474474532776113\n",
            "reward of step 21564 is: -0.00016648754112589577\n",
            "reward of step 21565 is: -0.00016650818923456403\n",
            "reward of step 21566 is: -0.00016559021940167876\n",
            "reward of step 21567 is: -0.0001531718072826364\n",
            "reward of step 21568 is: -0.00016501763651299446\n",
            "reward of step 21569 is: -0.00016116131751111427\n",
            "reward of step 21570 is: -0.00016244227177142942\n",
            "reward of step 21571 is: -0.00015799839061381304\n",
            "reward of step 21572 is: -0.00016128066401155885\n",
            "reward of step 21573 is: -0.00016521012143341145\n",
            "reward of step 21574 is: -0.00016885933017857607\n",
            "reward of step 21575 is: -0.00017307071117493277\n",
            "reward of step 21576 is: -0.00016202841397830648\n",
            "reward of step 21577 is: -0.00017648542547864127\n",
            "reward of step 21578 is: -0.0001696592424314231\n",
            "reward of step 21579 is: -0.00016742040838994748\n",
            "reward of step 21580 is: -0.00016067864345445284\n",
            "reward of step 21581 is: -0.00016692862656898132\n",
            "reward of step 21582 is: -0.00015710683213529246\n",
            "reward of step 21583 is: -0.00017575890655997158\n",
            "reward of step 21584 is: -0.0001743448503376236\n",
            "reward of step 21585 is: -0.00015547084271280563\n",
            "reward of step 21586 is: -0.0001658774996423388\n",
            "reward of step 21587 is: -0.0001707029598392723\n",
            "reward of step 21588 is: -0.00016221142191997183\n",
            "reward of step 21589 is: -0.00016195123295612582\n",
            "reward of step 21590 is: -0.0001630423725041475\n",
            "reward of step 21591 is: -0.00016579007279504785\n",
            "reward of step 21592 is: -0.0001565113370007739\n",
            "reward of step 21593 is: -0.00016157512774134147\n",
            "reward of step 21594 is: -0.00016405773776813974\n",
            "reward of step 21595 is: -0.00017297279157788925\n",
            "reward of step 21596 is: -0.00017213693364714623\n",
            "reward of step 21597 is: -0.00016689714590984196\n",
            "reward of step 21598 is: -0.00016676869692445535\n",
            "reward of step 21599 is: -0.00016999247937166055\n",
            "reward of step 21600 is: -0.00016061832932128304\n",
            "reward of step 21601 is: -0.00015970092394976764\n",
            "reward of step 21602 is: -0.0001629065042522168\n",
            "reward of step 21603 is: -0.00017007669579446953\n",
            "reward of step 21604 is: -0.0001692976339499493\n",
            "reward of step 21605 is: -0.00015741001582174916\n",
            "reward of step 21606 is: -0.00016911697922599573\n",
            "reward of step 21607 is: -0.00015513248559724814\n",
            "reward of step 21608 is: -0.0001644670246856129\n",
            "reward of step 21609 is: -0.000166748617228357\n",
            "reward of step 21610 is: -0.00015959629838224553\n",
            "reward of step 21611 is: -0.00016519895142552108\n",
            "reward of step 21612 is: -0.0001586960484115786\n",
            "reward of step 21613 is: -0.00016991979491819148\n",
            "reward of step 21614 is: -0.00016730584647171306\n",
            "reward of step 21615 is: -0.00016577204720563335\n",
            "reward of step 21616 is: -0.00016623873194070943\n",
            "reward of step 21617 is: -0.0001780764021586386\n",
            "reward of step 21618 is: -0.00016603765956319227\n",
            "reward of step 21619 is: -0.0001556426240471598\n",
            "reward of step 21620 is: -0.0001728576686690508\n",
            "reward of step 21621 is: -0.00017585801597087706\n",
            "reward of step 21622 is: -0.00015835301166430894\n",
            "reward of step 21623 is: -0.00017617376252249863\n",
            "reward of step 21624 is: -0.000159976868884399\n",
            "reward of step 21625 is: -0.0001685504818114556\n",
            "reward of step 21626 is: -0.00016708157865423113\n",
            "reward of step 21627 is: -0.00016489468862177352\n",
            "reward of step 21628 is: -0.0001568497333269015\n",
            "reward of step 21629 is: -0.00016880416704935012\n",
            "reward of step 21630 is: -0.0001707842473959014\n",
            "reward of step 21631 is: -0.000175064227245949\n",
            "reward of step 21632 is: -0.0001670818404300095\n",
            "reward of step 21633 is: -0.0001571875705028482\n",
            "reward of step 21634 is: -0.00017129962874067807\n",
            "reward of step 21635 is: -0.00016659317251502015\n",
            "reward of step 21636 is: -0.00017295422134345353\n",
            "reward of step 21637 is: -0.00015924968096208428\n",
            "reward of step 21638 is: -0.00016588490400732853\n",
            "reward of step 21639 is: -0.00016193250987775167\n",
            "reward of step 21640 is: -0.00016640805955938818\n",
            "reward of step 21641 is: -0.00015633768031416578\n",
            "reward of step 21642 is: -0.00017574907359001288\n",
            "reward of step 21643 is: -0.00017338441928309783\n",
            "reward of step 21644 is: -0.00016232296431554612\n",
            "reward of step 21645 is: -0.00017190750334409306\n",
            "reward of step 21646 is: -0.00016154015548953962\n",
            "reward of step 21647 is: -0.00016804006469847214\n",
            "reward of step 21648 is: -0.00016886631549052188\n",
            "reward of step 21649 is: -0.00016226766416342026\n",
            "reward of step 21650 is: -0.00016020274120339624\n",
            "reward of step 21651 is: -0.00016650810802164794\n",
            "reward of step 21652 is: -0.0001687970775052423\n",
            "reward of step 21653 is: -0.00016372705905340324\n",
            "reward of step 21654 is: -0.00015799335317613197\n",
            "reward of step 21655 is: -0.00015971782900647683\n",
            "reward of step 21656 is: -0.0001630510366080831\n",
            "reward of step 21657 is: -0.00015823615648898518\n",
            "reward of step 21658 is: -0.00016729861716822662\n",
            "reward of step 21659 is: -0.00016413754009369434\n",
            "reward of step 21660 is: -0.00016004145902477921\n",
            "reward of step 21661 is: -0.00016630477030941024\n",
            "reward of step 21662 is: -0.00016439584049529897\n",
            "reward of step 21663 is: -0.00017100926690750132\n",
            "reward of step 21664 is: -0.00016225581398477372\n",
            "reward of step 21665 is: -0.00016243815413774978\n",
            "reward of step 21666 is: -0.0001634603865333687\n",
            "reward of step 21667 is: -0.00016685390750823122\n",
            "reward of step 21668 is: -0.0001607950078882372\n",
            "reward of step 21669 is: -0.0001665232533935124\n",
            "reward of step 21670 is: -0.00017000887897908315\n",
            "reward of step 21671 is: -0.0001590916389255551\n",
            "reward of step 21672 is: -0.00016174167652491865\n",
            "reward of step 21673 is: -0.00017821056545482287\n",
            "reward of step 21674 is: -0.00016510672602880277\n",
            "reward of step 21675 is: -0.00016775045903903986\n",
            "reward of step 21676 is: -0.00017281967944741492\n",
            "reward of step 21677 is: -0.00016423745915227606\n",
            "reward of step 21678 is: -0.00016910424255973976\n",
            "reward of step 21679 is: -0.00016188113149529418\n",
            "reward of step 21680 is: -0.00016808413744854515\n",
            "reward of step 21681 is: -0.00016093635490556062\n",
            "reward of step 21682 is: -0.0001716313957529853\n",
            "reward of step 21683 is: -0.00015914980975637516\n",
            "reward of step 21684 is: -0.00015646752071439424\n",
            "reward of step 21685 is: -0.00015234829194681277\n",
            "reward of step 21686 is: -0.00016743799396933383\n",
            "reward of step 21687 is: -0.00016697630600569295\n",
            "reward of step 21688 is: -0.00016436433010910115\n",
            "reward of step 21689 is: -0.00015634435617610594\n",
            "reward of step 21690 is: -0.0001762891331115295\n",
            "reward of step 21691 is: -0.00016021383356730695\n",
            "reward of step 21692 is: -0.00016210211560043424\n",
            "reward of step 21693 is: -0.00017614243156955885\n",
            "reward of step 21694 is: -0.00017125026704757135\n",
            "reward of step 21695 is: -0.0001679394985091176\n",
            "reward of step 21696 is: -0.00017484103755963014\n",
            "reward of step 21697 is: -0.0001672495803041368\n",
            "reward of step 21698 is: -0.00016753573034541765\n",
            "reward of step 21699 is: -0.00017153021449653653\n",
            "reward of step 21700 is: -0.00016383341121702793\n",
            "reward of step 21701 is: -0.00016399671741112884\n",
            "reward of step 21702 is: -0.00015695724833140304\n",
            "reward of step 21703 is: -0.00016569877954228772\n",
            "reward of step 21704 is: -0.0001671712038154755\n",
            "reward of step 21705 is: -0.00016286401952083504\n",
            "reward of step 21706 is: -0.00016589229522359612\n",
            "reward of step 21707 is: -0.00016516828962941275\n",
            "reward of step 21708 is: -0.00015538457767837692\n",
            "reward of step 21709 is: -0.00017080113275700203\n",
            "reward of step 21710 is: -0.00016205165664108693\n",
            "reward of step 21711 is: -0.00015999062769869333\n",
            "reward of step 21712 is: -0.0001754463061211131\n",
            "reward of step 21713 is: -0.00016652486617376667\n",
            "reward of step 21714 is: -0.00017233533817339296\n",
            "reward of step 21715 is: -0.00016024467993977325\n",
            "reward of step 21716 is: -0.00016905624705213827\n",
            "reward of step 21717 is: -0.00016220409079446396\n",
            "reward of step 21718 is: -0.00017869088680189267\n",
            "reward of step 21719 is: -0.00015794216410231092\n",
            "reward of step 21720 is: -0.0001645856640353682\n",
            "reward of step 21721 is: -0.00016917401162731442\n",
            "reward of step 21722 is: -0.00017577235733891265\n",
            "reward of step 21723 is: -0.00017193083280579247\n",
            "reward of step 21724 is: -0.00017744982487644838\n",
            "reward of step 21725 is: -0.00016511430289537936\n",
            "reward of step 21726 is: -0.0001642802305605759\n",
            "reward of step 21727 is: -0.0001594683787940248\n",
            "reward of step 21728 is: -0.00016438231234415862\n",
            "reward of step 21729 is: -0.0001638315499528141\n",
            "reward of step 21730 is: -0.0001690983496196893\n",
            "reward of step 21731 is: -0.00015450923234228527\n",
            "reward of step 21732 is: -0.0001777719816628925\n",
            "reward of step 21733 is: -0.00017176096068804203\n",
            "reward of step 21734 is: -0.00016024152860241682\n",
            "reward of step 21735 is: -0.00017128393364762356\n",
            "reward of step 21736 is: -0.00015516732243923528\n",
            "reward of step 21737 is: -0.0001756162676044116\n",
            "reward of step 21738 is: -0.00016910819188745746\n",
            "reward of step 21739 is: -0.00016823250842559954\n",
            "reward of step 21740 is: -0.000170122913461864\n",
            "reward of step 21741 is: -0.00016855587775636255\n",
            "reward of step 21742 is: -0.00017405340482296497\n",
            "reward of step 21743 is: -0.00017643903974563834\n",
            "reward of step 21744 is: -0.00015423494074306434\n",
            "reward of step 21745 is: -0.00016920808317039503\n",
            "reward of step 21746 is: -0.00016598081223285235\n",
            "reward of step 21747 is: -0.0001734338468601651\n",
            "reward of step 21748 is: -0.00017441884071845443\n",
            "reward of step 21749 is: -0.00016204307563646024\n",
            "reward of step 21750 is: -0.00015391370908249863\n",
            "reward of step 21751 is: -0.00016589638857065025\n",
            "reward of step 21752 is: -0.00016870991914622784\n",
            "reward of step 21753 is: -0.00016397919942266425\n",
            "reward of step 21754 is: -0.00016876107449545895\n",
            "reward of step 21755 is: -0.00017258723197323934\n",
            "reward of step 21756 is: -0.00016535832879876705\n",
            "reward of step 21757 is: -0.0001528813245747013\n",
            "reward of step 21758 is: -0.0001657721917585168\n",
            "reward of step 21759 is: -0.00016366456291581785\n",
            "reward of step 21760 is: -0.00016927162673264907\n",
            "reward of step 21761 is: -0.0001725833091865509\n",
            "reward of step 21762 is: -0.00016683496105094811\n",
            "reward of step 21763 is: -0.00017042184964094874\n",
            "reward of step 21764 is: -0.00017518672518360674\n",
            "reward of step 21765 is: -0.00016269069262779282\n",
            "reward of step 21766 is: -0.0001541027604716835\n",
            "reward of step 21767 is: -0.00015854500869813052\n",
            "reward of step 21768 is: -0.00017107564771238787\n",
            "reward of step 21769 is: -0.00015926361226928335\n",
            "reward of step 21770 is: -0.00016294370579190444\n",
            "reward of step 21771 is: -0.00016809107093503518\n",
            "reward of step 21772 is: -0.00016112253306722326\n",
            "reward of step 21773 is: -0.0001595952796118592\n",
            "reward of step 21774 is: -0.00016428522318894762\n",
            "reward of step 21775 is: -0.0001619068100236473\n",
            "reward of step 21776 is: -0.00016536170630683208\n",
            "reward of step 21777 is: -0.00016399768171586023\n",
            "reward of step 21778 is: -0.0001655377134790959\n",
            "reward of step 21779 is: -0.00016472872012837075\n",
            "reward of step 21780 is: -0.00016968457275222892\n",
            "reward of step 21781 is: -0.00017440103045113353\n",
            "reward of step 21782 is: -0.00016666649330351183\n",
            "reward of step 21783 is: -0.00016393980944376466\n",
            "reward of step 21784 is: -0.00017677161840791103\n",
            "reward of step 21785 is: -0.00016785397005800233\n",
            "reward of step 21786 is: -0.00015634041422955673\n",
            "reward of step 21787 is: -0.00016271192832788893\n",
            "reward of step 21788 is: -0.0001638010316946448\n",
            "reward of step 21789 is: -0.00017826023731587145\n",
            "reward of step 21790 is: -0.0001534147335\n",
            "reward of step 21791 is: -0.00016567568866513802\n",
            "reward of step 21792 is: -0.00016592984837341448\n",
            "reward of step 21793 is: -0.0001750399367011154\n",
            "reward of step 21794 is: -0.0001689014326881829\n",
            "reward of step 21795 is: -0.0001602435596267178\n",
            "reward of step 21796 is: -0.000152857202184761\n",
            "reward of step 21797 is: -0.00016597415456047883\n",
            "reward of step 21798 is: -0.00017544948305298685\n",
            "reward of step 21799 is: -0.00016132126886993188\n",
            "reward of step 21800 is: -0.00015658310430047889\n",
            "reward of step 21801 is: -0.00016903264201838122\n",
            "reward of step 21802 is: -0.00017461506646444789\n",
            "reward of step 21803 is: -0.00016911355441895075\n",
            "reward of step 21804 is: -0.00016374454756305385\n",
            "reward of step 21805 is: -0.00015492867689152084\n",
            "reward of step 21806 is: -0.00016990812989452775\n",
            "reward of step 21807 is: -0.00015616617254697173\n",
            "reward of step 21808 is: -0.00015591079757044883\n",
            "reward of step 21809 is: -0.0001684642462676094\n",
            "reward of step 21810 is: -0.0001587906660570531\n",
            "reward of step 21811 is: -0.00015907941634653796\n",
            "reward of step 21812 is: -0.00016115154107986738\n",
            "reward of step 21813 is: -0.00017607062965903258\n",
            "reward of step 21814 is: -0.00016349615265426944\n",
            "reward of step 21815 is: -0.000172663281236451\n",
            "reward of step 21816 is: -0.0001668777864826554\n",
            "reward of step 21817 is: -0.00017246767824219276\n",
            "reward of step 21818 is: -0.00016836388385014196\n",
            "reward of step 21819 is: -0.00016761278372982155\n",
            "reward of step 21820 is: -0.00015407760905422401\n",
            "reward of step 21821 is: -0.00017785843826076929\n",
            "reward of step 21822 is: -0.0001715327663368214\n",
            "reward of step 21823 is: -0.0001646440746909965\n",
            "reward of step 21824 is: -0.00016714127675298228\n",
            "reward of step 21825 is: -0.0001693099447526253\n",
            "reward of step 21826 is: -0.00015988270311756588\n",
            "reward of step 21827 is: -0.00017254830663507675\n",
            "reward of step 21828 is: -0.0001783779092736567\n",
            "reward of step 21829 is: -0.00015953344385315072\n",
            "reward of step 21830 is: -0.00017106765852850298\n",
            "reward of step 21831 is: -0.00016811865837064238\n",
            "reward of step 21832 is: -0.00017637056114362359\n",
            "reward of step 21833 is: -0.00016299606865574905\n",
            "reward of step 21834 is: -0.00016130383343353308\n",
            "reward of step 21835 is: -0.00015974947572371088\n",
            "reward of step 21836 is: -0.00016795332982338872\n",
            "reward of step 21837 is: -0.00016796366051041755\n",
            "reward of step 21838 is: -0.00015716336201090472\n",
            "reward of step 21839 is: -0.00016473130330165361\n",
            "reward of step 21840 is: -0.00016115591847491682\n",
            "reward of step 21841 is: -0.00016992218327936212\n",
            "reward of step 21842 is: -0.00016094550025336484\n",
            "reward of step 21843 is: -0.0001696405244267943\n",
            "reward of step 21844 is: -0.0001608866147577479\n",
            "reward of step 21845 is: -0.00017240959172864646\n",
            "reward of step 21846 is: -0.00016075757818696733\n",
            "reward of step 21847 is: -0.0001551053315173008\n",
            "reward of step 21848 is: -0.00017444792256081715\n",
            "reward of step 21849 is: -0.00015836499184963802\n",
            "reward of step 21850 is: -0.00016575130060916327\n",
            "reward of step 21851 is: -0.0001655512448386782\n",
            "reward of step 21852 is: -0.00017315662467255928\n",
            "reward of step 21853 is: -0.00016607512729271254\n",
            "reward of step 21854 is: -0.00017620401989814494\n",
            "reward of step 21855 is: -0.00016982804526991899\n",
            "reward of step 21856 is: -0.00017160128597642447\n",
            "reward of step 21857 is: -0.00017068591304051584\n",
            "reward of step 21858 is: -0.00016772160755801357\n",
            "reward of step 21859 is: -0.0001691397262454753\n",
            "reward of step 21860 is: -0.0001662444804064599\n",
            "reward of step 21861 is: -0.00016381952867260913\n",
            "reward of step 21862 is: -0.0001668699164079863\n",
            "reward of step 21863 is: -0.0001647600884067154\n",
            "reward of step 21864 is: -0.00016403799282422186\n",
            "reward of step 21865 is: -0.0001711348316026126\n",
            "reward of step 21866 is: -0.000152832161012669\n",
            "reward of step 21867 is: -0.00017457606521909552\n",
            "reward of step 21868 is: -0.0001639880344724615\n",
            "reward of step 21869 is: -0.00016199393066386914\n",
            "reward of step 21870 is: -0.0001576918811751606\n",
            "reward of step 21871 is: -0.0001705721849969581\n",
            "reward of step 21872 is: -0.000165465305320844\n",
            "reward of step 21873 is: -0.00017314219802947286\n",
            "reward of step 21874 is: -0.000169273697908327\n",
            "reward of step 21875 is: -0.00015850569766413328\n",
            "reward of step 21876 is: -0.00016876312237687867\n",
            "reward of step 21877 is: -0.0001621932578145815\n",
            "reward of step 21878 is: -0.00016642750222795364\n",
            "reward of step 21879 is: -0.0001708602685461292\n",
            "reward of step 21880 is: -0.0001697629931938331\n",
            "reward of step 21881 is: -0.00017313624663386557\n",
            "reward of step 21882 is: -0.00015966954692951205\n",
            "reward of step 21883 is: -0.00015942164009268296\n",
            "reward of step 21884 is: -0.00016790033643888824\n",
            "reward of step 21885 is: -0.00017361297250378894\n",
            "reward of step 21886 is: -0.00016649861258092035\n",
            "reward of step 21887 is: -0.00017336106424375265\n",
            "reward of step 21888 is: -0.0001625220138214914\n",
            "reward of step 21889 is: -0.0001742900854380208\n",
            "reward of step 21890 is: -0.00016889227675450594\n",
            "reward of step 21891 is: -0.0001637276208185462\n",
            "reward of step 21892 is: -0.000166913799885049\n",
            "reward of step 21893 is: -0.00016236440011832367\n",
            "reward of step 21894 is: -0.000162393352218321\n",
            "reward of step 21895 is: -0.00015620622560396687\n",
            "reward of step 21896 is: -0.00016708862050828508\n",
            "reward of step 21897 is: -0.00016954560484820608\n",
            "reward of step 21898 is: -0.0001586641090003691\n",
            "reward of step 21899 is: -0.00016825528500777473\n",
            "reward of step 21900 is: -0.0001686775681073667\n",
            "reward of step 21901 is: -0.0001776420831513982\n",
            "reward of step 21902 is: -0.0001734860796684311\n",
            "reward of step 21903 is: -0.0001647937566101721\n",
            "reward of step 21904 is: -0.00016085328211598313\n",
            "reward of step 21905 is: -0.0001592419013425165\n",
            "reward of step 21906 is: -0.00017630212078514258\n",
            "reward of step 21907 is: -0.00016658367258711186\n",
            "reward of step 21908 is: -0.00017534711156210367\n",
            "reward of step 21909 is: -0.00015795954191605684\n",
            "reward of step 21910 is: -0.0001654193187118209\n",
            "reward of step 21911 is: -0.00016686312835288562\n",
            "reward of step 21912 is: -0.00016609141215527762\n",
            "reward of step 21913 is: -0.00015335484611726745\n",
            "reward of step 21914 is: -0.0001703428909867458\n",
            "reward of step 21915 is: -0.00015926141988665892\n",
            "reward of step 21916 is: -0.0001667316784336979\n",
            "reward of step 21917 is: -0.0001718488439309053\n",
            "reward of step 21918 is: -0.00016953753724810688\n",
            "reward of step 21919 is: -0.00017020178435906013\n",
            "reward of step 21920 is: -0.00016597539970516974\n",
            "reward of step 21921 is: -0.0001640359409680169\n",
            "reward of step 21922 is: -0.00015773934293815837\n",
            "reward of step 21923 is: -0.00017254466445929716\n",
            "reward of step 21924 is: -0.00016865287863474863\n",
            "reward of step 21925 is: -0.0001638507668392425\n",
            "reward of step 21926 is: -0.00016452740808651066\n",
            "reward of step 21927 is: -0.0001656208923433029\n",
            "reward of step 21928 is: -0.00017087873046539657\n",
            "reward of step 21929 is: -0.00016196125152732595\n",
            "reward of step 21930 is: -0.0001695734881453957\n",
            "reward of step 21931 is: -0.00017009217817215137\n",
            "reward of step 21932 is: -0.00017114033372747213\n",
            "reward of step 21933 is: -0.00017209500699119436\n",
            "reward of step 21934 is: -0.00016885368123009247\n",
            "reward of step 21935 is: -0.00016125575639320682\n",
            "reward of step 21936 is: -0.00016848512943605257\n",
            "reward of step 21937 is: -0.00016843028419433366\n",
            "reward of step 21938 is: -0.00017484928732472448\n",
            "reward of step 21939 is: -0.00017052088640503692\n",
            "reward of step 21940 is: -0.00018010543820188844\n",
            "reward of step 21941 is: -0.00017051651018587933\n",
            "reward of step 21942 is: -0.00017796259956014102\n",
            "reward of step 21943 is: -0.0001683019847654042\n",
            "reward of step 21944 is: -0.000153188313724913\n",
            "reward of step 21945 is: -0.00016317533122823467\n",
            "reward of step 21946 is: -0.0001761172848746024\n",
            "reward of step 21947 is: -0.00016456394251544105\n",
            "reward of step 21948 is: -0.00017258026043201293\n",
            "reward of step 21949 is: -0.0001696409734046142\n",
            "reward of step 21950 is: -0.00016014685908294251\n",
            "reward of step 21951 is: -0.00017706484983487657\n",
            "reward of step 21952 is: -0.00015562576178640363\n",
            "reward of step 21953 is: -0.0001557730702649378\n",
            "reward of step 21954 is: -0.00017090585563209578\n",
            "reward of step 21955 is: -0.00017829824208558874\n",
            "reward of step 21956 is: -0.00017577863660351854\n",
            "reward of step 21957 is: -0.0001592633877484609\n",
            "reward of step 21958 is: -0.00017080380799277487\n",
            "reward of step 21959 is: -0.00016209394515967354\n",
            "reward of step 21960 is: -0.00018075260706669377\n",
            "reward of step 21961 is: -0.0001609187896978573\n",
            "reward of step 21962 is: -0.000156674279573241\n",
            "reward of step 21963 is: -0.00016088611545431487\n",
            "reward of step 21964 is: -0.00017322368654869484\n",
            "reward of step 21965 is: -0.00016096359394683537\n",
            "reward of step 21966 is: -0.0001678742438097761\n",
            "reward of step 21967 is: -0.00016495701931066228\n",
            "reward of step 21968 is: -0.00015524933771332515\n",
            "reward of step 21969 is: -0.00017294850497014068\n",
            "reward of step 21970 is: -0.0001565025081648814\n",
            "reward of step 21971 is: -0.00015747752840611983\n",
            "reward of step 21972 is: -0.00017539366632817802\n",
            "reward of step 21973 is: -0.0001635738880201318\n",
            "reward of step 21974 is: -0.00015844529319688081\n",
            "reward of step 21975 is: -0.00017184654950068968\n",
            "reward of step 21976 is: -0.00016286400751594797\n",
            "reward of step 21977 is: -0.00017623361923759488\n",
            "reward of step 21978 is: -0.00016387108292204667\n",
            "reward of step 21979 is: -0.0001620379977234457\n",
            "reward of step 21980 is: -0.00015641899313461214\n",
            "reward of step 21981 is: -0.00016697482413953346\n",
            "reward of step 21982 is: -0.0001576795796396542\n",
            "reward of step 21983 is: -0.00017315937866635295\n",
            "reward of step 21984 is: -0.00016877993264909007\n",
            "reward of step 21985 is: -0.00016387720048622375\n",
            "reward of step 21986 is: -0.00017085245964777875\n",
            "reward of step 21987 is: -0.00016509560364880602\n",
            "reward of step 21988 is: -0.0001749091466984246\n",
            "reward of step 21989 is: -0.00016353435421940891\n",
            "reward of step 21990 is: -0.00016388463021106342\n",
            "reward of step 21991 is: -0.00015968346333903005\n",
            "reward of step 21992 is: -0.0001651709661856417\n",
            "reward of step 21993 is: -0.00016873159078553766\n",
            "reward of step 21994 is: -0.00016710258031828106\n",
            "reward of step 21995 is: -0.00016966705587735876\n",
            "reward of step 21996 is: -0.00016365073083497996\n",
            "reward of step 21997 is: -0.00016494220117139365\n",
            "reward of step 21998 is: -0.00016800580329399148\n",
            "reward of step 21999 is: -0.000170687674615491\n",
            "reward of step 22000 is: -0.0001686308405530951\n",
            "reward of step 22001 is: -4.106697659875589e-05\n",
            "reward of step 22002 is: 0.00013137818951293025\n",
            "reward of step 22003 is: 0.00013948768670487237\n",
            "reward of step 22004 is: 0.00013418341801762145\n",
            "reward of step 22005 is: 0.00012198018023024233\n",
            "reward of step 22006 is: 0.0001480727639363532\n",
            "reward of step 22007 is: 0.00011131603007343227\n",
            "reward of step 22008 is: 0.00012414879440087777\n",
            "reward of step 22009 is: 0.00013702467698668695\n",
            "reward of step 22010 is: 0.00012286228724499944\n",
            "reward of step 22011 is: 0.00013240229370594286\n",
            "reward of step 22012 is: 0.00012367404543056049\n",
            "reward of step 22013 is: 0.00012888788787380004\n",
            "reward of step 22014 is: 0.00013140541748988432\n",
            "reward of step 22015 is: 0.00013098312554506253\n",
            "reward of step 22016 is: 0.00013331544834005227\n",
            "reward of step 22017 is: 0.0001150344698808488\n",
            "reward of step 22018 is: 0.00014081352209494087\n",
            "reward of step 22019 is: 0.00011768967795365821\n",
            "reward of step 22020 is: 0.00012333518286818178\n",
            "reward of step 22021 is: 0.00012595960130803784\n",
            "reward of step 22022 is: 0.0001305330690872531\n",
            "reward of step 22023 is: 0.00014029965695083502\n",
            "reward of step 22024 is: 0.00013651578742742627\n",
            "reward of step 22025 is: 0.00014566815506808904\n",
            "reward of step 22026 is: 0.00012664345563296556\n",
            "reward of step 22027 is: 1.2029716812395224e-05\n",
            "reward of step 22028 is: -0.00015072004966325774\n",
            "reward of step 22029 is: 7.262588742119793e-05\n",
            "reward of step 22030 is: 0.00012838149786077661\n",
            "reward of step 22031 is: 0.00012420016282295129\n",
            "reward of step 22032 is: 0.00014160666469777928\n",
            "reward of step 22033 is: 0.0001306414218427574\n",
            "reward of step 22034 is: 0.00014229173946601602\n",
            "reward of step 22035 is: 0.0001263519791453603\n",
            "reward of step 22036 is: 0.00011573337356631477\n",
            "reward of step 22037 is: 0.00013631231684266588\n",
            "reward of step 22038 is: 0.0001348559650952772\n",
            "reward of step 22039 is: 0.00011897142381951053\n",
            "reward of step 22040 is: 0.0001300502020413824\n",
            "reward of step 22041 is: 0.0001433107807887058\n",
            "reward of step 22042 is: 0.00014336925807692486\n",
            "reward of step 22043 is: 0.00013545621477319535\n",
            "reward of step 22044 is: 0.00013759491638725365\n",
            "reward of step 22045 is: 0.00013869561745594432\n",
            "reward of step 22046 is: 0.0001139689334447307\n",
            "reward of step 22047 is: 0.00013173446572765473\n",
            "reward of step 22048 is: 0.0001247460950280577\n",
            "reward of step 22049 is: 0.00014439327122910155\n",
            "reward of step 22050 is: 0.00011936998235877668\n",
            "reward of step 22051 is: 0.00012990959934572742\n",
            "reward of step 22052 is: 0.00012633869283692757\n",
            "reward of step 22053 is: 0.00012583423701806573\n",
            "reward of step 22054 is: 0.0001291599585915649\n",
            "reward of step 22055 is: 0.0001249807314090157\n",
            "reward of step 22056 is: 0.0001221165342452031\n",
            "reward of step 22057 is: 0.00013324947381339032\n",
            "reward of step 22058 is: 0.0001288891483015002\n",
            "reward of step 22059 is: 0.00013109034187712518\n",
            "reward of step 22060 is: 0.00014333392701792203\n",
            "reward of step 22061 is: 0.0001460803852223468\n",
            "reward of step 22062 is: 0.00013620995574638927\n",
            "reward of step 22063 is: 0.0001285101087336317\n",
            "reward of step 22064 is: 0.00012279239075017187\n",
            "reward of step 22065 is: 0.0001287280613460041\n",
            "reward of step 22066 is: 0.0001247709513520972\n",
            "reward of step 22067 is: 0.0001315881075205016\n",
            "reward of step 22068 is: 0.00013059624102643597\n",
            "reward of step 22069 is: 0.00011632459253976056\n",
            "reward of step 22070 is: 0.0001436796162266299\n",
            "reward of step 22071 is: 0.00013216245446221237\n",
            "reward of step 22072 is: 0.00013633770877605778\n",
            "reward of step 22073 is: 0.00013583561102239512\n",
            "reward of step 22074 is: 0.00012240292018197697\n",
            "reward of step 22075 is: 0.00013706647702254918\n",
            "reward of step 22076 is: 0.00012093833990992539\n",
            "reward of step 22077 is: 0.00014210606082874826\n",
            "reward of step 22078 is: 0.00013097810893928705\n",
            "reward of step 22079 is: 0.0001308205048563641\n",
            "reward of step 22080 is: 0.0001321324709162929\n",
            "reward of step 22081 is: 0.0001229285035158076\n",
            "reward of step 22082 is: 0.00013269618345830103\n",
            "reward of step 22083 is: 0.00012935047119521598\n",
            "reward of step 22084 is: 0.0001362025026612345\n",
            "reward of step 22085 is: 0.00011482392171965598\n",
            "reward of step 22086 is: 0.00012302210839035488\n",
            "reward of step 22087 is: 0.0001297268409640748\n",
            "reward of step 22088 is: 0.00013118995324478756\n",
            "reward of step 22089 is: 0.00013296152427277517\n",
            "reward of step 22090 is: 0.0001307939154941115\n",
            "reward of step 22091 is: 0.0001278745463674995\n",
            "reward of step 22092 is: 0.0001339616747195856\n",
            "reward of step 22093 is: 0.00013524685283264508\n",
            "reward of step 22094 is: 0.00013233229850025447\n",
            "reward of step 22095 is: 0.000127604188479933\n",
            "reward of step 22096 is: 0.0001144959858518093\n",
            "reward of step 22097 is: 0.0001354932790074158\n",
            "reward of step 22098 is: 0.00012794057612912398\n",
            "reward of step 22099 is: 0.0001173230838253443\n",
            "reward of step 22100 is: 0.00012944216737505548\n",
            "reward of step 22101 is: 0.0001351317863044562\n",
            "reward of step 22102 is: 0.00013228361317781537\n",
            "reward of step 22103 is: 0.00011673736252017564\n",
            "reward of step 22104 is: 0.0001274141349166273\n",
            "reward of step 22105 is: 0.00012502215632564465\n",
            "reward of step 22106 is: 0.0001306503924463271\n",
            "reward of step 22107 is: 0.00011858392663790497\n",
            "reward of step 22108 is: 0.00013212169354233399\n",
            "reward of step 22109 is: 0.00013718192743894278\n",
            "reward of step 22110 is: 0.00011951906669374983\n",
            "reward of step 22111 is: 0.00013371277212013082\n",
            "reward of step 22112 is: 0.00012828992725109082\n",
            "reward of step 22113 is: 0.00013333192470886524\n",
            "reward of step 22114 is: 0.00012668978205124194\n",
            "reward of step 22115 is: 0.00012833687417940313\n",
            "reward of step 22116 is: 0.00012448320275846854\n",
            "reward of step 22117 is: 0.0001307634946833061\n",
            "reward of step 22118 is: 0.00012875687604236126\n",
            "reward of step 22119 is: 0.00011835469652824079\n",
            "reward of step 22120 is: 0.00011642753815777431\n",
            "reward of step 22121 is: 0.00013646945265723817\n",
            "reward of step 22122 is: 0.00012021972819187265\n",
            "reward of step 22123 is: 0.00013666909492862062\n",
            "reward of step 22124 is: 0.00012100448658354748\n",
            "reward of step 22125 is: 0.0001391346034321282\n",
            "reward of step 22126 is: 0.00013871266071330734\n",
            "reward of step 22127 is: 0.00012438265265969582\n",
            "reward of step 22128 is: 0.00012530379124442632\n",
            "reward of step 22129 is: 0.00012657882577340709\n",
            "reward of step 22130 is: 0.0001289843041037715\n",
            "reward of step 22131 is: 0.0001379844451453438\n",
            "reward of step 22132 is: 0.0001284536307529337\n",
            "reward of step 22133 is: 0.00012886741418108994\n",
            "reward of step 22134 is: 0.00014015077561825877\n",
            "reward of step 22135 is: 0.00011771781838078539\n",
            "reward of step 22136 is: 0.0001346029467204252\n",
            "reward of step 22137 is: 0.0001259035138398989\n",
            "reward of step 22138 is: 0.00011757590689390884\n",
            "reward of step 22139 is: 0.00013623179286642795\n",
            "reward of step 22140 is: 0.00013579262501372868\n",
            "reward of step 22141 is: 0.00013614756539853236\n",
            "reward of step 22142 is: 0.00013647795127329096\n",
            "reward of step 22143 is: 0.00013465603866123988\n",
            "reward of step 22144 is: 0.00012725897244104522\n",
            "reward of step 22145 is: 0.00012911711799897286\n",
            "reward of step 22146 is: 0.0001363382401572943\n",
            "reward of step 22147 is: 0.00014421144623044622\n",
            "reward of step 22148 is: 0.0001330172660534821\n",
            "reward of step 22149 is: 0.00013163223273904962\n",
            "reward of step 22150 is: 0.00013266692400903645\n",
            "reward of step 22151 is: 0.00011963185251087955\n",
            "reward of step 22152 is: 0.0001257606835980041\n",
            "reward of step 22153 is: 0.00012477126352515176\n",
            "reward of step 22154 is: 0.0001266578685332139\n",
            "reward of step 22155 is: 0.00012010193550684958\n",
            "reward of step 22156 is: 0.00013512471155123468\n",
            "reward of step 22157 is: 0.00013068101813847822\n",
            "reward of step 22158 is: 0.0001221535659551187\n",
            "reward of step 22159 is: 0.00014055210545317024\n",
            "reward of step 22160 is: 0.00013053261710690317\n",
            "reward of step 22161 is: 0.00012901500662109157\n",
            "reward of step 22162 is: 0.0001272493070458239\n",
            "reward of step 22163 is: 0.000124730262167996\n",
            "reward of step 22164 is: 0.00011597506481997981\n",
            "reward of step 22165 is: 0.0001230460864187475\n",
            "reward of step 22166 is: 0.00012699904626430498\n",
            "reward of step 22167 is: 0.00013757769302737195\n",
            "reward of step 22168 is: 0.00012951328301925922\n",
            "reward of step 22169 is: 0.0001128729064836854\n",
            "reward of step 22170 is: 0.00013788401827107477\n",
            "reward of step 22171 is: 0.00011963911872636038\n",
            "reward of step 22172 is: 0.00012716176488792482\n",
            "reward of step 22173 is: 0.00012297697933219497\n",
            "reward of step 22174 is: 0.00013101278828310024\n",
            "reward of step 22175 is: 0.0001247909779611862\n",
            "reward of step 22176 is: 0.00014432490278109983\n",
            "reward of step 22177 is: 0.00012974226645406478\n",
            "reward of step 22178 is: 0.0001422913581130025\n",
            "reward of step 22179 is: 0.00012468054151963383\n",
            "reward of step 22180 is: 0.00010994434282560374\n",
            "reward of step 22181 is: 0.00012908299867302132\n",
            "reward of step 22182 is: 0.00014324355559677598\n",
            "reward of step 22183 is: 0.0001240941258892028\n",
            "reward of step 22184 is: 0.00012312414377872534\n",
            "reward of step 22185 is: 0.00013071541155462718\n",
            "reward of step 22186 is: 0.0001348221846262675\n",
            "reward of step 22187 is: 0.0001374433450648199\n",
            "reward of step 22188 is: 0.00013753712133641937\n",
            "reward of step 22189 is: 0.00013274136123455808\n",
            "reward of step 22190 is: 0.00011813606807491784\n",
            "reward of step 22191 is: 0.0001332165375789304\n",
            "reward of step 22192 is: 0.00012235399517432458\n",
            "reward of step 22193 is: 0.00013205351779875166\n",
            "reward of step 22194 is: 0.00011995076116845051\n",
            "reward of step 22195 is: 0.0001228471754931166\n",
            "reward of step 22196 is: 0.00013352461908822772\n",
            "reward of step 22197 is: 0.0001485351576314636\n",
            "reward of step 22198 is: 0.00013603995945670296\n",
            "reward of step 22199 is: 0.00013291739012438796\n",
            "reward of step 22200 is: 0.00012175929072309455\n",
            "reward of step 22201 is: 0.0001323096797479545\n",
            "reward of step 22202 is: 0.00013510203753255674\n",
            "reward of step 22203 is: 0.00012452514815337377\n",
            "reward of step 22204 is: 0.0001319406750263802\n",
            "reward of step 22205 is: 0.0001304567682165931\n",
            "reward of step 22206 is: 0.0001430734429273232\n",
            "reward of step 22207 is: 0.00013141061182046174\n",
            "reward of step 22208 is: 0.00012772607787562415\n",
            "reward of step 22209 is: 0.00014192253952786948\n",
            "reward of step 22210 is: 0.00012743029755540237\n",
            "reward of step 22211 is: 0.00014419725047532667\n",
            "reward of step 22212 is: 0.00013298265791932744\n",
            "reward of step 22213 is: 0.00013355405394766635\n",
            "reward of step 22214 is: 0.00013168810440817905\n",
            "reward of step 22215 is: 0.00013518045164485478\n",
            "reward of step 22216 is: 0.0001286927924966583\n",
            "reward of step 22217 is: 0.0001230249035490308\n",
            "reward of step 22218 is: 0.0001318128642890089\n",
            "reward of step 22219 is: 0.00013068559138888528\n",
            "reward of step 22220 is: 0.00012532422655752847\n",
            "reward of step 22221 is: 0.0001266674411774432\n",
            "reward of step 22222 is: 0.00012849199548655902\n",
            "reward of step 22223 is: 0.00011791805691497705\n",
            "reward of step 22224 is: 0.00013485493135799738\n",
            "reward of step 22225 is: 0.00012660797220796432\n",
            "reward of step 22226 is: 0.00013770134007738019\n",
            "reward of step 22227 is: 0.0001267998146214684\n",
            "reward of step 22228 is: 0.00013411443294628346\n",
            "reward of step 22229 is: 0.00012766641873792343\n",
            "reward of step 22230 is: 0.00014338779589237227\n",
            "reward of step 22231 is: 0.00011893736639563934\n",
            "reward of step 22232 is: 0.00014074926391763405\n",
            "reward of step 22233 is: 0.00014050145714103067\n",
            "reward of step 22234 is: 0.0001307470227195327\n",
            "reward of step 22235 is: 0.00012156238851016761\n",
            "reward of step 22236 is: 0.00013425512973381812\n",
            "reward of step 22237 is: 0.00014300161097245237\n",
            "reward of step 22238 is: 0.0001295393474885441\n",
            "reward of step 22239 is: 0.00012356570109488973\n",
            "reward of step 22240 is: 0.00012599901067489165\n",
            "reward of step 22241 is: 0.00013591684498182803\n",
            "reward of step 22242 is: 0.00012751099729220588\n",
            "reward of step 22243 is: 0.00013679018091945983\n",
            "reward of step 22244 is: 0.00012896437209951306\n",
            "reward of step 22245 is: 0.00012497260135478294\n",
            "reward of step 22246 is: 0.0001277667439371389\n",
            "reward of step 22247 is: 0.00013307961327728576\n",
            "reward of step 22248 is: 0.00011393436022702919\n",
            "reward of step 22249 is: 0.00014285224534221451\n",
            "reward of step 22250 is: 0.0001254244533031895\n",
            "reward of step 22251 is: 0.00012737086107741347\n",
            "reward of step 22252 is: 0.00012162217616664431\n",
            "reward of step 22253 is: 0.00011938833199585816\n",
            "reward of step 22254 is: 0.00012432645260649884\n",
            "reward of step 22255 is: 0.00011984667838702908\n",
            "reward of step 22256 is: 0.00013515668461515246\n",
            "reward of step 22257 is: 0.0001282932585335348\n",
            "reward of step 22258 is: 0.0001257765989930411\n",
            "reward of step 22259 is: 0.00013059661678394165\n",
            "reward of step 22260 is: 0.00012872764229541534\n",
            "reward of step 22261 is: 0.000137679177630457\n",
            "reward of step 22262 is: 0.000134310931157862\n",
            "reward of step 22263 is: 0.00014192088877601895\n",
            "reward of step 22264 is: 0.00012794418480191206\n",
            "reward of step 22265 is: 0.00013141343953902628\n",
            "reward of step 22266 is: 0.00013323320046687993\n",
            "reward of step 22267 is: 0.00012830910618740753\n",
            "reward of step 22268 is: 0.00011677203690875058\n",
            "reward of step 22269 is: 0.00012714655298560877\n",
            "reward of step 22270 is: 0.00012783456218979034\n",
            "reward of step 22271 is: 0.00012562579954836033\n",
            "reward of step 22272 is: 0.00013938456886378284\n",
            "reward of step 22273 is: 0.00011631641807716604\n",
            "reward of step 22274 is: 0.00011857638078570979\n",
            "reward of step 22275 is: 0.00011489006045584616\n",
            "reward of step 22276 is: 0.00013309732441989938\n",
            "reward of step 22277 is: 0.00013297509400617832\n",
            "reward of step 22278 is: 0.0001268752245962806\n",
            "reward of step 22279 is: 0.00012818066354526833\n",
            "reward of step 22280 is: 0.00011861184885954283\n",
            "reward of step 22281 is: 0.000125251558356067\n",
            "reward of step 22282 is: 0.00012930980008340445\n",
            "reward of step 22283 is: 0.00012112417124021373\n",
            "reward of step 22284 is: 0.00012771667961930438\n",
            "reward of step 22285 is: 0.00013822246816810074\n",
            "reward of step 22286 is: 0.00013506707220515014\n",
            "reward of step 22287 is: 0.00012699480199843252\n",
            "reward of step 22288 is: 0.00011792479297405254\n",
            "reward of step 22289 is: 0.00012842815213436458\n",
            "reward of step 22290 is: 0.00012213946066904033\n",
            "reward of step 22291 is: 0.0001445616332807594\n",
            "reward of step 22292 is: 0.00013175592223856321\n",
            "reward of step 22293 is: 0.00013329584427176043\n",
            "reward of step 22294 is: 0.00013474824075552355\n",
            "reward of step 22295 is: 0.00011580733670927258\n",
            "reward of step 22296 is: 0.00012814962514431398\n",
            "reward of step 22297 is: 0.00013247642446770474\n",
            "reward of step 22298 is: 0.0001340905448141281\n",
            "reward of step 22299 is: 0.00011808522132105249\n",
            "reward of step 22300 is: 0.0001275267660386697\n",
            "reward of step 22301 is: 0.00013628789069162716\n",
            "reward of step 22302 is: 0.00012833808641046318\n",
            "reward of step 22303 is: 0.00013698424076871854\n",
            "reward of step 22304 is: 0.00012973617935494632\n",
            "reward of step 22305 is: 0.0001250990030708036\n",
            "reward of step 22306 is: 0.00012398988256520372\n",
            "reward of step 22307 is: 0.0001341108484587485\n",
            "reward of step 22308 is: 0.00013562512658348567\n",
            "reward of step 22309 is: 0.00012528643876073972\n",
            "reward of step 22310 is: 0.00014449026825578135\n",
            "reward of step 22311 is: 0.00012522534301736017\n",
            "reward of step 22312 is: 0.0001235460630370194\n",
            "reward of step 22313 is: 0.00012355419562849108\n",
            "reward of step 22314 is: 0.0001342810375368381\n",
            "reward of step 22315 is: 0.00013234821584495138\n",
            "reward of step 22316 is: 0.00013077615935027496\n",
            "reward of step 22317 is: 0.0001260990643354982\n",
            "reward of step 22318 is: 0.0001283630468181927\n",
            "reward of step 22319 is: 0.00013336386683011008\n",
            "reward of step 22320 is: 0.00014723445915530364\n",
            "reward of step 22321 is: 0.00012545857381463237\n",
            "reward of step 22322 is: 0.0001283551066683807\n",
            "reward of step 22323 is: 0.00012079531493647223\n",
            "reward of step 22324 is: 0.00013893917476409586\n",
            "reward of step 22325 is: 0.00013117114809585147\n",
            "reward of step 22326 is: 0.00013705899300437254\n",
            "reward of step 22327 is: 0.00012450339423179492\n",
            "reward of step 22328 is: 0.0001281021270005053\n",
            "reward of step 22329 is: 0.0001193145414436766\n",
            "reward of step 22330 is: 0.00012797819363598642\n",
            "reward of step 22331 is: 0.0001334700430238202\n",
            "reward of step 22332 is: 0.0001321252367807988\n",
            "reward of step 22333 is: 0.00012359336407026048\n",
            "reward of step 22334 is: 0.00013016441392349484\n",
            "reward of step 22335 is: 0.00012767956960679157\n",
            "reward of step 22336 is: 0.000136013190938063\n",
            "reward of step 22337 is: 0.00013552174419270412\n",
            "reward of step 22338 is: 0.00013964283865149226\n",
            "reward of step 22339 is: 0.00012346086026686492\n",
            "reward of step 22340 is: 0.00012159186756480582\n",
            "reward of step 22341 is: 0.00013671681755928925\n",
            "reward of step 22342 is: 0.00011540565265016392\n",
            "reward of step 22343 is: 0.00013321138141862997\n",
            "reward of step 22344 is: 0.0001269590903478359\n",
            "reward of step 22345 is: 0.00014432612910584425\n",
            "reward of step 22346 is: 0.00012945086695605559\n",
            "reward of step 22347 is: 0.00011845433357985185\n",
            "reward of step 22348 is: 0.00013784145817313394\n",
            "reward of step 22349 is: 0.0001433511573785165\n",
            "reward of step 22350 is: 0.00014269039275555817\n",
            "reward of step 22351 is: 0.00011908440827895712\n",
            "reward of step 22352 is: 0.00013022230020501754\n",
            "reward of step 22353 is: 0.0001356827578766817\n",
            "reward of step 22354 is: 0.00012004337206856822\n",
            "reward of step 22355 is: 0.00012924162768292\n",
            "reward of step 22356 is: 0.00012294738750594895\n",
            "reward of step 22357 is: 0.00013508305303898836\n",
            "reward of step 22358 is: 0.00012809302658046127\n",
            "reward of step 22359 is: 0.000119800930493737\n",
            "reward of step 22360 is: 0.0001257561599714629\n",
            "reward of step 22361 is: 0.00012543626630565912\n",
            "reward of step 22362 is: 0.00013078155497266885\n",
            "reward of step 22363 is: 0.000133222002695732\n",
            "reward of step 22364 is: 0.0001280980594663569\n",
            "reward of step 22365 is: 0.00011754798009384688\n",
            "reward of step 22366 is: 0.00011828112231033139\n",
            "reward of step 22367 is: 0.00012273904214487398\n",
            "reward of step 22368 is: 0.00014845185461636172\n",
            "reward of step 22369 is: 0.00012350147420037247\n",
            "reward of step 22370 is: 0.0001242097786520741\n",
            "reward of step 22371 is: 0.00011593307358892006\n",
            "reward of step 22372 is: 0.00012918236415362418\n",
            "reward of step 22373 is: 0.00013672617523449935\n",
            "reward of step 22374 is: 0.00012893991409551692\n",
            "reward of step 22375 is: 0.0001315118665374245\n",
            "reward of step 22376 is: 0.00014058889313779533\n",
            "reward of step 22377 is: 0.00012816816257955874\n",
            "reward of step 22378 is: 0.0001349258778264621\n",
            "reward of step 22379 is: 0.0001471859703640448\n",
            "reward of step 22380 is: 0.00012685157044583668\n",
            "reward of step 22381 is: 0.00011753460157594612\n",
            "reward of step 22382 is: 0.00012321828734555864\n",
            "reward of step 22383 is: 0.0001321862017246444\n",
            "reward of step 22384 is: 0.00012287707272737246\n",
            "reward of step 22385 is: 0.00011918306007306972\n",
            "reward of step 22386 is: 0.00014205982508201477\n",
            "reward of step 22387 is: 0.00013813058055446483\n",
            "reward of step 22388 is: 0.00012215839161375358\n",
            "reward of step 22389 is: 0.0001380453120440364\n",
            "reward of step 22390 is: 0.00013038340964892522\n",
            "reward of step 22391 is: 0.0001345897687479263\n",
            "reward of step 22392 is: 0.00014472661306280356\n",
            "reward of step 22393 is: 0.0001445654363908267\n",
            "reward of step 22394 is: 0.00013681364235350085\n",
            "reward of step 22395 is: 0.00014424674457978718\n",
            "reward of step 22396 is: 0.00013445719565966627\n",
            "reward of step 22397 is: 0.00012982730232505383\n",
            "reward of step 22398 is: 0.0001196602177902858\n",
            "reward of step 22399 is: 0.0001297724704647335\n",
            "reward of step 22400 is: 0.00011670100435327\n",
            "reward of step 22401 is: 0.00013040301262180626\n",
            "reward of step 22402 is: 0.00012974751757273387\n",
            "reward of step 22403 is: 0.00013207271127077988\n",
            "reward of step 22404 is: 0.0001403260851195346\n",
            "reward of step 22405 is: 0.00013722367418649934\n",
            "reward of step 22406 is: 0.0001250843616378137\n",
            "reward of step 22407 is: 0.00012843672226852453\n",
            "reward of step 22408 is: 0.00013355510229402234\n",
            "reward of step 22409 is: 0.00013406360012059042\n",
            "reward of step 22410 is: 0.00013151694131987776\n",
            "reward of step 22411 is: 0.00011733175267194702\n",
            "reward of step 22412 is: 0.0001301585173815349\n",
            "reward of step 22413 is: 0.00013312427465454225\n",
            "reward of step 22414 is: 0.00013871023265549047\n",
            "reward of step 22415 is: 0.0001222023094840588\n",
            "reward of step 22416 is: 0.00013611400342496065\n",
            "reward of step 22417 is: 0.00012588505211982785\n",
            "reward of step 22418 is: 0.0001222250758744355\n",
            "reward of step 22419 is: 0.0001269302936015589\n",
            "reward of step 22420 is: 0.00012891098389577807\n",
            "reward of step 22421 is: 0.00012374885577374155\n",
            "reward of step 22422 is: 0.00011773680540440987\n",
            "reward of step 22423 is: 0.00014105069273642927\n",
            "reward of step 22424 is: 0.00013068424313468876\n",
            "reward of step 22425 is: 0.0001432729434288251\n",
            "reward of step 22426 is: 0.00013081823289428198\n",
            "reward of step 22427 is: 0.00012170589483316572\n",
            "reward of step 22428 is: 0.00012043305014969754\n",
            "reward of step 22429 is: 0.00012312501612875604\n",
            "reward of step 22430 is: 0.00011985442370813061\n",
            "reward of step 22431 is: 0.00012317407790802032\n",
            "reward of step 22432 is: 0.00012321843743813638\n",
            "reward of step 22433 is: 0.00012495701804974118\n",
            "reward of step 22434 is: 0.00012712624755727983\n",
            "reward of step 22435 is: 0.00012345571338338024\n",
            "reward of step 22436 is: 0.00012662645168454737\n",
            "reward of step 22437 is: 0.00012045292649016835\n",
            "reward of step 22438 is: 0.00014138382818088796\n",
            "reward of step 22439 is: 0.00012744933804879793\n",
            "reward of step 22440 is: 0.00014381903275336558\n",
            "reward of step 22441 is: 0.00012008168874948784\n",
            "reward of step 22442 is: 0.00012642908946350554\n",
            "reward of step 22443 is: 0.00012277511564839382\n",
            "reward of step 22444 is: 0.00012788841885605592\n",
            "reward of step 22445 is: 0.00014308848843868607\n",
            "reward of step 22446 is: 0.0001328998091656369\n",
            "reward of step 22447 is: 0.00011528973492128759\n",
            "reward of step 22448 is: 0.00014320448153211772\n",
            "reward of step 22449 is: 0.0001389795761348216\n",
            "reward of step 22450 is: 0.00013530075974507144\n",
            "reward of step 22451 is: 0.00013457955952980122\n",
            "reward of step 22452 is: 0.0001374041796544987\n",
            "reward of step 22453 is: 0.00013738578677006196\n",
            "reward of step 22454 is: 0.0001461469314284671\n",
            "reward of step 22455 is: 0.0001348714775736003\n",
            "reward of step 22456 is: 0.00012902790533352588\n",
            "reward of step 22457 is: 0.00013736193148575402\n",
            "reward of step 22458 is: 0.00014005402394932928\n",
            "reward of step 22459 is: 0.00012262365492251597\n",
            "reward of step 22460 is: 0.00012009867966474759\n",
            "reward of step 22461 is: 0.00012163050539573263\n",
            "reward of step 22462 is: 0.0001297334722627289\n",
            "reward of step 22463 is: 0.0001130941528811552\n",
            "reward of step 22464 is: 0.0001185916774218929\n",
            "reward of step 22465 is: 0.00013953986170203\n",
            "reward of step 22466 is: 0.0001369014112643734\n",
            "reward of step 22467 is: 0.0001404806609016727\n",
            "reward of step 22468 is: 0.00012551312678212863\n",
            "reward of step 22469 is: 0.00012460132116956402\n",
            "reward of step 22470 is: 0.00012248854728269236\n",
            "reward of step 22471 is: 0.00013699286934644572\n",
            "reward of step 22472 is: 0.0001258206355755475\n",
            "reward of step 22473 is: 0.0001232360531676569\n",
            "reward of step 22474 is: 0.0001263513132308331\n",
            "reward of step 22475 is: 0.00012722094241677262\n",
            "reward of step 22476 is: 0.00012673836974773717\n",
            "reward of step 22477 is: 0.00012833191849871096\n",
            "reward of step 22478 is: 0.00013933902602158063\n",
            "reward of step 22479 is: 0.0001185814330771464\n",
            "reward of step 22480 is: 0.0001275168411424441\n",
            "reward of step 22481 is: 0.00013575472249096373\n",
            "reward of step 22482 is: 0.0001278770066907095\n",
            "reward of step 22483 is: 0.00013115810925925345\n",
            "reward of step 22484 is: 0.00012784367886951831\n",
            "reward of step 22485 is: 0.0001224479946590158\n",
            "reward of step 22486 is: 0.00012597926154988594\n",
            "reward of step 22487 is: 0.00012547936730851353\n",
            "reward of step 22488 is: 0.0001241110244250281\n",
            "reward of step 22489 is: 0.0001421246443004985\n",
            "reward of step 22490 is: 0.0001445973570536933\n",
            "reward of step 22491 is: 0.00013823732143150865\n",
            "reward of step 22492 is: 0.00014151866644735724\n",
            "reward of step 22493 is: 0.0001220814940025464\n",
            "reward of step 22494 is: 0.0001257733042409908\n",
            "reward of step 22495 is: 0.00012116231609528084\n",
            "reward of step 22496 is: 0.00013753255876189195\n",
            "reward of step 22497 is: 0.00013812638634042617\n",
            "reward of step 22498 is: 0.00011999721199035426\n",
            "reward of step 22499 is: 0.00014391442257956032\n",
            "reward of step 22500 is: 0.00012948372855910506\n",
            "reward of step 22501 is: 0.00011383295263599917\n",
            "reward of step 22502 is: 0.00012550322822100032\n",
            "reward of step 22503 is: 0.00012539527020378606\n",
            "reward of step 22504 is: 0.0001375260911916711\n",
            "reward of step 22505 is: 0.0001375659845751068\n",
            "reward of step 22506 is: 0.00013085358533669006\n",
            "reward of step 22507 is: 0.00012913369062353148\n",
            "reward of step 22508 is: 0.00012234744772570696\n",
            "reward of step 22509 is: 0.0001410343442462106\n",
            "reward of step 22510 is: 0.0001261718741035603\n",
            "reward of step 22511 is: 0.00012351950642571651\n",
            "reward of step 22512 is: 0.00012311459100316694\n",
            "reward of step 22513 is: 0.0001364603169291337\n",
            "reward of step 22514 is: 0.0001464872996941369\n",
            "reward of step 22515 is: 0.000144034737643924\n",
            "reward of step 22516 is: 0.00012723929982983099\n",
            "reward of step 22517 is: 0.00012620405197036338\n",
            "reward of step 22518 is: 0.00011155475557682095\n",
            "reward of step 22519 is: 0.00012452410967616118\n",
            "reward of step 22520 is: 0.0001352682012198944\n",
            "reward of step 22521 is: 0.00012127853714115428\n",
            "reward of step 22522 is: 0.0001196451455183722\n",
            "reward of step 22523 is: 0.00013056575962148683\n",
            "reward of step 22524 is: 0.00011845824875166572\n",
            "reward of step 22525 is: 0.00012405982625893645\n",
            "reward of step 22526 is: 0.0001321416784419844\n",
            "reward of step 22527 is: 0.00013203587188434314\n",
            "reward of step 22528 is: 0.0001299668687907099\n",
            "reward of step 22529 is: 0.0001269749219881795\n",
            "reward of step 22530 is: 0.00014159980415756084\n",
            "reward of step 22531 is: 0.00013322327470196294\n",
            "reward of step 22532 is: 0.0001235703331139855\n",
            "reward of step 22533 is: 0.0001233351862986361\n",
            "reward of step 22534 is: 0.0001408778261141658\n",
            "reward of step 22535 is: 0.00012971606693918913\n",
            "reward of step 22536 is: 0.00013588737322247388\n",
            "reward of step 22537 is: 0.00012029737006232686\n",
            "reward of step 22538 is: 0.00012829319346195997\n",
            "reward of step 22539 is: 0.0001451546270573181\n",
            "reward of step 22540 is: 0.00013373474188057354\n",
            "reward of step 22541 is: 0.0001225267299032475\n",
            "reward of step 22542 is: 0.00012640009841474392\n",
            "reward of step 22543 is: 0.00011703783168485866\n",
            "reward of step 22544 is: 0.0001252769907501333\n",
            "reward of step 22545 is: 0.00013088510151412742\n",
            "reward of step 22546 is: 0.0001341767434876487\n",
            "reward of step 22547 is: 0.00012838065471270087\n",
            "reward of step 22548 is: 0.00013947223201547622\n",
            "reward of step 22549 is: 0.0001257784085930129\n",
            "reward of step 22550 is: 0.00012767767622002266\n",
            "reward of step 22551 is: 0.00012452147426546972\n",
            "reward of step 22552 is: 0.00013573556240069652\n",
            "reward of step 22553 is: 0.00013235761083551785\n",
            "reward of step 22554 is: 0.00013282064212005458\n",
            "reward of step 22555 is: 0.00012552674009741742\n",
            "reward of step 22556 is: 0.0001291860564565895\n",
            "reward of step 22557 is: 0.00012697334088064135\n",
            "reward of step 22558 is: 0.00012880857093379325\n",
            "reward of step 22559 is: 0.00013253900600677682\n",
            "reward of step 22560 is: 0.00012938158792699458\n",
            "reward of step 22561 is: 0.00012368163341107565\n",
            "reward of step 22562 is: 0.0001402457700871885\n",
            "reward of step 22563 is: 0.00012395323160124689\n",
            "reward of step 22564 is: 0.00012885619872475955\n",
            "reward of step 22565 is: 0.00013180118971270783\n",
            "reward of step 22566 is: 0.00013632451414209368\n",
            "reward of step 22567 is: 0.0001236720964668616\n",
            "reward of step 22568 is: 0.00012555476343928902\n",
            "reward of step 22569 is: 0.0001324243031093148\n",
            "reward of step 22570 is: 0.00011753398649670925\n",
            "reward of step 22571 is: 0.0001248251916509629\n",
            "reward of step 22572 is: 0.00013820378257800255\n",
            "reward of step 22573 is: 0.00012667930694065555\n",
            "reward of step 22574 is: 0.00012247707210940464\n",
            "reward of step 22575 is: 0.0001308149512637981\n",
            "reward of step 22576 is: 0.0001364092792154306\n",
            "reward of step 22577 is: 0.00012454811086541598\n",
            "reward of step 22578 is: 0.0001236937772237083\n",
            "reward of step 22579 is: 0.00013805513401649207\n",
            "reward of step 22580 is: 0.00013064497221596923\n",
            "reward of step 22581 is: 0.00013426882992727672\n",
            "reward of step 22582 is: 0.00013268537736874067\n",
            "reward of step 22583 is: 0.00013046113102663356\n",
            "reward of step 22584 is: 0.00013423112569876702\n",
            "reward of step 22585 is: 0.0001189014104357425\n",
            "reward of step 22586 is: 0.00013438648779755496\n",
            "reward of step 22587 is: 0.00012412232138585044\n",
            "reward of step 22588 is: 0.00012295120863468429\n",
            "reward of step 22589 is: 0.00012291590542873004\n",
            "reward of step 22590 is: 0.0001366667293629793\n",
            "reward of step 22591 is: 0.00013249456030206392\n",
            "reward of step 22592 is: 0.00012045038348522716\n",
            "reward of step 22593 is: 0.00012690058055138376\n",
            "reward of step 22594 is: 0.00012765953387928759\n",
            "reward of step 22595 is: 0.00014362133113773268\n",
            "reward of step 22596 is: 0.00012647363188371809\n",
            "reward of step 22597 is: 0.00014953849299632787\n",
            "reward of step 22598 is: 0.00012706969937934518\n",
            "reward of step 22599 is: 0.00012097724260541295\n",
            "reward of step 22600 is: 0.0001384477560230569\n",
            "reward of step 22601 is: 0.0001252107811877494\n",
            "reward of step 22602 is: 0.00013247345680192298\n",
            "reward of step 22603 is: 0.0001283408703421081\n",
            "reward of step 22604 is: 0.00012227228370558985\n",
            "reward of step 22605 is: 0.00012757350389099056\n",
            "reward of step 22606 is: 0.0001270041634508217\n",
            "reward of step 22607 is: 0.0001286604476787871\n",
            "reward of step 22608 is: 0.00013495145258138065\n",
            "reward of step 22609 is: 0.00014429747604571185\n",
            "reward of step 22610 is: 0.0001312543401143886\n",
            "reward of step 22611 is: 0.0001294767456258762\n",
            "reward of step 22612 is: 0.000136607168821002\n",
            "reward of step 22613 is: 0.0001346602777757998\n",
            "reward of step 22614 is: 0.00012420119613396372\n",
            "reward of step 22615 is: 0.00012894227936080004\n",
            "reward of step 22616 is: 0.00013283665520199292\n",
            "reward of step 22617 is: 0.00012712285120310328\n",
            "reward of step 22618 is: 0.00013771907302208582\n",
            "reward of step 22619 is: 0.0001262984537002855\n",
            "reward of step 22620 is: 0.00011484962576846376\n",
            "reward of step 22621 is: 0.00013019014285899194\n",
            "reward of step 22622 is: 0.00012285178920913678\n",
            "reward of step 22623 is: 0.0001371220444223205\n",
            "reward of step 22624 is: 0.00012172188049693613\n",
            "reward of step 22625 is: 0.00012986423478745742\n",
            "reward of step 22626 is: 0.00013285403374074128\n",
            "reward of step 22627 is: 0.0001203741063432998\n",
            "reward of step 22628 is: 0.000116115491766533\n",
            "reward of step 22629 is: 0.0001298620767439572\n",
            "reward of step 22630 is: 0.00012051709653952834\n",
            "reward of step 22631 is: 0.00013132387499139567\n",
            "reward of step 22632 is: 0.00013083892012689152\n",
            "reward of step 22633 is: 0.00012910688699812911\n",
            "reward of step 22634 is: 0.00012862620995853722\n",
            "reward of step 22635 is: 0.0001233233365939093\n",
            "reward of step 22636 is: 0.00013265542985352593\n",
            "reward of step 22637 is: 0.00012051589255472918\n",
            "reward of step 22638 is: 0.0001458298363913699\n",
            "reward of step 22639 is: 0.00012305562822943636\n",
            "reward of step 22640 is: 0.00012202344854048815\n",
            "reward of step 22641 is: 0.00012557580135255826\n",
            "reward of step 22642 is: 0.00014073899297959916\n",
            "reward of step 22643 is: 0.00013801839611241035\n",
            "reward of step 22644 is: 0.00012756734696446726\n",
            "reward of step 22645 is: 0.00013541494085518528\n",
            "reward of step 22646 is: 0.00012723049704821103\n",
            "reward of step 22647 is: 0.00014601006659207018\n",
            "reward of step 22648 is: 0.00012874311278016347\n",
            "reward of step 22649 is: 0.00012939374995763522\n",
            "reward of step 22650 is: 0.00013048392287369834\n",
            "reward of step 22651 is: 0.00014013546415529105\n",
            "reward of step 22652 is: 0.00013161759321155908\n",
            "reward of step 22653 is: 0.00012937017213111577\n",
            "reward of step 22654 is: 0.0001257642220865766\n",
            "reward of step 22655 is: 0.0001309328436719503\n",
            "reward of step 22656 is: 0.00011668956106394275\n",
            "reward of step 22657 is: 0.00013168268328170532\n",
            "reward of step 22658 is: 0.00012132765246978348\n",
            "reward of step 22659 is: 0.00011926754178600702\n",
            "reward of step 22660 is: 0.0001319195226705734\n",
            "reward of step 22661 is: 0.00012629459783926013\n",
            "reward of step 22662 is: 0.0001243677933428782\n",
            "reward of step 22663 is: 0.0001301565207638812\n",
            "reward of step 22664 is: 0.00012410516706412193\n",
            "reward of step 22665 is: 0.00013772196951582528\n",
            "reward of step 22666 is: 0.00013051788629204529\n",
            "reward of step 22667 is: 0.00013202237552313513\n",
            "reward of step 22668 is: 0.00012899367376034576\n",
            "reward of step 22669 is: 0.00013612741948594229\n",
            "reward of step 22670 is: 0.00013905729860471406\n",
            "reward of step 22671 is: 0.00012414029351673074\n",
            "reward of step 22672 is: 0.00013437832059147632\n",
            "reward of step 22673 is: 0.00012020663776453664\n",
            "reward of step 22674 is: 0.000133972140160321\n",
            "reward of step 22675 is: 0.00013094801349081898\n",
            "reward of step 22676 is: 0.00012730916613936088\n",
            "reward of step 22677 is: 0.00013503053717534073\n",
            "reward of step 22678 is: 0.00012154393615416201\n",
            "reward of step 22679 is: 0.00013924021687461164\n",
            "reward of step 22680 is: 0.00013887795510859145\n",
            "reward of step 22681 is: 0.0001356230788527342\n",
            "reward of step 22682 is: 0.00013933213761045134\n",
            "reward of step 22683 is: 0.00013302796145131103\n",
            "reward of step 22684 is: 0.00013918033844463932\n",
            "reward of step 22685 is: 0.00013072872753404656\n",
            "reward of step 22686 is: 0.00012756870803061626\n",
            "reward of step 22687 is: 0.00013974580885037506\n",
            "reward of step 22688 is: 0.00013918953331086884\n",
            "reward of step 22689 is: 0.0001349852350582337\n",
            "reward of step 22690 is: 0.00012429415554710165\n",
            "reward of step 22691 is: 0.00013172687608804375\n",
            "reward of step 22692 is: 0.00013137808878098257\n",
            "reward of step 22693 is: 0.00012603790539245858\n",
            "reward of step 22694 is: 0.00014068098493735362\n",
            "reward of step 22695 is: 0.00013849678112704057\n",
            "reward of step 22696 is: 0.0001384726787085437\n",
            "reward of step 22697 is: 0.00012391698122875044\n",
            "reward of step 22698 is: 0.00012961019871214028\n",
            "reward of step 22699 is: 0.00012624330871438384\n",
            "reward of step 22700 is: 0.00012387385166085952\n",
            "reward of step 22701 is: 0.00012881226555201951\n",
            "reward of step 22702 is: 0.00012096245013033506\n",
            "reward of step 22703 is: 0.0001293244612466709\n",
            "reward of step 22704 is: 0.00013050360837534966\n",
            "reward of step 22705 is: 0.00013810003628035185\n",
            "reward of step 22706 is: 0.00011236496738911323\n",
            "reward of step 22707 is: 0.00013464070439990911\n",
            "reward of step 22708 is: 0.00012329800964811557\n",
            "reward of step 22709 is: 0.0001327233266998502\n",
            "reward of step 22710 is: 0.00013545978969580538\n",
            "reward of step 22711 is: 0.00013810389313426475\n",
            "reward of step 22712 is: 0.00012775641597889494\n",
            "reward of step 22713 is: 0.0001334729828428965\n",
            "reward of step 22714 is: 0.00013206086117450376\n",
            "reward of step 22715 is: 0.00011925344808151854\n",
            "reward of step 22716 is: 0.00013374102553907473\n",
            "reward of step 22717 is: 0.00012609153959712097\n",
            "reward of step 22718 is: 0.0001291144052441288\n",
            "reward of step 22719 is: 0.00012661214110433206\n",
            "reward of step 22720 is: 0.00012687129649750363\n",
            "reward of step 22721 is: 0.00013078068832316433\n",
            "reward of step 22722 is: 0.0001289677665116046\n",
            "reward of step 22723 is: 0.00012350317957970206\n",
            "reward of step 22724 is: 0.00014330445956372835\n",
            "reward of step 22725 is: 0.00013879858965892044\n",
            "reward of step 22726 is: 0.00014040864419128133\n",
            "reward of step 22727 is: 0.0001320267000977163\n",
            "reward of step 22728 is: 0.0001381788956517567\n",
            "reward of step 22729 is: 0.00014054280428741413\n",
            "reward of step 22730 is: 0.0001327789478324188\n",
            "reward of step 22731 is: 0.00014522020306064523\n",
            "reward of step 22732 is: 0.00011879907187953634\n",
            "reward of step 22733 is: 0.00013424409859715428\n",
            "reward of step 22734 is: 0.00013001993893772238\n",
            "reward of step 22735 is: 0.00013096623483508328\n",
            "reward of step 22736 is: 0.00013281169874370332\n",
            "reward of step 22737 is: 0.00013563012615421828\n",
            "reward of step 22738 is: 0.00013073022182734983\n",
            "reward of step 22739 is: 0.00011822150036814293\n",
            "reward of step 22740 is: 0.0001388497107420692\n",
            "reward of step 22741 is: 0.00012246911598375775\n",
            "reward of step 22742 is: 0.00013140142974882215\n",
            "reward of step 22743 is: 0.00014645568823180987\n",
            "reward of step 22744 is: 0.0001299109833133691\n",
            "reward of step 22745 is: 0.00013237403785715612\n",
            "reward of step 22746 is: 0.00013937675816017828\n",
            "reward of step 22747 is: 0.00013439780219506176\n",
            "reward of step 22748 is: 0.00014012004033973812\n",
            "reward of step 22749 is: 0.00013729324354593955\n",
            "reward of step 22750 is: 0.00012728584160098612\n",
            "reward of step 22751 is: 0.0001337384173573457\n",
            "reward of step 22752 is: 0.00013674158013826968\n",
            "reward of step 22753 is: 0.00012959514876704372\n",
            "reward of step 22754 is: 0.00013926029726114036\n",
            "reward of step 22755 is: 0.00013455291173977623\n",
            "reward of step 22756 is: 0.00014034311248219762\n",
            "reward of step 22757 is: 0.0001322341706579472\n",
            "reward of step 22758 is: 0.00013411049506345472\n",
            "reward of step 22759 is: 0.00014580113345266977\n",
            "reward of step 22760 is: 0.0001302458113755649\n",
            "reward of step 22761 is: 0.0001237214363005602\n",
            "reward of step 22762 is: 0.0001355403172373719\n",
            "reward of step 22763 is: 0.00011667610879818085\n",
            "reward of step 22764 is: 0.00012812497444959593\n",
            "reward of step 22765 is: 0.00012984641722068856\n",
            "reward of step 22766 is: 0.00013343228735471788\n",
            "reward of step 22767 is: 0.00013227018631571758\n",
            "reward of step 22768 is: 0.0001270197793968685\n",
            "reward of step 22769 is: 0.00014244917946461602\n",
            "reward of step 22770 is: 0.00011559110149687967\n",
            "reward of step 22771 is: 0.0001337002399438889\n",
            "reward of step 22772 is: 0.00012433286911998358\n",
            "reward of step 22773 is: 0.00014003919343522027\n",
            "reward of step 22774 is: 0.00012063036235263866\n",
            "reward of step 22775 is: 0.00011663937760166671\n",
            "reward of step 22776 is: 0.00011987293682370884\n",
            "reward of step 22777 is: 0.00013809480470012095\n",
            "reward of step 22778 is: 0.00011515793987377842\n",
            "reward of step 22779 is: 0.00014455517751659183\n",
            "reward of step 22780 is: 0.00014436679895990187\n",
            "reward of step 22781 is: 0.00012454011182249416\n",
            "reward of step 22782 is: 0.0001308402437442793\n",
            "reward of step 22783 is: 0.00013624532187267682\n",
            "reward of step 22784 is: 0.00012052532381996241\n",
            "reward of step 22785 is: 0.0001134846633805803\n",
            "reward of step 22786 is: 0.00013675558111124643\n",
            "reward of step 22787 is: 0.00013084957199585565\n",
            "reward of step 22788 is: 0.0001340030085365087\n",
            "reward of step 22789 is: 0.00012687683761743792\n",
            "reward of step 22790 is: 0.00012328549083802178\n",
            "reward of step 22791 is: 0.0001298213713987019\n",
            "reward of step 22792 is: 0.00013640212538373707\n",
            "reward of step 22793 is: 0.00012235064591604297\n",
            "reward of step 22794 is: 0.00013350405069419063\n",
            "reward of step 22795 is: 0.00011986994787042035\n",
            "reward of step 22796 is: 0.00011936285631027182\n",
            "reward of step 22797 is: 0.0001204027727769487\n",
            "reward of step 22798 is: 0.00014449398831596684\n",
            "reward of step 22799 is: 0.00013709922743952417\n",
            "reward of step 22800 is: 0.00012710805450575933\n",
            "reward of step 22801 is: 0.00012741303989745561\n",
            "reward of step 22802 is: 0.00012466878896964301\n",
            "reward of step 22803 is: 0.00012389018332061325\n",
            "reward of step 22804 is: 0.00012580237009107977\n",
            "reward of step 22805 is: 0.00011815792117501296\n",
            "reward of step 22806 is: 0.00012894118050111957\n",
            "reward of step 22807 is: 0.00012773501630887775\n",
            "reward of step 22808 is: 0.00012613008960703234\n",
            "reward of step 22809 is: 0.00013516108742753902\n",
            "reward of step 22810 is: 0.00012465004903295732\n",
            "reward of step 22811 is: 0.00012837633501658926\n",
            "reward of step 22812 is: 0.00013411790821688958\n",
            "reward of step 22813 is: 0.0001300717382137376\n",
            "reward of step 22814 is: 0.00013227347016151226\n",
            "reward of step 22815 is: 0.00014083677859466103\n",
            "reward of step 22816 is: 0.00012597609184269776\n",
            "reward of step 22817 is: 0.00014000106376446477\n",
            "reward of step 22818 is: 0.00012881982704435912\n",
            "reward of step 22819 is: 0.00014070399407382645\n",
            "reward of step 22820 is: 0.00012120244536835183\n",
            "reward of step 22821 is: 0.0001278740267503027\n",
            "reward of step 22822 is: 0.00011867857700638252\n",
            "reward of step 22823 is: 0.000137936518023002\n",
            "reward of step 22824 is: 0.00013092184176968294\n",
            "reward of step 22825 is: 0.00012355099841995632\n",
            "reward of step 22826 is: 0.00013177436061874998\n",
            "reward of step 22827 is: 0.00014354364994447283\n",
            "reward of step 22828 is: 0.00014343142636803492\n",
            "reward of step 22829 is: 0.0001373094250430126\n",
            "reward of step 22830 is: 0.00012024676976103586\n",
            "reward of step 22831 is: 0.00013098775341536167\n",
            "reward of step 22832 is: 0.00012072869467499354\n",
            "reward of step 22833 is: 0.00013654741272582397\n",
            "reward of step 22834 is: 0.00012232061075980895\n",
            "reward of step 22835 is: 0.00014143294597387148\n",
            "reward of step 22836 is: 0.00013092067360709236\n",
            "reward of step 22837 is: 0.00012479259615178384\n",
            "reward of step 22838 is: 0.00013290352150709936\n",
            "reward of step 22839 is: 0.00012971762028584624\n",
            "reward of step 22840 is: 0.00012363655790222262\n",
            "reward of step 22841 is: 0.00012519089833317877\n",
            "reward of step 22842 is: 0.00011769875237603488\n",
            "reward of step 22843 is: 0.00012689034874197996\n",
            "reward of step 22844 is: 0.00013055713293618818\n",
            "reward of step 22845 is: 0.00013286944951840883\n",
            "reward of step 22846 is: 0.00012422146731961816\n",
            "reward of step 22847 is: 0.00012874823689089214\n",
            "reward of step 22848 is: 0.00012964214524170312\n",
            "reward of step 22849 is: 0.00012497068304518984\n",
            "reward of step 22850 is: 0.0001346768904266619\n",
            "reward of step 22851 is: 0.0001283817164123408\n",
            "reward of step 22852 is: 0.00012639007848569655\n",
            "reward of step 22853 is: 0.00011728445977663889\n",
            "reward of step 22854 is: 0.00014420904500157832\n",
            "reward of step 22855 is: 0.00012962931808133772\n",
            "reward of step 22856 is: 0.00012597528079370023\n",
            "reward of step 22857 is: 0.00012088661083922506\n",
            "reward of step 22858 is: 0.0001325098009726129\n",
            "reward of step 22859 is: 0.0001298987414210504\n",
            "reward of step 22860 is: 0.00011673417031904809\n",
            "reward of step 22861 is: 0.00013250581674583597\n",
            "reward of step 22862 is: 0.00013369494632418298\n",
            "reward of step 22863 is: 0.00013200184243685693\n",
            "reward of step 22864 is: 0.00012251302100766963\n",
            "reward of step 22865 is: 0.00012082280402582106\n",
            "reward of step 22866 is: 0.00012218268925201015\n",
            "reward of step 22867 is: 0.00013087101046891763\n",
            "reward of step 22868 is: 0.00013016209538378658\n",
            "reward of step 22869 is: 0.00012424696239512898\n",
            "reward of step 22870 is: 0.00012916145527340711\n",
            "reward of step 22871 is: 0.00012996729325226217\n",
            "reward of step 22872 is: 0.00013800936964085766\n",
            "reward of step 22873 is: 0.00013244090067307082\n",
            "reward of step 22874 is: 0.00012565974059668443\n",
            "reward of step 22875 is: 0.00012260906866365772\n",
            "reward of step 22876 is: 0.00012792330259238542\n",
            "reward of step 22877 is: 0.00012112988406033697\n",
            "reward of step 22878 is: 0.00013642785630951977\n",
            "reward of step 22879 is: 0.00011934940583617697\n",
            "reward of step 22880 is: 0.00011641213913304807\n",
            "reward of step 22881 is: 0.0001268265374137793\n",
            "reward of step 22882 is: 0.00011764737777475302\n",
            "reward of step 22883 is: 0.0001187034169761706\n",
            "reward of step 22884 is: 0.00014005246812508917\n",
            "reward of step 22885 is: 0.00012155496127101046\n",
            "reward of step 22886 is: 0.00013016389602973926\n",
            "reward of step 22887 is: 0.00013684457632477618\n",
            "reward of step 22888 is: 0.00014377928688645686\n",
            "reward of step 22889 is: 0.00013858390087603969\n",
            "reward of step 22890 is: 0.00013198899712154376\n",
            "reward of step 22891 is: 0.00013798531377650052\n",
            "reward of step 22892 is: 0.00013001852857134056\n",
            "reward of step 22893 is: 0.0001287437140990074\n",
            "reward of step 22894 is: 0.0001216973244998117\n",
            "reward of step 22895 is: 0.0001341651345647356\n",
            "reward of step 22896 is: 0.00013065637123102662\n",
            "reward of step 22897 is: 0.00012841631578104577\n",
            "reward of step 22898 is: 0.00013435558762653582\n",
            "reward of step 22899 is: 0.00012153598786476004\n",
            "reward of step 22900 is: 0.00012813613407071947\n",
            "reward of step 22901 is: 0.0001346215617302968\n",
            "reward of step 22902 is: 0.00012508109981978702\n",
            "reward of step 22903 is: 0.0001242998563759826\n",
            "reward of step 22904 is: 0.0001227776140067\n",
            "reward of step 22905 is: 0.0001243041415156312\n",
            "reward of step 22906 is: 0.00012881932766394165\n",
            "reward of step 22907 is: 0.00013594078324652453\n",
            "reward of step 22908 is: 0.0001198112232498692\n",
            "reward of step 22909 is: 0.0001299572666121025\n",
            "reward of step 22910 is: 0.00012815885852313625\n",
            "reward of step 22911 is: 0.0001352942737904631\n",
            "reward of step 22912 is: 0.00012908390567895636\n",
            "reward of step 22913 is: 0.00013545272001699388\n",
            "reward of step 22914 is: 0.00012478548671593392\n",
            "reward of step 22915 is: 0.00014500621966901812\n",
            "reward of step 22916 is: 0.00012596788307157457\n",
            "reward of step 22917 is: 0.00011992662328822926\n",
            "reward of step 22918 is: 0.00013310430872564026\n",
            "reward of step 22919 is: 0.00013062815300370585\n",
            "reward of step 22920 is: 0.00013658287097516696\n",
            "reward of step 22921 is: 0.00013306719451854461\n",
            "reward of step 22922 is: 0.00014617969507587695\n",
            "reward of step 22923 is: 0.0001359167473175162\n",
            "reward of step 22924 is: 0.0001446003333651256\n",
            "reward of step 22925 is: 0.00014000326742192676\n",
            "reward of step 22926 is: 0.0001255079465068442\n",
            "reward of step 22927 is: 0.00012563031937852658\n",
            "reward of step 22928 is: 0.000128150829800904\n",
            "reward of step 22929 is: 0.00013632202715435873\n",
            "reward of step 22930 is: 0.00013194212210285844\n",
            "reward of step 22931 is: 0.00013930458925289323\n",
            "reward of step 22932 is: 0.00011564963246697769\n",
            "reward of step 22933 is: 0.00013330451856029951\n",
            "reward of step 22934 is: 0.0001292226601382256\n",
            "reward of step 22935 is: 0.00013182320875590675\n",
            "reward of step 22936 is: 0.00013709054169529702\n",
            "reward of step 22937 is: 0.0001332886624135454\n",
            "reward of step 22938 is: 0.0001395072129578363\n",
            "reward of step 22939 is: 0.00013166711276697474\n",
            "reward of step 22940 is: 0.00012610984418475678\n",
            "reward of step 22941 is: 0.00013600408706315842\n",
            "reward of step 22942 is: 0.00013901383416706507\n",
            "reward of step 22943 is: 0.00012025452464123835\n",
            "reward of step 22944 is: 0.00012381046713275283\n",
            "reward of step 22945 is: 0.00012497753757926116\n",
            "reward of step 22946 is: 0.00013037933482967301\n",
            "reward of step 22947 is: 0.00012967650250285788\n",
            "reward of step 22948 is: 0.00012371342608389547\n",
            "reward of step 22949 is: 0.00013541884982031004\n",
            "reward of step 22950 is: 0.00012881402692930776\n",
            "reward of step 22951 is: 0.00012693263615964757\n",
            "reward of step 22952 is: 0.00013698122342816434\n",
            "reward of step 22953 is: 0.00013159251016941988\n",
            "reward of step 22954 is: 0.0001316452878737615\n",
            "reward of step 22955 is: 0.00012439030101226047\n",
            "reward of step 22956 is: 0.00013965724244635342\n",
            "reward of step 22957 is: 0.00011358241067280202\n",
            "reward of step 22958 is: 0.0001367402181552351\n",
            "reward of step 22959 is: 0.00012722875316178344\n",
            "reward of step 22960 is: 0.00012788672959467302\n",
            "reward of step 22961 is: 0.000121900036665948\n",
            "reward of step 22962 is: 0.0001289371005460535\n",
            "reward of step 22963 is: 0.00014596397684811375\n",
            "reward of step 22964 is: 0.00013644574626492918\n",
            "reward of step 22965 is: 0.00012146117013962612\n",
            "reward of step 22966 is: 0.00012958647336864656\n",
            "reward of step 22967 is: 0.0001310524333932163\n",
            "reward of step 22968 is: 0.00013216365019027236\n",
            "reward of step 22969 is: 0.0001257071581255562\n",
            "reward of step 22970 is: 0.00012977027319976468\n",
            "reward of step 22971 is: 0.000129000168638288\n",
            "reward of step 22972 is: 0.0001343570998535291\n",
            "reward of step 22973 is: 0.00014259262751697833\n",
            "reward of step 22974 is: 0.0001318724376505634\n",
            "reward of step 22975 is: 0.00012050060046170622\n",
            "reward of step 22976 is: 0.0001264112384459727\n",
            "reward of step 22977 is: 0.0001366293183382174\n",
            "reward of step 22978 is: 0.00012028140468911773\n",
            "reward of step 22979 is: 0.0001381099611738779\n",
            "reward of step 22980 is: 0.0001322406692252249\n",
            "reward of step 22981 is: 0.00012029633208023605\n",
            "reward of step 22982 is: 0.0001355650741733588\n",
            "reward of step 22983 is: 0.00013450554369335627\n",
            "reward of step 22984 is: 0.00011717410971326004\n",
            "reward of step 22985 is: 0.0001260752956784146\n",
            "reward of step 22986 is: 0.00011354920457977985\n",
            "reward of step 22987 is: 0.00014522788230275668\n",
            "reward of step 22988 is: 0.00013270781705116062\n",
            "reward of step 22989 is: 0.00013317376681474332\n",
            "reward of step 22990 is: 0.0001188551760243889\n",
            "reward of step 22991 is: 0.0001370273682280666\n",
            "reward of step 22992 is: 0.0001249910493863491\n",
            "reward of step 22993 is: 0.0001280023092343462\n",
            "reward of step 22994 is: 0.00014698180880277242\n",
            "reward of step 22995 is: 0.0001385134199033808\n",
            "reward of step 22996 is: 0.00012447248679387364\n",
            "reward of step 22997 is: 0.00012841608383986947\n",
            "reward of step 22998 is: 0.00012127299084860755\n",
            "reward of step 22999 is: 0.00011712086376309499\n",
            "reward of step 23000 is: 0.0001311896182417702\n",
            "reward of step 23001 is: 0.00012381731221612207\n",
            "reward of step 23002 is: 0.0001343451544622411\n",
            "reward of step 23003 is: 0.0001306905877184543\n",
            "reward of step 23004 is: 0.000123010123959976\n",
            "reward of step 23005 is: 0.00013297483269166516\n",
            "reward of step 23006 is: 0.00012296080386867275\n",
            "reward of step 23007 is: 0.00014525286216675765\n",
            "reward of step 23008 is: 0.00012623595890657777\n",
            "reward of step 23009 is: 0.00013420009019611052\n",
            "reward of step 23010 is: 0.00012548034471379502\n",
            "reward of step 23011 is: 0.00014350108573913834\n",
            "reward of step 23012 is: 0.00011995853890976189\n",
            "reward of step 23013 is: 0.00013207727146945624\n",
            "reward of step 23014 is: 0.00013560159876692176\n",
            "reward of step 23015 is: 0.00014423261079803953\n",
            "reward of step 23016 is: 0.00013175235579428057\n",
            "reward of step 23017 is: 0.00013693604342886182\n",
            "reward of step 23018 is: 0.00013280048892946896\n",
            "reward of step 23019 is: 0.00011460592433455043\n",
            "reward of step 23020 is: 0.00013132694844228223\n",
            "reward of step 23021 is: 0.00011766988657679665\n",
            "reward of step 23022 is: 0.00012086489663507889\n",
            "reward of step 23023 is: 0.00012537889851457155\n",
            "reward of step 23024 is: 0.00013679971301003833\n",
            "reward of step 23025 is: 0.00013557534388115654\n",
            "reward of step 23026 is: 0.00013928778945492405\n",
            "reward of step 23027 is: 0.00011939111297308196\n",
            "reward of step 23028 is: 0.00013965512216093987\n",
            "reward of step 23029 is: 0.0001267055912527569\n",
            "reward of step 23030 is: 0.00011828898281316607\n",
            "reward of step 23031 is: 0.00012366105426398494\n",
            "reward of step 23032 is: 0.0001366081346364662\n",
            "reward of step 23033 is: 0.00014334021511644074\n",
            "reward of step 23034 is: 0.00013662924790595296\n",
            "reward of step 23035 is: 0.00012633565027205814\n",
            "reward of step 23036 is: 0.00013203724269205818\n",
            "reward of step 23037 is: 0.00012551107925056775\n",
            "reward of step 23038 is: 0.00011140214113685218\n",
            "reward of step 23039 is: 0.00012403876538048822\n",
            "reward of step 23040 is: 0.000141786756347254\n",
            "reward of step 23041 is: 0.00013595193425266144\n",
            "reward of step 23042 is: 0.00012207205450800998\n",
            "reward of step 23043 is: 0.00011906947307230763\n",
            "reward of step 23044 is: 0.00011587327895656696\n",
            "reward of step 23045 is: 0.00011456831938800314\n",
            "reward of step 23046 is: 0.0001356900492287692\n",
            "reward of step 23047 is: 0.0001322706402325703\n",
            "reward of step 23048 is: 0.00013096928478683416\n",
            "reward of step 23049 is: 0.00011678005664909126\n",
            "reward of step 23050 is: 0.00013305129056225573\n",
            "reward of step 23051 is: 0.00014428393319361663\n",
            "reward of step 23052 is: 0.0001362221722375144\n",
            "reward of step 23053 is: 0.00012912717491667515\n",
            "reward of step 23054 is: 0.00011742603448538235\n",
            "reward of step 23055 is: 0.0001355259225226711\n",
            "reward of step 23056 is: 0.00012110919837548226\n",
            "reward of step 23057 is: 0.00013624220839061587\n",
            "reward of step 23058 is: 0.0001293752203988379\n",
            "reward of step 23059 is: 0.0001288690690896536\n",
            "reward of step 23060 is: 0.00011864928974423378\n",
            "reward of step 23061 is: 0.00014551554010542287\n",
            "reward of step 23062 is: 0.00013127271466436072\n",
            "reward of step 23063 is: 0.000131453721928789\n",
            "reward of step 23064 is: 0.00011790404098963481\n",
            "reward of step 23065 is: 0.00012299472914927877\n",
            "reward of step 23066 is: 0.0001275195674202877\n",
            "reward of step 23067 is: 0.0001332966401232446\n",
            "reward of step 23068 is: 0.00014565365951335965\n",
            "reward of step 23069 is: 0.00012660063914037478\n",
            "reward of step 23070 is: 0.00012512310274894164\n",
            "reward of step 23071 is: 0.00012112172978013045\n",
            "reward of step 23072 is: 0.00012180156003629855\n",
            "reward of step 23073 is: 0.0001271198280866979\n",
            "reward of step 23074 is: 0.00011760357670197864\n",
            "reward of step 23075 is: 0.00012509160237943447\n",
            "reward of step 23076 is: 0.00014092890465274802\n",
            "reward of step 23077 is: 0.00011721890642710083\n",
            "reward of step 23078 is: 0.00011411456443205993\n",
            "reward of step 23079 is: 0.0001276687001335006\n",
            "reward of step 23080 is: 0.00012738998127325454\n",
            "reward of step 23081 is: 0.00013109453317713873\n",
            "reward of step 23082 is: 0.00012808945789424123\n",
            "reward of step 23083 is: 0.00013352467355056595\n",
            "reward of step 23084 is: 0.0001357175157041452\n",
            "reward of step 23085 is: 0.00011858644788685834\n",
            "reward of step 23086 is: 0.0001300492557973013\n",
            "reward of step 23087 is: 0.00012540658740052235\n",
            "reward of step 23088 is: 0.00014262574708665622\n",
            "reward of step 23089 is: 0.00012883894207428473\n",
            "reward of step 23090 is: 0.00012512990724126343\n",
            "reward of step 23091 is: 0.00013220317276425495\n",
            "reward of step 23092 is: 0.00012277485562214779\n",
            "reward of step 23093 is: 0.00013151956460197953\n",
            "reward of step 23094 is: 0.00012672773482529437\n",
            "reward of step 23095 is: 0.00012737781184408257\n",
            "reward of step 23096 is: 0.00013765212636817253\n",
            "reward of step 23097 is: 0.00013103275427020784\n",
            "reward of step 23098 is: 0.00012129762666817123\n",
            "reward of step 23099 is: 0.00013959190939716353\n",
            "reward of step 23100 is: 0.00012346170855996296\n",
            "reward of step 23101 is: 0.00012103655414353493\n",
            "reward of step 23102 is: 0.00011915285630461985\n",
            "reward of step 23103 is: 0.00012214602053840714\n",
            "reward of step 23104 is: 0.00013555786599219374\n",
            "reward of step 23105 is: 0.00012922918971543224\n",
            "reward of step 23106 is: 0.0001169312694969086\n",
            "reward of step 23107 is: 0.0001246702113915782\n",
            "reward of step 23108 is: 0.00012231809951933204\n",
            "reward of step 23109 is: 0.00013455955169861965\n",
            "reward of step 23110 is: 0.00012783511835047588\n",
            "reward of step 23111 is: 0.00013213351960745533\n",
            "reward of step 23112 is: 0.00013551490029838488\n",
            "reward of step 23113 is: 0.00011798299823836\n",
            "reward of step 23114 is: 0.0001295085002497786\n",
            "reward of step 23115 is: 0.0001423630848593971\n",
            "reward of step 23116 is: 0.0001188547968595887\n",
            "reward of step 23117 is: 0.0001310033562080817\n",
            "reward of step 23118 is: 0.000126121615747704\n",
            "reward of step 23119 is: 0.0001307167547568422\n",
            "reward of step 23120 is: 0.00013344070393908077\n",
            "reward of step 23121 is: 0.000131390305636086\n",
            "reward of step 23122 is: 0.00012406779975380683\n",
            "reward of step 23123 is: 0.00013147648435050797\n",
            "reward of step 23124 is: 0.00013652599130739622\n",
            "reward of step 23125 is: 0.00011859401208475515\n",
            "reward of step 23126 is: 0.0001301655591522544\n",
            "reward of step 23127 is: 0.00013285265827798088\n",
            "reward of step 23128 is: 0.00013108217344674476\n",
            "reward of step 23129 is: 0.00013493447073178097\n",
            "reward of step 23130 is: 0.00013627780287158792\n",
            "reward of step 23131 is: 0.00013288913213146337\n",
            "reward of step 23132 is: 0.0001361310799824375\n",
            "reward of step 23133 is: 0.00013020917301612814\n",
            "reward of step 23134 is: 0.00013001993647939397\n",
            "reward of step 23135 is: 0.0001377473346650804\n",
            "reward of step 23136 is: 0.00013377227949586053\n",
            "reward of step 23137 is: 0.00012973392252372808\n",
            "reward of step 23138 is: 0.00014211566325172972\n",
            "reward of step 23139 is: 0.000129586176521291\n",
            "reward of step 23140 is: 0.0001411098715094191\n",
            "reward of step 23141 is: 0.00012382699366143813\n",
            "reward of step 23142 is: 0.00014159712576376378\n",
            "reward of step 23143 is: 0.00014613108951178332\n",
            "reward of step 23144 is: 0.00012392534895557295\n",
            "reward of step 23145 is: 0.0001228316429512287\n",
            "reward of step 23146 is: 0.00013036818658658438\n",
            "reward of step 23147 is: 0.00013009571449320553\n",
            "reward of step 23148 is: 0.0001361164794694944\n",
            "reward of step 23149 is: 0.00013177652803767324\n",
            "reward of step 23150 is: 0.00013239946625297723\n",
            "reward of step 23151 is: 0.00011923245987213554\n",
            "reward of step 23152 is: 0.0001231852041671772\n",
            "reward of step 23153 is: 0.0001321905613235473\n",
            "reward of step 23154 is: 0.0001365317716029007\n",
            "reward of step 23155 is: 0.00012504983958632775\n",
            "reward of step 23156 is: 0.0001447311978729267\n",
            "reward of step 23157 is: 0.00014199838533141319\n",
            "reward of step 23158 is: 0.00012586597432137522\n",
            "reward of step 23159 is: 0.0001361904188822451\n",
            "reward of step 23160 is: 0.00013602751401025866\n",
            "reward of step 23161 is: 0.0001238833028173505\n",
            "reward of step 23162 is: 0.0001324149059707638\n",
            "reward of step 23163 is: 0.00011825007494946036\n",
            "reward of step 23164 is: 0.00013360465777383535\n",
            "reward of step 23165 is: 0.00013817360065022545\n",
            "reward of step 23166 is: 0.00013201175738371122\n",
            "reward of step 23167 is: 0.00012411777037185138\n",
            "reward of step 23168 is: 0.00011879394363778071\n",
            "reward of step 23169 is: 0.00013805323638299167\n",
            "reward of step 23170 is: 0.0001311492362359131\n",
            "reward of step 23171 is: 0.00012972233250346514\n",
            "reward of step 23172 is: 0.0001245037180823213\n",
            "reward of step 23173 is: 0.00011738405890171296\n",
            "reward of step 23174 is: 0.00011948195278154518\n",
            "reward of step 23175 is: 0.00013496818540117294\n",
            "reward of step 23176 is: 0.00014022113810071942\n",
            "reward of step 23177 is: 0.00012559635141155164\n",
            "reward of step 23178 is: 0.00011952973238847073\n",
            "reward of step 23179 is: 0.0001243236216551586\n",
            "reward of step 23180 is: 0.00013105908225751172\n",
            "reward of step 23181 is: 0.00012424689020977629\n",
            "reward of step 23182 is: 0.00012708992887235475\n",
            "reward of step 23183 is: 0.0001278136849481523\n",
            "reward of step 23184 is: 0.0001408839380078073\n",
            "reward of step 23185 is: 0.0001233805985294252\n",
            "reward of step 23186 is: 0.0001230652956794141\n",
            "reward of step 23187 is: 0.00012471923957158194\n",
            "reward of step 23188 is: 0.00013080926626089936\n",
            "reward of step 23189 is: 0.00011754449315804199\n",
            "reward of step 23190 is: 0.00011197191459105841\n",
            "reward of step 23191 is: 0.00012934460418199888\n",
            "reward of step 23192 is: 0.00011055543488241887\n",
            "reward of step 23193 is: 0.00013706564209273187\n",
            "reward of step 23194 is: 0.00013537861482875376\n",
            "reward of step 23195 is: 0.00014310756119274165\n",
            "reward of step 23196 is: 0.00013890255498662195\n",
            "reward of step 23197 is: 0.00012985696880695905\n",
            "reward of step 23198 is: 0.00013265882113010704\n",
            "reward of step 23199 is: 0.00012091301213909673\n",
            "reward of step 23200 is: 0.00013285132869119345\n",
            "reward of step 23201 is: 0.00012956368426930034\n",
            "reward of step 23202 is: 0.00011976768042370648\n",
            "reward of step 23203 is: 0.00012404429420764476\n",
            "reward of step 23204 is: 0.0001272016346672559\n",
            "reward of step 23205 is: 0.00013843253161034664\n",
            "reward of step 23206 is: 0.00011359046572008389\n",
            "reward of step 23207 is: 0.00012588060943136866\n",
            "reward of step 23208 is: 0.00012896950907684136\n",
            "reward of step 23209 is: 0.00012208740352798612\n",
            "reward of step 23210 is: 0.0001237270359727653\n",
            "reward of step 23211 is: 0.00013613503438472883\n",
            "reward of step 23212 is: 0.00012473311262586428\n",
            "reward of step 23213 is: 0.00013631967176147965\n",
            "reward of step 23214 is: 0.00012696346880174437\n",
            "reward of step 23215 is: 0.00013624211364882458\n",
            "reward of step 23216 is: 0.00012217813603121645\n",
            "reward of step 23217 is: 0.00015095200480987124\n",
            "reward of step 23218 is: 0.00013053676941127067\n",
            "reward of step 23219 is: 0.00013547757836054948\n",
            "reward of step 23220 is: 0.0001270164744678212\n",
            "reward of step 23221 is: 0.00013908249997395352\n",
            "reward of step 23222 is: 0.00011475011100170038\n",
            "reward of step 23223 is: 0.0001343547999857785\n",
            "reward of step 23224 is: 0.00013186775306622074\n",
            "reward of step 23225 is: 0.00013350730906898709\n",
            "reward of step 23226 is: 0.00012505160445241728\n",
            "reward of step 23227 is: 0.00012910101824147778\n",
            "reward of step 23228 is: 0.00012018909505660085\n",
            "reward of step 23229 is: 0.000128194477290352\n",
            "reward of step 23230 is: 0.00013594397500821717\n",
            "reward of step 23231 is: 0.00011970749154904277\n",
            "reward of step 23232 is: 0.0001156803729160049\n",
            "reward of step 23233 is: 0.00013185564551324226\n",
            "reward of step 23234 is: 0.0001291498475932928\n",
            "reward of step 23235 is: 0.0001450406362385484\n",
            "reward of step 23236 is: 0.00013325604550153207\n",
            "reward of step 23237 is: 0.00012304969062264568\n",
            "reward of step 23238 is: 0.0001360059315582869\n",
            "reward of step 23239 is: 0.0001355544486317653\n",
            "reward of step 23240 is: 0.00013145324629624435\n",
            "reward of step 23241 is: 0.00013205536785072122\n",
            "reward of step 23242 is: 0.00012561328283974008\n",
            "reward of step 23243 is: 0.00012814804554632162\n",
            "reward of step 23244 is: 0.00011129510335169882\n",
            "reward of step 23245 is: 0.00013275261654324206\n",
            "reward of step 23246 is: 0.00012965611247107853\n",
            "reward of step 23247 is: 0.00012962425500905828\n",
            "reward of step 23248 is: 0.00012833858534248531\n",
            "reward of step 23249 is: 0.0001279855532727542\n",
            "reward of step 23250 is: 0.00013227103603385206\n",
            "reward of step 23251 is: 0.00013213026976796502\n",
            "reward of step 23252 is: 0.00013510048728713445\n",
            "reward of step 23253 is: 0.00012838516871397203\n",
            "reward of step 23254 is: 0.00013886024366292798\n",
            "reward of step 23255 is: 0.0001325564504249632\n",
            "reward of step 23256 is: 0.0001272091209274856\n",
            "reward of step 23257 is: 0.00012099208120954187\n",
            "reward of step 23258 is: 0.00012860970679515603\n",
            "reward of step 23259 is: 0.00013311204158324684\n",
            "reward of step 23260 is: 0.000117821789133742\n",
            "reward of step 23261 is: 0.00014344326484595104\n",
            "reward of step 23262 is: 0.0001301160244301622\n",
            "reward of step 23263 is: 0.00012936561649148885\n",
            "reward of step 23264 is: 0.0001372345720542792\n",
            "reward of step 23265 is: 0.00012986995679356992\n",
            "reward of step 23266 is: 0.00011813424662497937\n",
            "reward of step 23267 is: 0.00012392274989007188\n",
            "reward of step 23268 is: 0.00013226359862217766\n",
            "reward of step 23269 is: 0.00012686507218450356\n",
            "reward of step 23270 is: 0.00012294974613031844\n",
            "reward of step 23271 is: 0.0001257635711570668\n",
            "reward of step 23272 is: 0.0001463013772221807\n",
            "reward of step 23273 is: 0.0001377094677236044\n",
            "reward of step 23274 is: 0.00012324897856511914\n",
            "reward of step 23275 is: 0.00012784700677667552\n",
            "reward of step 23276 is: 0.00013376374114875813\n",
            "reward of step 23277 is: 0.0001303184882921233\n",
            "reward of step 23278 is: 0.00011471993864472566\n",
            "reward of step 23279 is: 0.00013405712168145596\n",
            "reward of step 23280 is: 0.00013485414397994196\n",
            "reward of step 23281 is: 0.0001289593654160213\n",
            "reward of step 23282 is: 0.00013085909118131726\n",
            "reward of step 23283 is: 0.00014444008375362366\n",
            "reward of step 23284 is: 0.00012186899570940056\n",
            "reward of step 23285 is: 0.00013346974916061862\n",
            "reward of step 23286 is: 0.00012807401606532251\n",
            "reward of step 23287 is: 0.00013312173509825382\n",
            "reward of step 23288 is: 0.00012838621950870088\n",
            "reward of step 23289 is: 0.00013093260674256973\n",
            "reward of step 23290 is: 0.00013164743840524267\n",
            "reward of step 23291 is: 0.00013974963293994475\n",
            "reward of step 23292 is: 0.00011618580593348118\n",
            "reward of step 23293 is: 0.00012897027341782292\n",
            "reward of step 23294 is: 0.00013615208614381876\n",
            "reward of step 23295 is: 0.0001370660205840905\n",
            "reward of step 23296 is: 0.00011887866342407629\n",
            "reward of step 23297 is: 0.00012031913119637089\n",
            "reward of step 23298 is: 0.00012939012173585293\n",
            "reward of step 23299 is: 0.0001378721747692186\n",
            "reward of step 23300 is: 0.00012074359906953536\n",
            "reward of step 23301 is: 0.0001413876372322222\n",
            "reward of step 23302 is: 0.00013191743363603773\n",
            "reward of step 23303 is: 0.0001317894906549403\n",
            "reward of step 23304 is: 0.00012457168162182465\n",
            "reward of step 23305 is: 0.0001451027979625595\n",
            "reward of step 23306 is: 0.0001329278172332357\n",
            "reward of step 23307 is: 0.00012438727952179305\n",
            "reward of step 23308 is: 0.0001269754997526897\n",
            "reward of step 23309 is: 0.00012160160149740453\n",
            "reward of step 23310 is: 0.00013937963468791642\n",
            "reward of step 23311 is: 0.000129125981393434\n",
            "reward of step 23312 is: 0.00012683083033951652\n",
            "reward of step 23313 is: 0.00012534128752566073\n",
            "reward of step 23314 is: 0.00013020493769986833\n",
            "reward of step 23315 is: 0.00013171129750231975\n",
            "reward of step 23316 is: 0.00012903242526882851\n",
            "reward of step 23317 is: 0.00013668264076326602\n",
            "reward of step 23318 is: 0.00013370479765025816\n",
            "reward of step 23319 is: 0.0001333114701923705\n",
            "reward of step 23320 is: 0.00013260663531342967\n",
            "reward of step 23321 is: 0.00012573562233921621\n",
            "reward of step 23322 is: 0.00013825180872337924\n",
            "reward of step 23323 is: 0.0001319456594105427\n",
            "reward of step 23324 is: 0.00013045687844264017\n",
            "reward of step 23325 is: 0.00012313598372047923\n",
            "reward of step 23326 is: 0.0001443623529748063\n",
            "reward of step 23327 is: 0.00012493934727341105\n",
            "reward of step 23328 is: 0.00012031877939028248\n",
            "reward of step 23329 is: 0.00012057858151596801\n",
            "reward of step 23330 is: 0.00013530735452860272\n",
            "reward of step 23331 is: 0.0001233896885327899\n",
            "reward of step 23332 is: 0.00013888154645298647\n",
            "reward of step 23333 is: 0.00013922951625025147\n",
            "reward of step 23334 is: 0.00013972611612449423\n",
            "reward of step 23335 is: 0.0001275387825542046\n",
            "reward of step 23336 is: 0.00012223204487296987\n",
            "reward of step 23337 is: 0.00013944852979441951\n",
            "reward of step 23338 is: 0.00014117284116894316\n",
            "reward of step 23339 is: 0.00013467928051617161\n",
            "reward of step 23340 is: 0.0001282427542368141\n",
            "reward of step 23341 is: 0.0001244476954162228\n",
            "reward of step 23342 is: 0.00012036924857801981\n",
            "reward of step 23343 is: 0.00012672426599087024\n",
            "reward of step 23344 is: 0.000134792651179622\n",
            "reward of step 23345 is: 0.00012740223226539798\n",
            "reward of step 23346 is: 0.00013170686009919905\n",
            "reward of step 23347 is: 0.00012580785342879893\n",
            "reward of step 23348 is: 0.00013115382954083512\n",
            "reward of step 23349 is: 0.00013929623499339528\n",
            "reward of step 23350 is: 0.00013859540004759394\n",
            "reward of step 23351 is: 0.00012457037044369976\n",
            "reward of step 23352 is: 0.00014095391711315067\n",
            "reward of step 23353 is: 0.00012347845910357997\n",
            "reward of step 23354 is: 0.00011847887145400607\n",
            "reward of step 23355 is: 0.00012758369396332072\n",
            "reward of step 23356 is: 0.0001381246891733397\n",
            "reward of step 23357 is: 0.0001364359000486096\n",
            "reward of step 23358 is: 0.00013241417406403702\n",
            "reward of step 23359 is: 0.00013459718185909844\n",
            "reward of step 23360 is: 0.00012577884195758587\n",
            "reward of step 23361 is: 0.0001290479265470382\n",
            "reward of step 23362 is: 0.0001283252539159639\n",
            "reward of step 23363 is: 0.00011203570621776528\n",
            "reward of step 23364 is: 0.00013540839852524669\n",
            "reward of step 23365 is: 0.00011471885852857384\n",
            "reward of step 23366 is: 0.0001392962437376028\n",
            "reward of step 23367 is: 0.00013434864344004954\n",
            "reward of step 23368 is: 0.00014298685806480414\n",
            "reward of step 23369 is: 0.00012023883310945096\n",
            "reward of step 23370 is: 0.00014163778374875146\n",
            "reward of step 23371 is: 0.00013513678140337934\n",
            "reward of step 23372 is: 0.00012487184684002015\n",
            "reward of step 23373 is: 0.0001214091010738235\n",
            "reward of step 23374 is: 0.0001170893891731858\n",
            "reward of step 23375 is: 0.00013190502495267855\n",
            "reward of step 23376 is: 0.00012123444807878039\n",
            "reward of step 23377 is: 0.00013983930581196492\n",
            "reward of step 23378 is: 0.00013371803506224226\n",
            "reward of step 23379 is: 0.00012683585268943105\n",
            "reward of step 23380 is: 0.00013251713306269714\n",
            "reward of step 23381 is: 0.0001428005873998988\n",
            "reward of step 23382 is: 0.00012267725562168887\n",
            "reward of step 23383 is: 0.0001318552407058008\n",
            "reward of step 23384 is: 0.00014103846484412745\n",
            "reward of step 23385 is: 0.00013278003641753865\n",
            "reward of step 23386 is: 0.0001280204255316015\n",
            "reward of step 23387 is: 0.00012225731247607262\n",
            "reward of step 23388 is: 0.0001333790846264251\n",
            "reward of step 23389 is: 0.00011931726348356791\n",
            "reward of step 23390 is: 0.00012082727691526333\n",
            "reward of step 23391 is: 0.00013406303692902518\n",
            "reward of step 23392 is: 0.00013700704738788124\n",
            "reward of step 23393 is: 0.00013287123516941425\n",
            "reward of step 23394 is: 0.00013784959941198093\n",
            "reward of step 23395 is: 0.00012645693867992258\n",
            "reward of step 23396 is: 0.00012810362857722889\n",
            "reward of step 23397 is: 0.0001287491254520069\n",
            "reward of step 23398 is: 0.0001312249109384679\n",
            "reward of step 23399 is: 0.00014569468260947633\n",
            "reward of step 23400 is: 0.0001156092071337386\n",
            "reward of step 23401 is: 0.0001262139323000515\n",
            "reward of step 23402 is: 0.0001224434033105891\n",
            "reward of step 23403 is: 0.0001301433804886914\n",
            "reward of step 23404 is: 0.00012311700967846837\n",
            "reward of step 23405 is: 0.00011986200187103407\n",
            "reward of step 23406 is: 0.00012742058256393486\n",
            "reward of step 23407 is: 0.0001281519517449013\n",
            "reward of step 23408 is: 0.00013002694648936664\n",
            "reward of step 23409 is: 0.00012657358988411554\n",
            "reward of step 23410 is: 0.00011927855730426077\n",
            "reward of step 23411 is: 0.00012047862164218098\n",
            "reward of step 23412 is: 0.00013012404233876248\n",
            "reward of step 23413 is: 0.00012726710810845296\n",
            "reward of step 23414 is: 0.0001236222779278981\n",
            "reward of step 23415 is: 0.00012985112677089836\n",
            "reward of step 23416 is: 0.0001339879469058971\n",
            "reward of step 23417 is: 0.00014178432340413938\n",
            "reward of step 23418 is: 0.00012513377748790168\n",
            "reward of step 23419 is: 0.00013459044684111847\n",
            "reward of step 23420 is: 0.00013265869201607394\n",
            "reward of step 23421 is: 0.0001197586030110706\n",
            "reward of step 23422 is: 0.00012520570163491445\n",
            "reward of step 23423 is: 0.00014522366410630867\n",
            "reward of step 23424 is: 0.00012608563752901388\n",
            "reward of step 23425 is: 0.00013361718259904867\n",
            "reward of step 23426 is: 0.00011506518626082818\n",
            "reward of step 23427 is: 0.00013600631506418772\n",
            "reward of step 23428 is: 0.00012773591839771651\n",
            "reward of step 23429 is: 0.00012161184794675815\n",
            "reward of step 23430 is: 0.00013183936275460123\n",
            "reward of step 23431 is: 0.00013527919524538047\n",
            "reward of step 23432 is: 0.0001161489833333639\n",
            "reward of step 23433 is: 0.00012943076425564985\n",
            "reward of step 23434 is: 0.00013137894672639682\n",
            "reward of step 23435 is: 0.00013183332608846844\n",
            "reward of step 23436 is: 0.00012216710757987774\n",
            "reward of step 23437 is: 0.0001287209707918281\n",
            "reward of step 23438 is: 0.00013837053975977425\n",
            "reward of step 23439 is: 0.00013144771032065844\n",
            "reward of step 23440 is: 0.00012971099156012844\n",
            "reward of step 23441 is: 0.00013025600450022846\n",
            "reward of step 23442 is: 0.0001301514325733651\n",
            "reward of step 23443 is: 0.000132585630499101\n",
            "reward of step 23444 is: 0.0001229724707071226\n",
            "reward of step 23445 is: 0.0001287750495888336\n",
            "reward of step 23446 is: 0.00014384991893541662\n",
            "reward of step 23447 is: 0.00012877113671412382\n",
            "reward of step 23448 is: 0.00012671280065606165\n",
            "reward of step 23449 is: 0.0001370741788603982\n",
            "reward of step 23450 is: 0.00012236279506499948\n",
            "reward of step 23451 is: 0.00013171916492511103\n",
            "reward of step 23452 is: 0.00012666066683743833\n",
            "reward of step 23453 is: 0.0001399300571667606\n",
            "reward of step 23454 is: 0.00013940794931649242\n",
            "reward of step 23455 is: 0.0001237153357636479\n",
            "reward of step 23456 is: 0.0001304731684332631\n",
            "reward of step 23457 is: 0.00012369103244534255\n",
            "reward of step 23458 is: 0.00013437202309825322\n",
            "reward of step 23459 is: 0.00011921860726759118\n",
            "reward of step 23460 is: 0.0001346555312307053\n",
            "reward of step 23461 is: 0.00012575024862406648\n",
            "reward of step 23462 is: 0.00012912448399452953\n",
            "reward of step 23463 is: 0.0001384662072860774\n",
            "reward of step 23464 is: 0.00012541424482608816\n",
            "reward of step 23465 is: 0.0001182822627889322\n",
            "reward of step 23466 is: 0.0001325380199870821\n",
            "reward of step 23467 is: 0.00013052142696252751\n",
            "reward of step 23468 is: 0.00012520030824955553\n",
            "reward of step 23469 is: 0.00012958184568061815\n",
            "reward of step 23470 is: 0.0001365526338302133\n",
            "reward of step 23471 is: 0.00013656443182296057\n",
            "reward of step 23472 is: 0.00012523975807584903\n",
            "reward of step 23473 is: 0.00013166014386683874\n",
            "reward of step 23474 is: 0.00011958603942469196\n",
            "reward of step 23475 is: 0.00013836557947637985\n",
            "reward of step 23476 is: 0.00013666795401421516\n",
            "reward of step 23477 is: 0.00012558127284066723\n",
            "reward of step 23478 is: 0.00013379601084639653\n",
            "reward of step 23479 is: 0.00012779630596354086\n",
            "reward of step 23480 is: 0.0001408353303009495\n",
            "reward of step 23481 is: 0.0001234975442659102\n",
            "reward of step 23482 is: 0.0001232023416442932\n",
            "reward of step 23483 is: 0.00012832533816342084\n",
            "reward of step 23484 is: 0.00013518256642501583\n",
            "reward of step 23485 is: 0.00013334545799600076\n",
            "reward of step 23486 is: 0.00012250470232675294\n",
            "reward of step 23487 is: 0.00012842439863568387\n",
            "reward of step 23488 is: 0.00012848266794442887\n",
            "reward of step 23489 is: 0.00012168621648225567\n",
            "reward of step 23490 is: 0.00012454878301292854\n",
            "reward of step 23491 is: 0.00011323228779239413\n",
            "reward of step 23492 is: 0.00013468162948527876\n",
            "reward of step 23493 is: 0.0001232072241019833\n",
            "reward of step 23494 is: 0.00012721168199576874\n",
            "reward of step 23495 is: 0.00013739831009764236\n",
            "reward of step 23496 is: 0.00013889624367833248\n",
            "reward of step 23497 is: 0.00013449003267810962\n",
            "reward of step 23498 is: 0.00012979701566829632\n",
            "reward of step 23499 is: 0.0001277804488219576\n",
            "reward of step 23500 is: 0.00012766794630514452\n",
            "reward of step 23501 is: 0.0001353925280062623\n",
            "reward of step 23502 is: 0.0001375057860010054\n",
            "reward of step 23503 is: 0.00014262559034156804\n",
            "reward of step 23504 is: 0.00011570507268632204\n",
            "reward of step 23505 is: 0.00013251439545679226\n",
            "reward of step 23506 is: 0.00012563113798451673\n",
            "reward of step 23507 is: 0.00013835442310576333\n",
            "reward of step 23508 is: 0.00012695819452403513\n",
            "reward of step 23509 is: 0.0001147348262486327\n",
            "reward of step 23510 is: 0.0001355696248307592\n",
            "reward of step 23511 is: 0.00014442770758080054\n",
            "reward of step 23512 is: 0.0001223590546223378\n",
            "reward of step 23513 is: 0.00012634091203077405\n",
            "reward of step 23514 is: 0.00014108949247901702\n",
            "reward of step 23515 is: 0.00013469589155315663\n",
            "reward of step 23516 is: 0.00012410506925608118\n",
            "reward of step 23517 is: 0.00012941539979831755\n",
            "reward of step 23518 is: 0.00013831407536210897\n",
            "reward of step 23519 is: 0.00012575067663326826\n",
            "reward of step 23520 is: 0.00012985081735369632\n",
            "reward of step 23521 is: 0.00011892758380181004\n",
            "reward of step 23522 is: 0.00012994633217744634\n",
            "reward of step 23523 is: 0.00014346317627528197\n",
            "reward of step 23524 is: 0.00014412009284712915\n",
            "reward of step 23525 is: 0.0001306807167655867\n",
            "reward of step 23526 is: 0.00012223691698127126\n",
            "reward of step 23527 is: 0.00011798299645531036\n",
            "reward of step 23528 is: 0.00013304183370031668\n",
            "reward of step 23529 is: 0.0001297766107998509\n",
            "reward of step 23530 is: 0.00013150077922689278\n",
            "reward of step 23531 is: 0.00012849425804491908\n",
            "reward of step 23532 is: 0.00013580376157221842\n",
            "reward of step 23533 is: 0.00012138612126858502\n",
            "reward of step 23534 is: 0.00014591716505294786\n",
            "reward of step 23535 is: 0.00013881210746289954\n",
            "reward of step 23536 is: 0.00012546054442374386\n",
            "reward of step 23537 is: 0.00014323064125358086\n",
            "reward of step 23538 is: 0.00013555799394320375\n",
            "reward of step 23539 is: 0.00011485165313521758\n",
            "reward of step 23540 is: 0.0001414103472573659\n",
            "reward of step 23541 is: 0.0001370217433886158\n",
            "reward of step 23542 is: 0.000132819214430303\n",
            "reward of step 23543 is: 0.00011948192966913675\n",
            "reward of step 23544 is: 0.00014724761211941904\n",
            "reward of step 23545 is: 0.00013766573081775972\n",
            "reward of step 23546 is: 0.00011731985686343269\n",
            "reward of step 23547 is: 0.00011410888628132333\n",
            "reward of step 23548 is: 0.00013573195124356975\n",
            "reward of step 23549 is: 0.0001473730596508921\n",
            "reward of step 23550 is: 0.000139231702874773\n",
            "reward of step 23551 is: 0.00012963416159849305\n",
            "reward of step 23552 is: 0.00012829343782039222\n",
            "reward of step 23553 is: 0.00011680449117656511\n",
            "reward of step 23554 is: 0.0001248147969134482\n",
            "reward of step 23555 is: 0.00012121255427664396\n",
            "reward of step 23556 is: 0.00013405719273548378\n",
            "reward of step 23557 is: 0.00011628346175685073\n",
            "reward of step 23558 is: 0.00011259920571506248\n",
            "reward of step 23559 is: 0.00012168010879295831\n",
            "reward of step 23560 is: 0.000132836122532798\n",
            "reward of step 23561 is: 0.00012646307835959954\n",
            "reward of step 23562 is: 0.00011537562143293979\n",
            "reward of step 23563 is: 0.00014893479401005454\n",
            "reward of step 23564 is: 0.00013263206376454322\n",
            "reward of step 23565 is: 0.00012727170095798164\n",
            "reward of step 23566 is: 0.000129151686970955\n",
            "reward of step 23567 is: 0.0001160866729364145\n",
            "reward of step 23568 is: 0.00013037399423339007\n",
            "reward of step 23569 is: 0.00013195746270581063\n",
            "reward of step 23570 is: 0.00013239573237595689\n",
            "reward of step 23571 is: 0.00013775077860659469\n",
            "reward of step 23572 is: 0.00013084382469690802\n",
            "reward of step 23573 is: 0.00012976650582788272\n",
            "reward of step 23574 is: 0.0001382567468283391\n",
            "reward of step 23575 is: 0.00013490759998624735\n",
            "reward of step 23576 is: 0.0001407528422944439\n",
            "reward of step 23577 is: 0.0001398837302598661\n",
            "reward of step 23578 is: 0.0001350074566575255\n",
            "reward of step 23579 is: 0.0001410619275027524\n",
            "reward of step 23580 is: 0.0001404720756903512\n",
            "reward of step 23581 is: 0.00013443031077181204\n",
            "reward of step 23582 is: 0.00011871081827888758\n",
            "reward of step 23583 is: 0.00013447794685891124\n",
            "reward of step 23584 is: 0.0001236580095728923\n",
            "reward of step 23585 is: 0.0001370903127735063\n",
            "reward of step 23586 is: 0.0001205332619853043\n",
            "reward of step 23587 is: 0.0001338530133746107\n",
            "reward of step 23588 is: 0.00012981821108765497\n",
            "reward of step 23589 is: 0.00014247658263304752\n",
            "reward of step 23590 is: 0.0001285700097403238\n",
            "reward of step 23591 is: 0.00012676824381813528\n",
            "reward of step 23592 is: 0.00011626589155560861\n",
            "reward of step 23593 is: 0.00013283992327072888\n",
            "reward of step 23594 is: 0.00011347202783446463\n",
            "reward of step 23595 is: 0.00011904229485374899\n",
            "reward of step 23596 is: 0.00013010280874197773\n",
            "reward of step 23597 is: 0.00013773777159221829\n",
            "reward of step 23598 is: 0.00012117491972987631\n",
            "reward of step 23599 is: 0.00012094988017723353\n",
            "reward of step 23600 is: 0.00013021852406816235\n",
            "reward of step 23601 is: 0.0001313472987982331\n",
            "reward of step 23602 is: 0.00013885072354705987\n",
            "reward of step 23603 is: 0.00014037078148013108\n",
            "reward of step 23604 is: 0.0001364928266371959\n",
            "reward of step 23605 is: 0.00011416997838483202\n",
            "reward of step 23606 is: 0.0001211795007159673\n",
            "reward of step 23607 is: 0.0001300308736355196\n",
            "reward of step 23608 is: 0.00012318663672139608\n",
            "reward of step 23609 is: 0.00012445963353098155\n",
            "reward of step 23610 is: 0.00012703770134091995\n",
            "reward of step 23611 is: 0.00012938998575508272\n",
            "reward of step 23612 is: 0.00012921141214381529\n",
            "reward of step 23613 is: 0.00011754903415860912\n",
            "reward of step 23614 is: 0.0001319749475491516\n",
            "reward of step 23615 is: 0.00011862218877478281\n",
            "reward of step 23616 is: 0.00012690785760939794\n",
            "reward of step 23617 is: 0.0001298381059594177\n",
            "reward of step 23618 is: 0.0001331617970989505\n",
            "reward of step 23619 is: 0.00012495220722009124\n",
            "reward of step 23620 is: 0.00012967580752250356\n",
            "reward of step 23621 is: 0.00013216972102406705\n",
            "reward of step 23622 is: 0.00012835474588534772\n",
            "reward of step 23623 is: 0.00014427113966655915\n",
            "reward of step 23624 is: 0.00013149251656471717\n",
            "reward of step 23625 is: 0.00011961579153290751\n",
            "reward of step 23626 is: 0.00012389054706073263\n",
            "reward of step 23627 is: 0.00012926271151671195\n",
            "reward of step 23628 is: 0.0001341668282541898\n",
            "reward of step 23629 is: 0.00012426993712099196\n",
            "reward of step 23630 is: 0.00011896945616059216\n",
            "reward of step 23631 is: 0.00013934081416305837\n",
            "reward of step 23632 is: 0.00011888760450814523\n",
            "reward of step 23633 is: 0.00013055815132648467\n",
            "reward of step 23634 is: 0.00012451542321158707\n",
            "reward of step 23635 is: 0.00012037950157847795\n",
            "reward of step 23636 is: 0.0001281615642251149\n",
            "reward of step 23637 is: 0.00012822315695439746\n",
            "reward of step 23638 is: 0.00011997749093754129\n",
            "reward of step 23639 is: 0.00012135160703347986\n",
            "reward of step 23640 is: 0.00011787434027759243\n",
            "reward of step 23641 is: 0.00013311246298778468\n",
            "reward of step 23642 is: 0.00012965519165901405\n",
            "reward of step 23643 is: 0.0001229525459021837\n",
            "reward of step 23644 is: 0.00012750322807574433\n",
            "reward of step 23645 is: 0.00013846922685075645\n",
            "reward of step 23646 is: 0.0001248544866734969\n",
            "reward of step 23647 is: 0.0001308772446179388\n",
            "reward of step 23648 is: 0.00013292255099898632\n",
            "reward of step 23649 is: 0.00012950566109761098\n",
            "reward of step 23650 is: 0.000127115699874499\n",
            "reward of step 23651 is: 0.0001420182337677717\n",
            "reward of step 23652 is: 0.00013347495217553762\n",
            "reward of step 23653 is: 0.00012067356973939425\n",
            "reward of step 23654 is: 0.00012841457377294526\n",
            "reward of step 23655 is: 0.00013426702045489446\n",
            "reward of step 23656 is: 0.00014396623878692484\n",
            "reward of step 23657 is: 0.000130041030283822\n",
            "reward of step 23658 is: 0.00014572021767812206\n",
            "reward of step 23659 is: 0.0001277936199305636\n",
            "reward of step 23660 is: 0.00012931740061558267\n",
            "reward of step 23661 is: 0.00012481550904507456\n",
            "reward of step 23662 is: 0.000128747440159187\n",
            "reward of step 23663 is: 0.0001372673930088847\n",
            "reward of step 23664 is: 0.00013030097689970777\n",
            "reward of step 23665 is: 0.00013718448160959082\n",
            "reward of step 23666 is: 0.00013605314678843023\n",
            "reward of step 23667 is: 0.00013521272841729657\n",
            "reward of step 23668 is: 0.00013541204862935292\n",
            "reward of step 23669 is: 0.00013088628395293517\n",
            "reward of step 23670 is: 0.00013460722123573713\n",
            "reward of step 23671 is: 0.00013516654040699648\n",
            "reward of step 23672 is: 0.00012887306463777853\n",
            "reward of step 23673 is: 0.000129000237338413\n",
            "reward of step 23674 is: 0.0001433886301227104\n",
            "reward of step 23675 is: 0.0001297151199932815\n",
            "reward of step 23676 is: 0.00012366577691474918\n",
            "reward of step 23677 is: 0.00013598948256968\n",
            "reward of step 23678 is: 0.00012888659519261613\n",
            "reward of step 23679 is: 0.0001395327679588843\n",
            "reward of step 23680 is: 0.00012704852220080142\n",
            "reward of step 23681 is: 0.00012542499860420091\n",
            "reward of step 23682 is: 0.00011457323945688397\n",
            "reward of step 23683 is: 0.00013173116435771724\n",
            "reward of step 23684 is: 0.00013682846555838486\n",
            "reward of step 23685 is: 0.000122286288554112\n",
            "reward of step 23686 is: 0.0001263623089013031\n",
            "reward of step 23687 is: 0.00012081177221235003\n",
            "reward of step 23688 is: 0.00013064532162507898\n",
            "reward of step 23689 is: 0.00013004161328744279\n",
            "reward of step 23690 is: 0.00013251970305939753\n",
            "reward of step 23691 is: 0.00014465945495695503\n",
            "reward of step 23692 is: 0.00012699470512139794\n",
            "reward of step 23693 is: 0.00013626060133704274\n",
            "reward of step 23694 is: 0.00013529660983804597\n",
            "reward of step 23695 is: 0.00013320123234440698\n",
            "reward of step 23696 is: 0.00012907795503843016\n",
            "reward of step 23697 is: 0.00012711063989754445\n",
            "reward of step 23698 is: 0.000135886079475994\n",
            "reward of step 23699 is: 0.00013493091620585512\n",
            "reward of step 23700 is: 0.00013617725548084473\n",
            "reward of step 23701 is: 0.0001352087657182773\n",
            "reward of step 23702 is: 0.00012904613061700464\n",
            "reward of step 23703 is: 0.00014198754170506022\n",
            "reward of step 23704 is: 0.00013464015500078028\n",
            "reward of step 23705 is: 0.00011368980251113865\n",
            "reward of step 23706 is: 0.00011422653801506693\n",
            "reward of step 23707 is: 0.00012870322956835654\n",
            "reward of step 23708 is: 0.00013761555608167697\n",
            "reward of step 23709 is: 0.000127038910968468\n",
            "reward of step 23710 is: 0.00013764697808362345\n",
            "reward of step 23711 is: 0.00012854069554767974\n",
            "reward of step 23712 is: 0.00012653764255746597\n",
            "reward of step 23713 is: 0.00012713667664923667\n",
            "reward of step 23714 is: 0.0001292641622201094\n",
            "reward of step 23715 is: 0.00012813149977155497\n",
            "reward of step 23716 is: 0.0001339582760888914\n",
            "reward of step 23717 is: 0.0001272075733519803\n",
            "reward of step 23718 is: 0.00013475568696038877\n",
            "reward of step 23719 is: 0.00012568672316646637\n",
            "reward of step 23720 is: 0.00013417876180526927\n",
            "reward of step 23721 is: 0.00013901444694786548\n",
            "reward of step 23722 is: 0.00013652029718042786\n",
            "reward of step 23723 is: 0.00012708828820373648\n",
            "reward of step 23724 is: 0.0001322890807100576\n",
            "reward of step 23725 is: 0.00012090027349340491\n",
            "reward of step 23726 is: 0.0001238340992821135\n",
            "reward of step 23727 is: 0.0001385580118060787\n",
            "reward of step 23728 is: 0.00012554005619630677\n",
            "reward of step 23729 is: 0.00012798442284977376\n",
            "reward of step 23730 is: 0.00012791359807406096\n",
            "reward of step 23731 is: 0.00011781725870032608\n",
            "reward of step 23732 is: 0.00011987360382339335\n",
            "reward of step 23733 is: 0.00012859608747679444\n",
            "reward of step 23734 is: 0.00013578064917452317\n",
            "reward of step 23735 is: 0.0001230880876766752\n",
            "reward of step 23736 is: 0.0001354568670969932\n",
            "reward of step 23737 is: 0.00012597037700864575\n",
            "reward of step 23738 is: 0.00013014486112757352\n",
            "reward of step 23739 is: 0.00012724140378117763\n",
            "reward of step 23740 is: 0.0001357506441973218\n",
            "reward of step 23741 is: 0.0001192245078875191\n",
            "reward of step 23742 is: 0.00012749264814373556\n",
            "reward of step 23743 is: 0.00013655597452219212\n",
            "reward of step 23744 is: 0.0001337498971711617\n",
            "reward of step 23745 is: 0.00012980050503722603\n",
            "reward of step 23746 is: 0.00012501223610519963\n",
            "reward of step 23747 is: 0.00012317926957197738\n",
            "reward of step 23748 is: 0.0001280012101052807\n",
            "reward of step 23749 is: 0.00011707748800455367\n",
            "reward of step 23750 is: 0.00012959080010495154\n",
            "reward of step 23751 is: 0.00012169580951884096\n",
            "reward of step 23752 is: 0.00012294359525203983\n",
            "reward of step 23753 is: 0.00013989442896081576\n",
            "reward of step 23754 is: 0.00013829509585059821\n",
            "reward of step 23755 is: 0.00013024832688191289\n",
            "reward of step 23756 is: 0.0001314916735389783\n",
            "reward of step 23757 is: 0.00014905853216228254\n",
            "reward of step 23758 is: 0.00012460525647599145\n",
            "reward of step 23759 is: 0.0001378034110095389\n",
            "reward of step 23760 is: 0.00012958946159872294\n",
            "reward of step 23761 is: 0.00013171986903818164\n",
            "reward of step 23762 is: 0.00013139762108295544\n",
            "reward of step 23763 is: 0.00013037848209979642\n",
            "reward of step 23764 is: 0.0001320050630400273\n",
            "reward of step 23765 is: 0.00013615601395287452\n",
            "reward of step 23766 is: 0.00013790008516803969\n",
            "reward of step 23767 is: 0.00014085613149106437\n",
            "reward of step 23768 is: 0.00012348755983930835\n",
            "reward of step 23769 is: 0.00014289165334959865\n",
            "reward of step 23770 is: 0.00012825313007344357\n",
            "reward of step 23771 is: 0.00013195646496174147\n",
            "reward of step 23772 is: 0.00013176776208058226\n",
            "reward of step 23773 is: 0.00012272849802924033\n",
            "reward of step 23774 is: 0.00013930809054429853\n",
            "reward of step 23775 is: 0.0001281623148174363\n",
            "reward of step 23776 is: 0.00013723257888646176\n",
            "reward of step 23777 is: 0.00012687993537252744\n",
            "reward of step 23778 is: 0.00012432196247660532\n",
            "reward of step 23779 is: 0.00012409522876580633\n",
            "reward of step 23780 is: 0.00014094212704711292\n",
            "reward of step 23781 is: 0.00012697101553598233\n",
            "reward of step 23782 is: 0.00013225823934236944\n",
            "reward of step 23783 is: 0.0001454261786072266\n",
            "reward of step 23784 is: 0.0001231782008584448\n",
            "reward of step 23785 is: 0.00012075881337756175\n",
            "reward of step 23786 is: 0.0001391463154236313\n",
            "reward of step 23787 is: 0.0001321287425082335\n",
            "reward of step 23788 is: 0.0001312243577823799\n",
            "reward of step 23789 is: 0.0001177747184672994\n",
            "reward of step 23790 is: 0.00012665498655657455\n",
            "reward of step 23791 is: 0.00012108202754132811\n",
            "reward of step 23792 is: 0.00012613870315780494\n",
            "reward of step 23793 is: 0.00013838568791848624\n",
            "reward of step 23794 is: 0.00012455142227481698\n",
            "reward of step 23795 is: 0.00014434690947549164\n",
            "reward of step 23796 is: 0.00011549313407997419\n",
            "reward of step 23797 is: 0.00012654924568734194\n",
            "reward of step 23798 is: 0.00012114802780712988\n",
            "reward of step 23799 is: 0.00012685848925938085\n",
            "reward of step 23800 is: 0.0001373962407639803\n",
            "reward of step 23801 is: 0.0001249013527846702\n",
            "reward of step 23802 is: 0.0001400722825702763\n",
            "reward of step 23803 is: 0.0001317870764796941\n",
            "reward of step 23804 is: 0.0001334241424358146\n",
            "reward of step 23805 is: 0.00013568957276416556\n",
            "reward of step 23806 is: 0.00011818514725646484\n",
            "reward of step 23807 is: 0.00012547025037482602\n",
            "reward of step 23808 is: 0.0001255134222310449\n",
            "reward of step 23809 is: 0.00012912882395431615\n",
            "reward of step 23810 is: 0.00012205322050983173\n",
            "reward of step 23811 is: 0.00013162413272192815\n",
            "reward of step 23812 is: 0.00013901230470291653\n",
            "reward of step 23813 is: 0.00014288569369295544\n",
            "reward of step 23814 is: 0.00012121164040828309\n",
            "reward of step 23815 is: 0.0001349434684148865\n",
            "reward of step 23816 is: 0.0001276405211062608\n",
            "reward of step 23817 is: 0.00012884915118262314\n",
            "reward of step 23818 is: 0.00012676798524810935\n",
            "reward of step 23819 is: 0.00014216205265535226\n",
            "reward of step 23820 is: 0.00012500126963308706\n",
            "reward of step 23821 is: 0.00012836412231504105\n",
            "reward of step 23822 is: 0.00012660923030414616\n",
            "reward of step 23823 is: 0.00014125069998731328\n",
            "reward of step 23824 is: 0.0001399406911940117\n",
            "reward of step 23825 is: 0.0001236576647071972\n",
            "reward of step 23826 is: 0.00012603025558774255\n",
            "reward of step 23827 is: 0.00013304093205587618\n",
            "reward of step 23828 is: 0.00012848534532381074\n",
            "reward of step 23829 is: 0.00013139869797626147\n",
            "reward of step 23830 is: 0.00012928278948683342\n",
            "reward of step 23831 is: 0.00013509325241048317\n",
            "reward of step 23832 is: 0.00013707607624229167\n",
            "reward of step 23833 is: 0.00012073572005310067\n",
            "reward of step 23834 is: 0.00013164923397340547\n",
            "reward of step 23835 is: 0.0001244988952553589\n",
            "reward of step 23836 is: 0.0001398505258832953\n",
            "reward of step 23837 is: 0.00012659136152734003\n",
            "reward of step 23838 is: 0.00012715877929733157\n",
            "reward of step 23839 is: 0.0001221943000198736\n",
            "reward of step 23840 is: 0.00013390064675997292\n",
            "reward of step 23841 is: 0.00012670397586555352\n",
            "reward of step 23842 is: 0.00013789639771071775\n",
            "reward of step 23843 is: 0.00013028874363705634\n",
            "reward of step 23844 is: 0.00012410227000923322\n",
            "reward of step 23845 is: 0.00013625474801254764\n",
            "reward of step 23846 is: 0.00013911436628593124\n",
            "reward of step 23847 is: 0.0001499568398762851\n",
            "reward of step 23848 is: 0.00013259269176666626\n",
            "reward of step 23849 is: 0.0001222677865473116\n",
            "reward of step 23850 is: 0.0001366513464171\n",
            "reward of step 23851 is: 0.00013532508637066788\n",
            "reward of step 23852 is: 0.00013522988058963718\n",
            "reward of step 23853 is: 0.0001286869391012247\n",
            "reward of step 23854 is: 0.00013664306302559772\n",
            "reward of step 23855 is: 0.00011570034649904234\n",
            "reward of step 23856 is: 0.00012427143667962068\n",
            "reward of step 23857 is: 0.0001345484340988501\n",
            "reward of step 23858 is: 0.00011486623895610091\n",
            "reward of step 23859 is: 0.0001362984883042029\n",
            "reward of step 23860 is: 0.0001231025405378317\n",
            "reward of step 23861 is: 0.00012806449577115126\n",
            "reward of step 23862 is: 0.0001261247507789934\n",
            "reward of step 23863 is: 0.00014364260149521006\n",
            "reward of step 23864 is: 0.00011862803801288886\n",
            "reward of step 23865 is: 0.00014193722610638396\n",
            "reward of step 23866 is: 0.00013384112328703848\n",
            "reward of step 23867 is: 0.00011670154145259169\n",
            "reward of step 23868 is: 0.00013086294068667158\n",
            "reward of step 23869 is: 0.00012874109379079661\n",
            "reward of step 23870 is: 0.00011673557729532306\n",
            "reward of step 23871 is: 0.0001338799034473443\n",
            "reward of step 23872 is: 0.00011578799533962498\n",
            "reward of step 23873 is: 0.0001336126078948271\n",
            "reward of step 23874 is: 0.00013198528320953546\n",
            "reward of step 23875 is: 0.00012933221631414174\n",
            "reward of step 23876 is: 0.00013465357238889446\n",
            "reward of step 23877 is: 0.00013694071373550521\n",
            "reward of step 23878 is: 0.00012894637739687204\n",
            "reward of step 23879 is: 0.00014498990088518607\n",
            "reward of step 23880 is: 0.00013734486955044607\n",
            "reward of step 23881 is: 0.00012511809550180326\n",
            "reward of step 23882 is: 0.00012226820906487525\n",
            "reward of step 23883 is: 0.00013098912518945744\n",
            "reward of step 23884 is: 0.0001321455863965889\n",
            "reward of step 23885 is: 0.0001364430680099742\n",
            "reward of step 23886 is: 0.00012718448244529687\n",
            "reward of step 23887 is: 0.00013605701686519105\n",
            "reward of step 23888 is: 0.00013041677948406245\n",
            "reward of step 23889 is: 0.00012953972871277954\n",
            "reward of step 23890 is: 0.0001332992874991589\n",
            "reward of step 23891 is: 0.00012621050624202212\n",
            "reward of step 23892 is: 0.00011681986111415815\n",
            "reward of step 23893 is: 0.00015051120208417433\n",
            "reward of step 23894 is: 0.00011719636131644445\n",
            "reward of step 23895 is: 0.0001260766418927575\n",
            "reward of step 23896 is: 0.00013042903897614194\n",
            "reward of step 23897 is: 0.00013215064619046427\n",
            "reward of step 23898 is: 0.000145847938470535\n",
            "reward of step 23899 is: 0.00013551566344041944\n",
            "reward of step 23900 is: 0.00011983934830235477\n",
            "reward of step 23901 is: 0.00013327517964119306\n",
            "reward of step 23902 is: 0.0001300198255650231\n",
            "reward of step 23903 is: 0.00013629548320368156\n",
            "reward of step 23904 is: 0.00013342728644630473\n",
            "reward of step 23905 is: 0.0001359530333841286\n",
            "reward of step 23906 is: 0.00011975808632413018\n",
            "reward of step 23907 is: 0.00012060679134530064\n",
            "reward of step 23908 is: 0.00013841674627812226\n",
            "reward of step 23909 is: 0.00012884394882179025\n",
            "reward of step 23910 is: 0.00011033174694757375\n",
            "reward of step 23911 is: 0.00012963189535125397\n",
            "reward of step 23912 is: 0.00013808137066914888\n",
            "reward of step 23913 is: 0.00013358082047575752\n",
            "reward of step 23914 is: 0.00011725169669576735\n",
            "reward of step 23915 is: 0.00013105810649353508\n",
            "reward of step 23916 is: 0.00013579526382921062\n",
            "reward of step 23917 is: 0.00011443620203293793\n",
            "reward of step 23918 is: 0.0001372092201570347\n",
            "reward of step 23919 is: 0.00014461542857149569\n",
            "reward of step 23920 is: 0.0001284492679748238\n",
            "reward of step 23921 is: 0.00013486627771666597\n",
            "reward of step 23922 is: 0.00013824716870070969\n",
            "reward of step 23923 is: 0.00011551261636225467\n",
            "reward of step 23924 is: 0.00012683760268337186\n",
            "reward of step 23925 is: 0.00013632359858200763\n",
            "reward of step 23926 is: 0.00013223413816461997\n",
            "reward of step 23927 is: 0.00012589117642055803\n",
            "reward of step 23928 is: 0.00012405867712123197\n",
            "reward of step 23929 is: 0.00013522854052083194\n",
            "reward of step 23930 is: 0.00014127038860360972\n",
            "reward of step 23931 is: 0.00012241417151792562\n",
            "reward of step 23932 is: 0.00012024777846916324\n",
            "reward of step 23933 is: 0.00011413956807643992\n",
            "reward of step 23934 is: 0.00012352455512822365\n",
            "reward of step 23935 is: 0.00012697577372787594\n",
            "reward of step 23936 is: 0.0001239194594261551\n",
            "reward of step 23937 is: 0.00013287697420137978\n",
            "reward of step 23938 is: 0.00012285311954480222\n",
            "reward of step 23939 is: 0.0001376066761120671\n",
            "reward of step 23940 is: 0.00011844713724937624\n",
            "reward of step 23941 is: 0.00013068764970571703\n",
            "reward of step 23942 is: 0.00012815483700666784\n",
            "reward of step 23943 is: 0.00013702079795793872\n",
            "reward of step 23944 is: 0.00012301864653996557\n",
            "reward of step 23945 is: 0.0001235598276244705\n",
            "reward of step 23946 is: 0.00011624187861848241\n",
            "reward of step 23947 is: 0.0001230976019430206\n",
            "reward of step 23948 is: 0.00012969520966142457\n",
            "reward of step 23949 is: 0.0001158735449694061\n",
            "reward of step 23950 is: 0.00013453985633010392\n",
            "reward of step 23951 is: 0.00012906782535819684\n",
            "reward of step 23952 is: 0.00012725788345595293\n",
            "reward of step 23953 is: 0.0001182133272060733\n",
            "reward of step 23954 is: 0.00011980567556452711\n",
            "reward of step 23955 is: 0.00012743380814527735\n",
            "reward of step 23956 is: 0.00013673894528674557\n",
            "reward of step 23957 is: 0.00013542855070074555\n",
            "reward of step 23958 is: 0.00012560520157041418\n",
            "reward of step 23959 is: 0.00013358848250942778\n",
            "reward of step 23960 is: 0.00012658017795781688\n",
            "reward of step 23961 is: 0.0001328494312580917\n",
            "reward of step 23962 is: 0.0001246131852940269\n",
            "reward of step 23963 is: 0.00013210480488895675\n",
            "reward of step 23964 is: 0.00013007563157176584\n",
            "reward of step 23965 is: 0.00012273417282764761\n",
            "reward of step 23966 is: 0.0001313136549879306\n",
            "reward of step 23967 is: 0.000124419916174847\n",
            "reward of step 23968 is: 0.00011776745903295993\n",
            "reward of step 23969 is: 0.00012047160070849703\n",
            "reward of step 23970 is: 0.00013926142455962078\n",
            "reward of step 23971 is: 0.00011627278445749892\n",
            "reward of step 23972 is: 0.0001249009637319241\n",
            "reward of step 23973 is: 0.00013908525760760896\n",
            "reward of step 23974 is: 0.00012506098298179465\n",
            "reward of step 23975 is: 0.0001399547173343234\n",
            "reward of step 23976 is: 0.00014060801027754367\n",
            "reward of step 23977 is: 0.00012509068334561773\n",
            "reward of step 23978 is: 0.00013906750560374297\n",
            "reward of step 23979 is: 0.00012611026559959204\n",
            "reward of step 23980 is: 0.00013850958762815478\n",
            "reward of step 23981 is: 0.0001308055240402426\n",
            "reward of step 23982 is: 0.00013101481215682962\n",
            "reward of step 23983 is: 0.00011253612497826387\n",
            "reward of step 23984 is: 0.00012212387747812382\n",
            "reward of step 23985 is: 0.00013751644786981186\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4326fee8443c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-86275e2ecc46>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_frames, plotting_interval)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_step\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_random_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             ):\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mactor_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mcritic_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-86275e2ecc46>\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m  \u001b[0;31m# for shortening the following lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"next_obs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-3b6b9afdad49>\u001b[0m in \u001b[0;36msample_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;34m\"\"\"Randomly sample a batch of experiences from memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0midxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         return dict(obs=self.obs_buf[idxs],\n\u001b[1;32m     35\u001b[0m                     \u001b[0mnext_obs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_obs_buf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "7p0roQPkH46C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.array([ -57.53854223, -44.63363074,0.        ])\n",
        "B = np.array([-407.76417867,-564.62837335,0.        ])\n",
        "\n",
        "print(\"Expand dims\")\n",
        "A = np.expand_dims(A, axis=0)\n",
        "B = np.expand_dims(B, axis=0)\n",
        "print(A-B)\n",
        "np.sqrt(np.sum((A - B)**2,axis=1))"
      ],
      "metadata": {
        "id": "azo5xqDdUaw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "power_radar   = 1000\n",
        "power_bs_comm = 100\n",
        "power_bs_priv = np.ones((5,1))\n",
        "sigma2 = -10**(-18)  \n",
        "B = 10**6\n",
        "H_radar_uav   = np.array([7.32715132e-12])\n",
        "H_user_radar  = np.array([[8.58882632e-14, 1.90202363e-13, 7.27181848e-14, 1.50638726e-13, 9.32527962e-14],\n",
        "                [8.58882632e-14, 1.90202363e-13, 7.27181848e-14, 1.50638726e-13, 9.32527962e-14],\n",
        "                [8.58882632e-14, 1.90202363e-13, 7.27181848e-14, 1.50638726e-13, 9.32527962e-14],\n",
        "                [8.58882632e-14, 1.90202363e-13, 7.27181848e-14, 1.50638726e-13, 9.32527962e-14],\n",
        "                [8.58882632e-14, 1.90202363e-13, 7.27181848e-14, 1.50638726e-13, 9.32527962e-14]])\n",
        "# print(H_radar_uav)\n",
        "# print(np.sum(power_bs_priv))\n",
        "numerator = (H_radar_uav**2)*power_radar\n",
        "print(numerator)\n",
        "denominator = (H_user_radar**2) * (power_bs_comm + np.sum(power_bs_priv)) + (B*(sigma2))\n",
        "print(denominator)\n",
        "SINR = numerator/denominator\n",
        "print(SINR)"
      ],
      "metadata": {
        "id": "3btEVIJsPowE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BS_x = 0\n",
        "BS_y = 0\n",
        "theta  = 0\n",
        "UAV_trajectory = []\n",
        "for i in range(1000):\n",
        "    theta  = theta + np.pi/360\n",
        "    print(theta)\n",
        "    r      = 500*np.sin(theta/2)\n",
        "    UAV_vx = r*np.cos(theta)\n",
        "    UAV_vy = r*np.sin(theta)\n",
        "    UAV_vh = 0\n",
        "    UAV_trajectory.append([UAV_vx, UAV_vy, UAV_vh])\n",
        "    fig, ax = plt.subplots()\n",
        "    circle1 = plt.Circle((BS_x, BS_y), 1, color='r', fill=True)\n",
        "    circle2 = plt.Circle((BS_x, BS_y), 100, color='g', fill=False)\n",
        "    circle3 = plt.Circle((BS_x, BS_y), 1000, color='b', fill=False)\n",
        "    ax.add_patch(circle1)\n",
        "    ax.add_patch(circle2)\n",
        "    ax.add_patch(circle3)\n",
        "    gu = np.array(UAV_trajectory).transpose()[0:2].transpose()\n",
        "    plt.scatter(gu[:,0], gu[:,1])\n",
        "    plt.show()    "
      ],
      "metadata": {
        "id": "n8IeJExwwyLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "V = np.array([1,2,3,4,5])\n",
        "\n",
        "# Private user exclude sum of user at this point\n",
        "# Clone P_BS_U vector into P_BS_U matrix \n",
        "clonedM = np.ones((len(V),1))*V\n",
        "print(f\"clonedM: {clonedM}\")\n",
        "# Remove diagonal\n",
        "diagonalExcludedM = clonedM -np.diag(np.diag(clonedM))\n",
        "print(f\"diagonalExcludedM: {diagonalExcludedM}\")\n",
        "# Sum over self-excluded matrix\n",
        "rowWise_SumM = np.matrix(diagonalExcludedM).sum(axis=1)\n",
        "print(f\"rowWise_SumM: {rowWise_SumM}\")\n",
        "\n",
        "print(np.multiply(h.transpose(),rowWise_SumM))"
      ],
      "metadata": {
        "id": "H-z4cB9oPGn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RvJVuOhCUvuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}